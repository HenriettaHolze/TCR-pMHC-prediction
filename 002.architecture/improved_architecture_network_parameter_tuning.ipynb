{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "improved_architecture_network_parameter_tuning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7_0PTt2zDcu"
      },
      "source": [
        "# Model with improved architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1eP9673zDc2"
      },
      "source": [
        "#!/usr/bin/env python\n",
        "# coding: utf-8\n",
        "# Imports\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn  # All neural network modules, nn.Linear, nn.Conv2d, BatchNorm, Loss functions\n",
        "import torch.nn.functional as F  # All functions that don't have any parameters\n",
        "import torch.optim as optim  # For all Optimization algorithms, SGD, Adam, etc.\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, roc_curve, matthews_corrcoef"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qRPBXUqK-9g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4568587-6705-437e-c979-379c44e49202"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rL2nactfLNg2"
      },
      "source": [
        "drive_path = 'drive/My Drive/Colab Notebooks/tcr-prediction/'\n",
        "# sys.path.append(drive_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4XZINiozDc7"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbWQ2zIpzDc7",
        "outputId": "50d4c858-b5b2-48d3-9e66-a09ce514ad92"
      },
      "source": [
        "data_list = []\n",
        "target_list = []\n",
        "\n",
        "import glob\n",
        "\n",
        "for fp in glob.glob(drive_path+\"train/*input.npz\"):\n",
        "    data = np.load(fp)[\"arr_0\"]\n",
        "    targets = np.load(fp.replace(\"input\", \"labels\"))[\"arr_0\"]\n",
        "\n",
        "    data_list.append(data)\n",
        "    target_list.append(targets)\n",
        "# print(data_list)\n",
        "\n",
        "# Note:\n",
        "# Choose your own training and val set based on data_list and target_list\n",
        "# Here using the last partition as val set\n",
        "\n",
        "X_train = np.concatenate(data_list[:-1])\n",
        "y_train = np.concatenate(target_list[:-1])\n",
        "nsamples, nx, ny = X_train.shape\n",
        "print(\"Training set shape:\", nsamples, nx, ny)\n",
        "\n",
        "X_val = np.concatenate(data_list[-1:])\n",
        "y_val = np.concatenate(target_list[-1:])\n",
        "nsamples, nx, ny = X_val.shape\n",
        "print(\"val set shape:\", nsamples, nx, ny)\n",
        "\n",
        "p_neg = len(y_train[y_train == 1]) / len(y_train) * 100\n",
        "print(\"Percent positive samples in train:\", p_neg)\n",
        "\n",
        "p_pos = len(y_val[y_val == 1]) / len(y_val) * 100\n",
        "print(\"Percent positive samples in val:\", p_pos)\n",
        "\n",
        "# make the data set into one dataset that can go into dataloader\n",
        "train_ds = []\n",
        "for i in range(len(X_train)):\n",
        "    train_ds.append([np.transpose(X_train[i]), y_train[i]])\n",
        "\n",
        "val_ds = []\n",
        "for i in range(len(X_val)):\n",
        "    val_ds.append([np.transpose(X_val[i]), y_val[i]])\n",
        "\n",
        "bat_size = 64\n",
        "print(\"\\nNOTE:\\nSetting batch-size to\", bat_size)\n",
        "train_ldr = torch.utils.data.DataLoader(train_ds, batch_size=bat_size, shuffle=True)\n",
        "val_ldr = torch.utils.data.DataLoader(val_ds, batch_size=bat_size, shuffle=True)\n",
        "\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device (CPU/GPU):\", device)\n",
        "# device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set shape: 4174 420 54\n",
            "val set shape: 1532 420 54\n",
            "Percent positive samples in train: 24.96406324868232\n",
            "Percent positive samples in val: 25.0\n",
            "\n",
            "NOTE:\n",
            "Setting batch-size to 64\n",
            "Using device (CPU/GPU): cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYfFVJPczDdB"
      },
      "source": [
        "## Define network\n",
        "\n",
        "Changes in network (compared to example notebook)  \n",
        "- drop out between convolutional layers (0.3)\n",
        "- add lstm\n",
        "- adapt dense layer to output of lstm\n",
        "- sigmoid activation function of dense layer output so we get classes as output (or change loss to BCEWithLogitsLoss?)\n",
        "- adam optimizer with weight decay instead of SGD \n",
        "- learning rate to 0.001 and more epochs\n",
        "- early stopping after 5 iterations without improved validation loss\n",
        "- weighted loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzkW9V9bzDdC"
      },
      "source": [
        "## Parameter tuning\n",
        "\n",
        "Perform a grid search to choose optimal parameters\n",
        "\n",
        "- drop out ratio [0.1, 0.5]\n",
        "- weight decay []\n",
        "- Number of dense layers [2, 3]\n",
        "- weighted loss [yes, no]\n",
        "- learning rate [0.001, 0.0001]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87Rp9m_SzDdE"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self,  num_classes, n_local_feat, n_global_feat, num_fc, dropout):\n",
        "        self.num_fc = num_fc\n",
        "        super(Net, self).__init__()   \n",
        "        self.bn0 = nn.BatchNorm1d(n_local_feat)\n",
        "        self.conv1 = nn.Conv1d(in_channels=n_local_feat, out_channels=100, kernel_size=3, stride=2, padding=1)\n",
        "        torch.nn.init.kaiming_uniform_(self.conv1.weight)\n",
        "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "        self.conv1_bn = nn.BatchNorm1d(100)\n",
        "        \n",
        "        self.conv2 = nn.Conv1d(in_channels=100, out_channels=100, kernel_size=3, stride=2, padding=1)\n",
        "        torch.nn.init.kaiming_uniform_(self.conv2.weight)\n",
        "        self.conv2_bn = nn.BatchNorm1d(100)\n",
        "        \n",
        "        ######## code from master thesis \n",
        "        self.rnn = nn.LSTM(input_size=100,hidden_size=26,num_layers=3, dropout=dropout, batch_first=True, bidirectional = True)\n",
        "        self.drop = nn.Dropout(p = dropout) # Dunno if dropout should be even higher?? - Christian\n",
        "        self.fc1 = nn.Linear(26*2 + n_global_feat, 26*2 + n_global_feat)\n",
        "        torch.nn.init.xavier_uniform_(self.fc1.weight)\n",
        "        ########\n",
        "        \n",
        "        # since we add new features in this step, we have to use batch normalization again\n",
        "        self.bn1 = nn.BatchNorm1d(26*2 + n_global_feat)\n",
        "        # if we pipe the global terms innto the fc, we should have more than just 1\n",
        "        if num_fc == 3:\n",
        "            self.fc2 = nn.Linear(26*2 + n_global_feat, 26*2 + n_global_feat)\n",
        "            torch.nn.init.xavier_uniform_(self.fc2.weight)\n",
        "        self.fc_last = nn.Linear(26*2 + n_global_feat, num_classes)\n",
        "        torch.nn.init.xavier_uniform_(self.fc_last.weight)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        local_features = x[:, :27, :]\n",
        "        # global features are the same for the whole sequence -> take first value\n",
        "        global_features = x[:, 27:, 0]\n",
        "\n",
        "        ######## code from master thesis\n",
        "        x = self.bn0(local_features)\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.conv1_bn(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.conv2_bn(x)\n",
        "        x = self.drop(x)\n",
        "        x = x.transpose_(2, 1)\n",
        "        x, (h, c) = self.rnn(x)\n",
        "        # concatenate bidirectional output of last layer\n",
        "        cat = torch.cat((h[-2, :, :], h[-1, :, :]), dim=1)\n",
        "        # add global features\n",
        "        x = torch.cat((cat, global_features), dim=1)\n",
        "        x = self.drop(x)\n",
        "        x = self.bn1(x)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.drop(x)\n",
        "        if self.num_fc == 3:\n",
        "            x = F.relu(self.fc1(x))\n",
        "            x = self.drop(x)\n",
        "        x = torch.sigmoid(self.fc_last(x))\n",
        "        ########\n",
        "        \n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GSYKEWJzDdG"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2uo_XJWzDdH"
      },
      "source": [
        "def train(learning_rate, dropout, weight_decay, num_fc, loss_weight):\n",
        "    \n",
        "    filename = 'early_stopping_model_{lr}_{do}_{wd}_{fc}_{wl}.pt'.format(lr=learning_rate, do=dropout, wd=weight_decay, fc=num_fc, wl=loss_weight)\n",
        "    \n",
        "    # Hyperparameters fixed\n",
        "    _, input_size, n_features = X_train.shape\n",
        "    n_local_feat = 27\n",
        "    n_global_feat = n_features - n_local_feat\n",
        "    num_classes = 1\n",
        "\n",
        "    if loss_weight:\n",
        "        loss_weight = sum(y_train) / len(y_train)\n",
        "        print(\"loss weight\", loss_weight)\n",
        "    \n",
        "    # Initialize network\n",
        "    net = Net(num_classes=num_classes, n_local_feat=n_local_feat, n_global_feat=n_global_feat, num_fc=num_fc, dropout=dropout).to(device)\n",
        "\n",
        "    # Loss and optimizer\n",
        "    if loss_weight != False:\n",
        "        criterion = nn.BCELoss(reduction='none')  # for weighted loss\n",
        "    else:\n",
        "        criterion = nn.BCELoss()\n",
        "\n",
        "    # optimizer = optim.SGD(net.parameters(), lr=learning_rate)\n",
        "    optimizer = optim.Adam(net.parameters(), lr=learning_rate,\n",
        "        weight_decay=weight_decay,\n",
        "        amsgrad=True\n",
        "    )\n",
        "\n",
        "    num_epochs = 50\n",
        "\n",
        "    train_acc, train_loss = [], []\n",
        "    valid_acc, valid_loss = [], []\n",
        "    losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    # for early stopping\n",
        "    no_epoch_improve = 0\n",
        "    min_val_loss = np.Inf\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        cur_loss = 0\n",
        "        val_loss = 0\n",
        "\n",
        "        net.train()\n",
        "        train_preds, train_preds_auc, train_targs = [], [], []\n",
        "        for batch_idx, (data, target) in enumerate(train_ldr):\n",
        "            X_batch = data.float().detach().requires_grad_(True)\n",
        "            target_batch = torch.tensor(np.array(target), dtype=torch.float).unsqueeze(1)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = net(X_batch.to(device))\n",
        "\n",
        "            if loss_weight != False:\n",
        "                # calculate weighted loss\n",
        "                intermediate_loss = criterion(output, target_batch.to(device))\n",
        "                weights = torch.FloatTensor(abs(target_batch - loss_weight)).to(device)\n",
        "                batch_loss = torch.mean(weights * intermediate_loss)\n",
        "\n",
        "            else:\n",
        "                batch_loss = criterion(output, target_batch.to(device))\n",
        "\n",
        "            batch_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            preds = np.round(output.detach().cpu())\n",
        "            preds_auc = output.detach().cpu()\n",
        "            train_targs += list(np.array(target_batch.cpu()))\n",
        "            train_preds += list(preds.data.numpy().flatten())\n",
        "            train_preds_auc += list(preds_auc.data.numpy().flatten())\n",
        "            cur_loss += batch_loss.detach().cpu()\n",
        "\n",
        "        losses.append(cur_loss / len(train_ldr.dataset))\n",
        "\n",
        "        net.eval()\n",
        "        ### Evaluate validation\n",
        "        val_preds, val_preds_auc, val_targs = [], [], []\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (data, target) in enumerate(val_ldr):  ###\n",
        "                x_batch_val = data.float().detach()\n",
        "                y_batch_val = target.float().detach().unsqueeze(1)\n",
        "\n",
        "                output = net(x_batch_val.to(device))\n",
        "\n",
        "                if loss_weight != False:\n",
        "                    # calculate weighted loss\n",
        "                    intermediate_loss = criterion(output, y_batch_val.to(device))\n",
        "                    weights = torch.FloatTensor(abs(y_batch_val - loss_weight)).to(device)\n",
        "                    val_batch_loss = torch.mean(weights * intermediate_loss)\n",
        "                else:\n",
        "                    val_batch_loss = criterion(output, y_batch_val.to(device))\n",
        "\n",
        "                preds = np.round(output.detach().cpu())\n",
        "                val_preds += list(preds.data.numpy().flatten())\n",
        "                preds_auc = output.detach().cpu()\n",
        "                val_preds_auc += list(preds_auc.data.numpy().flatten())\n",
        "                val_targs += list(np.array(y_batch_val))\n",
        "                val_loss += val_batch_loss.detach().cpu()\n",
        "\n",
        "            val_losses.append(val_loss / len(val_ldr.dataset))\n",
        "            print(\"\\nEpoch:\", epoch + 1)\n",
        "\n",
        "            train_acc_cur = accuracy_score(train_targs, train_preds)\n",
        "            valid_acc_cur = accuracy_score(val_targs, val_preds)\n",
        "\n",
        "            train_acc.append(train_acc_cur)\n",
        "            valid_acc.append(valid_acc_cur)\n",
        "\n",
        "\n",
        "            print(\n",
        "                \"Training loss:\",\n",
        "                losses[-1].item(),\n",
        "                \"Validation loss:\",\n",
        "                val_losses[-1].item(),\n",
        "                end=\"\\n\",\n",
        "            )\n",
        "            print(\n",
        "                \"MCC Train:\",\n",
        "                matthews_corrcoef(train_targs, train_preds),\n",
        "                \"MCC val:\",\n",
        "                matthews_corrcoef(val_targs, val_preds),\n",
        "            )\n",
        "\n",
        "        # Early stopping: no improvement in validation loss in 10 consecutive epochs\n",
        "        if (val_loss / len(X_val)).item() < min_val_loss:\n",
        "            no_epoch_improve = 0\n",
        "            min_val_loss = (val_loss / len(X_val))\n",
        "            torch.save(net, drive_path+'models_parameter_tuning/'+filename)\n",
        "            best_epoch = epoch\n",
        "        else:\n",
        "            no_epoch_improve +=1\n",
        "        if no_epoch_improve == 10:\n",
        "            print(\"Early stopping\\n\")\n",
        "            \n",
        "            return losses, val_losses, train_acc, valid_acc, filename\n",
        "        \n",
        "    return losses, val_losses, train_acc, valid_acc, filename"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPu-twwZzDdL",
        "outputId": "1c40b75b-4ba0-410a-fd76-a8e8fb745084"
      },
      "source": [
        "# Hyperparameters tuning\n",
        "learning_rates = [0.001, 0.0001]\n",
        "dropouts = [0.1, 0.5]\n",
        "weight_decays = [0.0005, 0.005]\n",
        "num_fcs = [2, 3]\n",
        "weighted_loss = [False, True]\n",
        "\n",
        "train_losses = None\n",
        "\n",
        "with open(drive_path+'models_parameter_tuning/record_metrics_parameter_tuning.txt', 'w') as o:\n",
        "    o.write(\"learning_rate\\tdropout\\tweigt_decay\\tnum_fc\\tweighted_loss\\tmetric\\tfilename\\tvalues\\n\")\n",
        "\n",
        "for learning_rate in learning_rates:\n",
        "    for dropout in dropouts:\n",
        "        for weight_decay in weight_decays:\n",
        "            for num_fc in num_fcs:\n",
        "                for loss_weight in weighted_loss:\n",
        "                    print(learning_rate, dropout, weight_decay, num_fc, loss_weight)\n",
        "                    train_losses, val_losses, train_acc, val_acc, filename = train(learning_rate, dropout, weight_decay, num_fc, loss_weight)\n",
        "                    metrics = [train_losses, val_losses, train_acc, val_acc]\n",
        "                    metric_names = [\"train_losses\", \"val_losses\", \"train_acc\", \"val_acc\"]\n",
        "                    # save losses and accuracies in a file\n",
        "                    for i in range(len(metrics)):\n",
        "                        mystring = \"{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\n\".format(\n",
        "                                learning_rate,\n",
        "                                dropout,\n",
        "                                weight_decay,\n",
        "                                num_fc,\n",
        "                                loss_weight,\n",
        "                                metric_names[i],\n",
        "                                filename,\n",
        "                                ','.join([str(np.array(j)) for j in metrics[i]]))\n",
        "                        print(mystring)\n",
        "                        with open(drive_path+'models_parameter_tuning/record_metrics_parameter_tuning.txt', 'a') as o:\n",
        "                            o.write(mystring)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.001 0.1 0.0005 2 False\n",
            "\n",
            "Epoch: 1\n",
            "Training loss: 0.008800300769507885 Validation loss: 0.007910066284239292\n",
            "MCC Train: 0.17084724383581937 MCC val: 0.4244100066648927\n",
            "\n",
            "Epoch: 2\n",
            "Training loss: 0.0075065698474645615 Validation loss: 0.006129715126007795\n",
            "MCC Train: 0.44785342667393635 MCC val: 0.6200793678821332\n",
            "\n",
            "Epoch: 3\n",
            "Training loss: 0.006113286595791578 Validation loss: 0.005755214020609856\n",
            "MCC Train: 0.6048951760188641 MCC val: 0.6279774657984041\n",
            "\n",
            "Epoch: 4\n",
            "Training loss: 0.0049704257398843765 Validation loss: 0.005524890031665564\n",
            "MCC Train: 0.6503613270210328 MCC val: 0.6490852154624128\n",
            "\n",
            "Epoch: 5\n",
            "Training loss: 0.004385320004075766 Validation loss: 0.005519299302250147\n",
            "MCC Train: 0.6922350834460298 MCC val: 0.6654620236342264\n",
            "\n",
            "Epoch: 6\n",
            "Training loss: 0.004058794118463993 Validation loss: 0.005536530166864395\n",
            "MCC Train: 0.7252151122177273 MCC val: 0.6491195676696224\n",
            "\n",
            "Epoch: 7\n",
            "Training loss: 0.003594002453610301 Validation loss: 0.005923681892454624\n",
            "MCC Train: 0.752513150050782 MCC val: 0.6604221427408924\n",
            "\n",
            "Epoch: 8\n",
            "Training loss: 0.003357723355293274 Validation loss: 0.006255915388464928\n",
            "MCC Train: 0.7686008957559451 MCC val: 0.6527857912877979\n",
            "\n",
            "Epoch: 9\n",
            "Training loss: 0.0030232989229261875 Validation loss: 0.006735349074006081\n",
            "MCC Train: 0.7879657290102785 MCC val: 0.5823599971672466\n",
            "\n",
            "Epoch: 10\n",
            "Training loss: 0.0027339572552591562 Validation loss: 0.007105354219675064\n",
            "MCC Train: 0.8113768336023477 MCC val: 0.6328724501393698\n",
            "\n",
            "Epoch: 11\n",
            "Training loss: 0.002274293452501297 Validation loss: 0.0072600566782057285\n",
            "MCC Train: 0.8529423895178865 MCC val: 0.6459881437302141\n",
            "\n",
            "Epoch: 12\n",
            "Training loss: 0.0018487779889255762 Validation loss: 0.007864173501729965\n",
            "MCC Train: 0.8842233530125497 MCC val: 0.6150516226386188\n",
            "\n",
            "Epoch: 13\n",
            "Training loss: 0.0017924263374879956 Validation loss: 0.007947327569127083\n",
            "MCC Train: 0.8792034838375534 MCC val: 0.648626179709678\n",
            "\n",
            "Epoch: 14\n",
            "Training loss: 0.0016375749837607145 Validation loss: 0.009091177955269814\n",
            "MCC Train: 0.8918405364144978 MCC val: 0.6098665461710787\n",
            "\n",
            "Epoch: 15\n",
            "Training loss: 0.0015384057769551873 Validation loss: 0.008770843036472797\n",
            "MCC Train: 0.8949285630764607 MCC val: 0.6445317969898595\n",
            "Early stopping\n",
            "\n",
            "0.001\t0.1\t0.0005\t2\tFalse\ttrain_losses\tearly_stopping_model_0.001_0.1_0.0005_2_False.pt\t0.008800301,0.00750657,0.0061132866,0.0049704257,0.00438532,0.004058794,0.0035940025,0.0033577234,0.003023299,0.0027339573,0.0022742935,0.001848778,0.0017924263,0.001637575,0.0015384058\n",
            "\n",
            "0.001\t0.1\t0.0005\t2\tFalse\tval_losses\tearly_stopping_model_0.001_0.1_0.0005_2_False.pt\t0.007910066,0.006129715,0.005755214,0.00552489,0.0055192993,0.00553653,0.005923682,0.0062559154,0.006735349,0.007105354,0.0072600567,0.0078641735,0.007947328,0.009091178,0.008770843\n",
            "\n",
            "0.001\t0.1\t0.0005\t2\tFalse\ttrain_acc\tearly_stopping_model_0.001_0.1_0.0005_2_False.pt\t0.7491614758025874,0.8148059415428845,0.8622424532822233,0.8766171538092956,0.8900335409678966,0.9005749880210829,0.9099185433636799,0.915428845232391,0.9223766171538093,0.930522280785817,0.945376137997125,0.956875898418783,0.9549592716818399,0.9597508385241974,0.9607091518926689\n",
            "\n",
            "0.001\t0.1\t0.0005\t2\tFalse\tval_acc\tearly_stopping_model_0.001_0.1_0.0005_2_False.pt\t0.7996083550913838,0.8668407310704961,0.868798955613577,0.8714099216710183,0.8785900783289817,0.8707571801566579,0.8759791122715405,0.8714099216710183,0.8400783289817232,0.8609660574412533,0.8681462140992167,0.8531331592689295,0.868798955613577,0.8498694516971279,0.8674934725848564\n",
            "\n",
            "0.001 0.1 0.0005 2 True\n",
            "loss weight 0.2496406324868232\n",
            "\n",
            "Epoch: 1\n",
            "Training loss: 0.004153411369770765 Validation loss: 0.0036114149261265993\n",
            "MCC Train: 0.1459848446884994 MCC val: 0.29208949690337954\n",
            "\n",
            "Epoch: 2\n",
            "Training loss: 0.0036264981608837843 Validation loss: 0.0032607640605419874\n",
            "MCC Train: 0.2797812284119298 MCC val: 0.36481234382752076\n",
            "\n",
            "Epoch: 3\n",
            "Training loss: 0.003271672874689102 Validation loss: 0.00311512709595263\n",
            "MCC Train: 0.37948317372632595 MCC val: 0.4129767211440357\n",
            "\n",
            "Epoch: 4\n",
            "Training loss: 0.0028731515631079674 Validation loss: 0.0027781061362475157\n",
            "MCC Train: 0.48948762916718774 MCC val: 0.5964772289793714\n",
            "\n",
            "Epoch: 5\n",
            "Training loss: 0.0022322190925478935 Validation loss: 0.002697274787351489\n",
            "MCC Train: 0.6199239037127904 MCC val: 0.5713386840615908\n",
            "\n",
            "Epoch: 6\n",
            "Training loss: 0.001925987540744245 Validation loss: 0.0029721197206526995\n",
            "MCC Train: 0.6931019599112883 MCC val: 0.5273500137473778\n",
            "\n",
            "Epoch: 7\n",
            "Training loss: 0.0016272158827632666 Validation loss: 0.0029901994857937098\n",
            "MCC Train: 0.715415984209935 MCC val: 0.5679506368519565\n",
            "\n",
            "Epoch: 8\n",
            "Training loss: 0.001524670864455402 Validation loss: 0.0031435878481715918\n",
            "MCC Train: 0.7433700775498389 MCC val: 0.5859498055957015\n",
            "\n",
            "Epoch: 9\n",
            "Training loss: 0.0012848478509113193 Validation loss: 0.003639291739091277\n",
            "MCC Train: 0.790835937012159 MCC val: 0.599659574687044\n",
            "\n",
            "Epoch: 10\n",
            "Training loss: 0.00104805629234761 Validation loss: 0.003966140560805798\n",
            "MCC Train: 0.8075547070888937 MCC val: 0.6400009678660897\n",
            "\n",
            "Epoch: 11\n",
            "Training loss: 0.0011365817626938224 Validation loss: 0.003885876387357712\n",
            "MCC Train: 0.8101785465249056 MCC val: 0.6030226891555273\n",
            "\n",
            "Epoch: 12\n",
            "Training loss: 0.0010258093243464828 Validation loss: 0.0039550443179905415\n",
            "MCC Train: 0.8135494525203719 MCC val: 0.5841708152898016\n",
            "\n",
            "Epoch: 13\n",
            "Training loss: 0.0009446082403883338 Validation loss: 0.004173896741122007\n",
            "MCC Train: 0.8608434906099991 MCC val: 0.6274065723604343\n",
            "\n",
            "Epoch: 14\n",
            "Training loss: 0.000890732160769403 Validation loss: 0.004405617248266935\n",
            "MCC Train: 0.8451444011464052 MCC val: 0.5850480486869175\n",
            "\n",
            "Epoch: 15\n",
            "Training loss: 0.0008000731468200684 Validation loss: 0.004303723108023405\n",
            "MCC Train: 0.8696021992158316 MCC val: 0.5963755386675754\n",
            "Early stopping\n",
            "\n",
            "0.001\t0.1\t0.0005\t2\tTrue\ttrain_losses\tearly_stopping_model_0.001_0.1_0.0005_2_True.pt\t0.0041534114,0.0036264982,0.0032716729,0.0028731516,0.002232219,0.0019259875,0.0016272159,0.0015246709,0.0012848479,0.0010480563,0.0011365818,0.0010258093,0.00094460824,0.00089073216,0.00080007315\n",
            "\n",
            "0.001\t0.1\t0.0005\t2\tTrue\tval_losses\tearly_stopping_model_0.001_0.1_0.0005_2_True.pt\t0.003611415,0.003260764,0.003115127,0.0027781061,0.0026972748,0.0029721197,0.0029901995,0.0031435878,0.0036392917,0.0039661406,0.0038858764,0.0039550443,0.0041738967,0.0044056172,0.004303723\n",
            "\n",
            "0.001\t0.1\t0.0005\t2\tTrue\ttrain_acc\tearly_stopping_model_0.001_0.1_0.0005_2_True.pt\t0.5749880210828942,0.6538092956396742,0.7326305701964543,0.791327264015333,0.8461907043603258,0.8742213703881169,0.8821274556780067,0.8936272160996646,0.9147101102060373,0.9211787254432199,0.9230953521801629,0.9242932438907523,0.9446574029707714,0.9374700527072353,0.9477719214183038\n",
            "\n",
            "0.001\t0.1\t0.0005\t2\tTrue\tval_acc\tearly_stopping_model_0.001_0.1_0.0005_2_True.pt\t0.6481723237597912,0.7225848563968669,0.7578328981723238,0.8511749347258486,0.8198433420365535,0.7898172323759791,0.8172323759791122,0.8335509138381201,0.8459530026109661,0.8648825065274152,0.8439947780678851,0.8368146214099217,0.8596605744125326,0.8335509138381201,0.8426892950391645\n",
            "\n",
            "0.001 0.1 0.0005 3 False\n",
            "\n",
            "Epoch: 1\n",
            "Training loss: 0.00882209837436676 Validation loss: 0.008112546987831593\n",
            "MCC Train: 0.1254912908683289 MCC val: 0.30049017948392465\n",
            "\n",
            "Epoch: 2\n",
            "Training loss: 0.007918043993413448 Validation loss: 0.007282877806574106\n",
            "MCC Train: 0.31317459840430006 MCC val: 0.48846598612922604\n",
            "\n",
            "Epoch: 3\n",
            "Training loss: 0.007051451131701469 Validation loss: 0.007007075939327478\n",
            "MCC Train: 0.486077752775417 MCC val: 0.5073516907305001\n",
            "\n",
            "Epoch: 4\n",
            "Training loss: 0.005873588379472494 Validation loss: 0.005903530865907669\n",
            "MCC Train: 0.594140538722149 MCC val: 0.6204931518473105\n",
            "\n",
            "Epoch: 5\n",
            "Training loss: 0.004934130236506462 Validation loss: 0.0052641769871115685\n",
            "MCC Train: 0.6485910667314583 MCC val: 0.6565967173662405\n",
            "\n",
            "Epoch: 6\n",
            "Training loss: 0.0044269138015806675 Validation loss: 0.005653768312186003\n",
            "MCC Train: 0.6787171505896175 MCC val: 0.6490724778399222\n",
            "\n",
            "Epoch: 7\n",
            "Training loss: 0.004034815356135368 Validation loss: 0.006777395959943533\n",
            "MCC Train: 0.7132815743033516 MCC val: 0.5811506929049135\n",
            "\n",
            "Epoch: 8\n",
            "Training loss: 0.0035152139607816935 Validation loss: 0.007248920388519764\n",
            "MCC Train: 0.7520496039075882 MCC val: 0.5902203724613269\n",
            "\n",
            "Epoch: 9\n",
            "Training loss: 0.003423526883125305 Validation loss: 0.006775201298296452\n",
            "MCC Train: 0.7640351758890152 MCC val: 0.6050294730822892\n",
            "\n",
            "Epoch: 10\n",
            "Training loss: 0.0030119961593300104 Validation loss: 0.007220989093184471\n",
            "MCC Train: 0.7881204837145857 MCC val: 0.6157731213223214\n",
            "\n",
            "Epoch: 11\n",
            "Training loss: 0.002831696067005396 Validation loss: 0.0072272117249667645\n",
            "MCC Train: 0.825138017147555 MCC val: 0.618581773276272\n",
            "\n",
            "Epoch: 12\n",
            "Training loss: 0.0024557423312216997 Validation loss: 0.007175304461270571\n",
            "MCC Train: 0.8401676990788655 MCC val: 0.630343850464793\n",
            "\n",
            "Epoch: 13\n",
            "Training loss: 0.002098398981615901 Validation loss: 0.007730869110673666\n",
            "MCC Train: 0.856746890493527 MCC val: 0.6115822624046876\n",
            "\n",
            "Epoch: 14\n",
            "Training loss: 0.002015420002862811 Validation loss: 0.008936894126236439\n",
            "MCC Train: 0.8756320664061791 MCC val: 0.6021849063226479\n",
            "\n",
            "Epoch: 15\n",
            "Training loss: 0.0017140452982857823 Validation loss: 0.008510027080774307\n",
            "MCC Train: 0.8823231384498839 MCC val: 0.6249518948163401\n",
            "Early stopping\n",
            "\n",
            "0.001\t0.1\t0.0005\t3\tFalse\ttrain_losses\tearly_stopping_model_0.001_0.1_0.0005_3_False.pt\t0.008822098,0.007918044,0.007051451,0.0058735884,0.0049341302,0.004426914,0.0040348154,0.003515214,0.0034235269,0.0030119962,0.002831696,0.0024557423,0.002098399,0.00201542,0.0017140453\n",
            "\n",
            "0.001\t0.1\t0.0005\t3\tFalse\tval_losses\tearly_stopping_model_0.001_0.1_0.0005_3_False.pt\t0.008112547,0.007282878,0.007007076,0.005903531,0.005264177,0.0056537683,0.006777396,0.0072489204,0.0067752013,0.007220989,0.0072272117,0.0071753045,0.007730869,0.008936894,0.008510027\n",
            "\n",
            "0.001\t0.1\t0.0005\t3\tFalse\ttrain_acc\tearly_stopping_model_0.001_0.1_0.0005_3_False.pt\t0.7513176808816483,0.780067081935793,0.8263057019645424,0.8588883564925731,0.8761379971250599,0.8859607091518926,0.8974604695735505,0.9103977000479156,0.9139913751796838,0.9223766171538093,0.9357930043124102,0.9408241494968855,0.9468136080498323,0.9535218016291327,0.9561571633924293\n",
            "\n",
            "0.001\t0.1\t0.0005\t3\tFalse\tval_acc\tearly_stopping_model_0.001_0.1_0.0005_3_False.pt\t0.7637075718015666,0.8198433420365535,0.8244125326370757,0.8668407310704961,0.8785900783289817,0.8753263707571801,0.8328981723237598,0.8368146214099217,0.8544386422976501,0.8596605744125326,0.8577023498694517,0.8616187989556136,0.8550913838120104,0.8557441253263708,0.860313315926893\n",
            "\n",
            "0.001 0.1 0.0005 3 True\n",
            "loss weight 0.2496406324868232\n",
            "\n",
            "Epoch: 1\n",
            "Training loss: 0.004044046625494957 Validation loss: 0.0036318348720669746\n",
            "MCC Train: 0.1250657927207781 MCC val: 0.30364440204612714\n",
            "\n",
            "Epoch: 2\n",
            "Training loss: 0.0036711746361106634 Validation loss: 0.0034712597262114286\n",
            "MCC Train: 0.2796142310527208 MCC val: 0.26179877192027456\n",
            "\n",
            "Epoch: 3\n",
            "Training loss: 0.0032338513992726803 Validation loss: 0.002946268767118454\n",
            "MCC Train: 0.4149724001977105 MCC val: 0.5039149919052904\n",
            "\n",
            "Epoch: 4\n",
            "Training loss: 0.002801971510052681 Validation loss: 0.002903872635215521\n",
            "MCC Train: 0.5111189694823282 MCC val: 0.49185928689212394\n",
            "\n",
            "Epoch: 5\n",
            "Training loss: 0.0023384855594486 Validation loss: 0.002637283643707633\n",
            "MCC Train: 0.6197079390793386 MCC val: 0.5695744343380466\n",
            "\n",
            "Epoch: 6\n",
            "Training loss: 0.0020498447120189667 Validation loss: 0.0029034805484116077\n",
            "MCC Train: 0.6687157913459665 MCC val: 0.5100204153532014\n",
            "\n",
            "Epoch: 7\n",
            "Training loss: 0.0018041576258838177 Validation loss: 0.003091370454058051\n",
            "MCC Train: 0.6807741766664959 MCC val: 0.5416157816275976\n",
            "\n",
            "Epoch: 8\n",
            "Training loss: 0.0017296376172453165 Validation loss: 0.00308330450206995\n",
            "MCC Train: 0.7098513461581272 MCC val: 0.5750490947050095\n",
            "\n",
            "Epoch: 9\n",
            "Training loss: 0.0013549935538321733 Validation loss: 0.0031261825934052467\n",
            "MCC Train: 0.7635622737327673 MCC val: 0.5907689987281721\n",
            "\n",
            "Epoch: 10\n",
            "Training loss: 0.0013264502631500363 Validation loss: 0.003479045582935214\n",
            "MCC Train: 0.775347504567393 MCC val: 0.5692512660985432\n",
            "\n",
            "Epoch: 11\n",
            "Training loss: 0.001250694622285664 Validation loss: 0.003726908704265952\n",
            "MCC Train: 0.7925502801750859 MCC val: 0.5392990123175055\n",
            "\n",
            "Epoch: 12\n",
            "Training loss: 0.0010997670469805598 Validation loss: 0.003603009507060051\n",
            "MCC Train: 0.79886588478682 MCC val: 0.5702141601557839\n",
            "\n",
            "Epoch: 13\n",
            "Training loss: 0.0010268490295857191 Validation loss: 0.004137279000133276\n",
            "MCC Train: 0.8312792707014786 MCC val: 0.5733876460856259\n",
            "\n",
            "Epoch: 14\n",
            "Training loss: 0.000881192390806973 Validation loss: 0.003929401282221079\n",
            "MCC Train: 0.8599516632713625 MCC val: 0.5886695538388056\n",
            "\n",
            "Epoch: 15\n",
            "Training loss: 0.0007852361886762083 Validation loss: 0.00448742276057601\n",
            "MCC Train: 0.8603785236327638 MCC val: 0.5888125803319141\n",
            "Early stopping\n",
            "\n",
            "0.001\t0.1\t0.0005\t3\tTrue\ttrain_losses\tearly_stopping_model_0.001_0.1_0.0005_3_True.pt\t0.0040440466,0.0036711746,0.0032338514,0.0028019715,0.0023384856,0.0020498447,0.0018041576,0.0017296376,0.0013549936,0.0013264503,0.0012506946,0.001099767,0.001026849,0.0008811924,0.0007852362\n",
            "\n",
            "0.001\t0.1\t0.0005\t3\tTrue\tval_losses\tearly_stopping_model_0.001_0.1_0.0005_3_True.pt\t0.0036318349,0.0034712597,0.0029462688,0.0029038726,0.0026372836,0.0029034805,0.0030913705,0.0030833045,0.0031261826,0.0034790456,0.0037269087,0.0036030095,0.004137279,0.0039294013,0.0044874228\n",
            "\n",
            "0.001\t0.1\t0.0005\t3\tTrue\ttrain_acc\tearly_stopping_model_0.001_0.1_0.0005_3_True.pt\t0.5836128413991375,0.669142309535218,0.7637757546717777,0.8107331097268807,0.849544801149976,0.8672735984666986,0.868471490177288,0.8794920939147101,0.9027311931001437,0.907762338284619,0.9137517968375659,0.9180642069956876,0.9317201724964064,0.9441782462865357,0.9432199329180642\n",
            "\n",
            "0.001\t0.1\t0.0005\t3\tTrue\tval_acc\tearly_stopping_model_0.001_0.1_0.0005_3_True.pt\t0.6899477806788512,0.6468668407310705,0.8133159268929504,0.79177545691906,0.8211488250652742,0.7852480417754569,0.8107049608355091,0.827023498694517,0.8361618798955613,0.8237597911227154,0.8087467362924282,0.8237597911227154,0.8315926892950392,0.835509138381201,0.8400783289817232\n",
            "\n",
            "0.001 0.1 0.005 2 False\n",
            "\n",
            "Epoch: 1\n",
            "Training loss: 0.009314531460404396 Validation loss: 0.007939975708723068\n",
            "MCC Train: 0.1484195310713951 MCC val: 0.46833383232585984\n",
            "\n",
            "Epoch: 2\n",
            "Training loss: 0.00741964764893055 Validation loss: 0.006618024781346321\n",
            "MCC Train: 0.4441835657083815 MCC val: 0.5802651980486843\n",
            "\n",
            "Epoch: 3\n",
            "Training loss: 0.006330979522317648 Validation loss: 0.006812694016844034\n",
            "MCC Train: 0.5609678747105245 MCC val: 0.5204657845842863\n",
            "\n",
            "Epoch: 4\n",
            "Training loss: 0.0056482707150280476 Validation loss: 0.005830253474414349\n",
            "MCC Train: 0.6050654304954792 MCC val: 0.6214584446320618\n",
            "\n",
            "Epoch: 5\n",
            "Training loss: 0.004943888634443283 Validation loss: 0.005705930758267641\n",
            "MCC Train: 0.6511366406263358 MCC val: 0.595364691833151\n",
            "\n",
            "Epoch: 6\n",
            "Training loss: 0.004580950830131769 Validation loss: 0.005994048435240984\n",
            "MCC Train: 0.6658319290431717 MCC val: 0.6018294109279556\n",
            "\n",
            "Epoch: 7\n",
            "Training loss: 0.004155158996582031 Validation loss: 0.005373919382691383\n",
            "MCC Train: 0.7164248118570076 MCC val: 0.6496061915975162\n",
            "\n",
            "Epoch: 8\n",
            "Training loss: 0.0038905648980289698 Validation loss: 0.005516658537089825\n",
            "MCC Train: 0.722275616047739 MCC val: 0.6485924544503464\n",
            "\n",
            "Epoch: 9\n",
            "Training loss: 0.0036032043863087893 Validation loss: 0.006555019877851009\n",
            "MCC Train: 0.7491864971220494 MCC val: 0.5558170096676339\n",
            "\n",
            "Epoch: 10\n",
            "Training loss: 0.003421331290155649 Validation loss: 0.006063059903681278\n",
            "MCC Train: 0.7552548795622904 MCC val: 0.5950268078012179\n",
            "\n",
            "Epoch: 11\n",
            "Training loss: 0.0030078385025262833 Validation loss: 0.005778758320957422\n",
            "MCC Train: 0.7835555317068384 MCC val: 0.6507230285062737\n",
            "\n",
            "Epoch: 12\n",
            "Training loss: 0.0029087497387081385 Validation loss: 0.00570406811311841\n",
            "MCC Train: 0.8101305833599239 MCC val: 0.6564839007471845\n",
            "\n",
            "Epoch: 13\n",
            "Training loss: 0.002694918541237712 Validation loss: 0.006165600847452879\n",
            "MCC Train: 0.8199316126558649 MCC val: 0.6407296806042386\n",
            "\n",
            "Epoch: 14\n",
            "Training loss: 0.0023762830533087254 Validation loss: 0.007390827406197786\n",
            "MCC Train: 0.8466096620492741 MCC val: 0.5786897279479843\n",
            "\n",
            "Epoch: 15\n",
            "Training loss: 0.0022854432463645935 Validation loss: 0.006274484097957611\n",
            "MCC Train: 0.8574206482917738 MCC val: 0.6431129389318738\n",
            "\n",
            "Epoch: 16\n",
            "Training loss: 0.0022985567338764668 Validation loss: 0.006110668648034334\n",
            "MCC Train: 0.8607005580562465 MCC val: 0.653344932268581\n",
            "\n",
            "Epoch: 17\n",
            "Training loss: 0.002209726255387068 Validation loss: 0.006126304157078266\n",
            "MCC Train: 0.8531410779002097 MCC val: 0.6230971229762855\n",
            "Early stopping\n",
            "\n",
            "0.001\t0.1\t0.005\t2\tFalse\ttrain_losses\tearly_stopping_model_0.001_0.1_0.005_2_False.pt\t0.009314531,0.0074196476,0.0063309795,0.0056482707,0.0049438886,0.004580951,0.004155159,0.003890565,0.0036032044,0.0034213313,0.0030078385,0.0029087497,0.0026949185,0.002376283,0.0022854432,0.0022985567,0.0022097263\n",
            "\n",
            "0.001\t0.1\t0.005\t2\tFalse\tval_losses\tearly_stopping_model_0.001_0.1_0.005_2_False.pt\t0.007939976,0.006618025,0.006812694,0.0058302535,0.0057059308,0.0059940484,0.0053739194,0.0055166585,0.00655502,0.00606306,0.0057787583,0.005704068,0.006165601,0.0073908274,0.006274484,0.0061106686,0.006126304\n",
            "\n",
            "0.001\t0.1\t0.005\t2\tFalse\ttrain_acc\tearly_stopping_model_0.001_0.1_0.005_2_False.pt\t0.7146621945376138,0.813847628174413,0.8485864877815046,0.8622424532822233,0.8768567321514135,0.8814087206516531,0.8981792045999042,0.9000958313368471,0.9091998083373263,0.9111164350742693,0.920939147101102,0.930522280785817,0.9338763775754672,0.9434595112601821,0.9472927647340681,0.9484906564446574,0.9456157163392429\n",
            "\n",
            "0.001\t0.1\t0.005\t2\tFalse\tval_acc\tearly_stopping_model_0.001_0.1_0.005_2_False.pt\t0.8185378590078329,0.8544386422976501,0.8361618798955613,0.8661879895561357,0.8537859007832899,0.8518276762402088,0.8746736292428199,0.8740208877284595,0.8231070496083551,0.8505221932114883,0.8727154046997389,0.8772845953002611,0.8701044386422977,0.8361618798955613,0.8714099216710183,0.8759791122715405,0.860313315926893\n",
            "\n",
            "0.001 0.1 0.005 2 True\n",
            "loss weight 0.2496406324868232\n",
            "\n",
            "Epoch: 1\n",
            "Training loss: 0.004139067605137825 Validation loss: 0.003667452372610569\n",
            "MCC Train: 0.1305995559552988 MCC val: 0.2936936078941757\n",
            "\n",
            "Epoch: 2\n",
            "Training loss: 0.00355639960616827 Validation loss: 0.0031909628305584192\n",
            "MCC Train: 0.30175158221069204 MCC val: 0.3836104325938053\n",
            "\n",
            "Epoch: 3\n",
            "Training loss: 0.003190448973327875 Validation loss: 0.003042205236852169\n",
            "MCC Train: 0.40367963177421623 MCC val: 0.4377067780914794\n",
            "\n",
            "Epoch: 4\n",
            "Training loss: 0.0027725500985980034 Validation loss: 0.0027277597691863775\n",
            "MCC Train: 0.514114565550349 MCC val: 0.5144789330922092\n",
            "\n",
            "Epoch: 5\n",
            "Training loss: 0.002503965748474002 Validation loss: 0.0026446098927408457\n",
            "MCC Train: 0.5847366096566055 MCC val: 0.5544880005731733\n",
            "\n",
            "Epoch: 6\n",
            "Training loss: 0.00221708114258945 Validation loss: 0.0025174436159431934\n",
            "MCC Train: 0.6232298130694852 MCC val: 0.5664072793968385\n",
            "\n",
            "Epoch: 7\n",
            "Training loss: 0.0020333221182227135 Validation loss: 0.0026973430067300797\n",
            "MCC Train: 0.6589637078676883 MCC val: 0.5403211302202958\n",
            "\n",
            "Epoch: 8\n",
            "Training loss: 0.001975736580789089 Validation loss: 0.0025145874824374914\n",
            "MCC Train: 0.6617782024381496 MCC val: 0.6101791747225849\n",
            "\n",
            "Epoch: 9\n",
            "Training loss: 0.001854677451774478 Validation loss: 0.002593277720734477\n",
            "MCC Train: 0.6884249210657797 MCC val: 0.5680272006795178\n",
            "\n",
            "Epoch: 10\n",
            "Training loss: 0.0017626777989789844 Validation loss: 0.0026528723537921906\n",
            "MCC Train: 0.7180533121871453 MCC val: 0.5046955021480446\n",
            "\n",
            "Epoch: 11\n",
            "Training loss: 0.0016714197117835283 Validation loss: 0.0026859480421990156\n",
            "MCC Train: 0.7164524726516508 MCC val: 0.543421876698015\n",
            "\n",
            "Epoch: 12\n",
            "Training loss: 0.0015820880653336644 Validation loss: 0.0026955679059028625\n",
            "MCC Train: 0.7502362465607633 MCC val: 0.5524841163099808\n",
            "\n",
            "Epoch: 13\n",
            "Training loss: 0.0015485279727727175 Validation loss: 0.0026932458858937025\n",
            "MCC Train: 0.7443038423082283 MCC val: 0.5805436436016421\n",
            "\n",
            "Epoch: 14\n",
            "Training loss: 0.0015033266972750425 Validation loss: 0.002491618972271681\n",
            "MCC Train: 0.75883994750492 MCC val: 0.5381840770524243\n",
            "\n",
            "Epoch: 15\n",
            "Training loss: 0.0015130577376112342 Validation loss: 0.002627715701237321\n",
            "MCC Train: 0.7508378791412188 MCC val: 0.5706339370252271\n",
            "\n",
            "Epoch: 16\n",
            "Training loss: 0.0013707426842302084 Validation loss: 0.002741294214501977\n",
            "MCC Train: 0.7736102229975422 MCC val: 0.5618593254508278\n",
            "\n",
            "Epoch: 17\n",
            "Training loss: 0.001204971456900239 Validation loss: 0.002878660336136818\n",
            "MCC Train: 0.8274260907451336 MCC val: 0.6247904132017792\n",
            "\n",
            "Epoch: 18\n",
            "Training loss: 0.0012429403141140938 Validation loss: 0.0029937915969640017\n",
            "MCC Train: 0.8147840269085167 MCC val: 0.6136058919066393\n",
            "\n",
            "Epoch: 19\n",
            "Training loss: 0.001301732612773776 Validation loss: 0.0025787975173443556\n",
            "MCC Train: 0.7899677761160897 MCC val: 0.6098529519707975\n",
            "\n",
            "Epoch: 20\n",
            "Training loss: 0.0012227774132043123 Validation loss: 0.0026584293227642775\n",
            "MCC Train: 0.8163097026041204 MCC val: 0.5567448262477044\n",
            "\n",
            "Epoch: 21\n",
            "Training loss: 0.0010635307990014553 Validation loss: 0.0026671267114579678\n",
            "MCC Train: 0.8465911410839394 MCC val: 0.576045521150823\n",
            "\n",
            "Epoch: 22\n",
            "Training loss: 0.0010500515345484018 Validation loss: 0.003267697524279356\n",
            "MCC Train: 0.8520682355047023 MCC val: 0.6718383330093743\n",
            "\n",
            "Epoch: 23\n",
            "Training loss: 0.0009994677966460586 Validation loss: 0.0028383112512528896\n",
            "MCC Train: 0.8623234700070591 MCC val: 0.5764526077078002\n",
            "\n",
            "Epoch: 24\n",
            "Training loss: 0.0010335100814700127 Validation loss: 0.003055344335734844\n",
            "MCC Train: 0.8471331877919303 MCC val: 0.5983006906259488\n",
            "Early stopping\n",
            "\n",
            "0.001\t0.1\t0.005\t2\tTrue\ttrain_losses\tearly_stopping_model_0.001_0.1_0.005_2_True.pt\t0.0041390676,0.0035563996,0.003190449,0.00277255,0.0025039657,0.0022170811,0.0020333221,0.0019757366,0.0018546775,0.0017626778,0.0016714197,0.0015820881,0.001548528,0.0015033267,0.0015130577,0.0013707427,0.0012049715,0.0012429403,0.0013017326,0.0012227774,0.0010635308,0.0010500515,0.0009994678,0.0010335101\n",
            "\n",
            "0.001\t0.1\t0.005\t2\tTrue\tval_losses\tearly_stopping_model_0.001_0.1_0.005_2_True.pt\t0.0036674524,0.0031909628,0.0030422052,0.0027277598,0.00264461,0.0025174436,0.002697343,0.0025145875,0.0025932777,0.0026528724,0.002685948,0.002695568,0.002693246,0.002491619,0.0026277157,0.0027412942,0.0028786603,0.0029937916,0.0025787975,0.0026584293,0.0026671267,0.0032676975,0.0028383113,0.0030553443\n",
            "\n",
            "0.001\t0.1\t0.005\t2\tTrue\ttrain_acc\tearly_stopping_model_0.001_0.1_0.005_2_True.pt\t0.5896022999520844,0.67680881648299,0.7546717776712986,0.8104935313847628,0.8342117872544322,0.8493052228078581,0.8581696214662194,0.8622424532822233,0.8715860086248203,0.8859607091518926,0.8823670340201246,0.8977000479156684,0.8960229995208433,0.9017728797316723,0.8986583612841399,0.9080019166267369,0.9307618591279349,0.9254911356013417,0.9161475802587447,0.926689027311931,0.9389075227599425,0.9415428845232391,0.9456157163392429,0.9389075227599425\n",
            "\n",
            "0.001\t0.1\t0.005\t2\tTrue\tval_acc\tearly_stopping_model_0.001_0.1_0.005_2_True.pt\t0.6710182767624021,0.7526109660574413,0.7845953002610966,0.8054830287206266,0.8152741514360313,0.8263707571801566,0.7996083550913838,0.8472584856396866,0.8178851174934726,0.7721932114882507,0.8087467362924282,0.8152741514360313,0.8315926892950392,0.7989556135770235,0.8276762402088773,0.8172323759791122,0.8596605744125326,0.8531331592689295,0.847911227154047,0.8204960835509139,0.8315926892950392,0.8818537859007833,0.8283289817232375,0.8485639686684073\n",
            "\n",
            "0.001 0.1 0.005 3 False\n",
            "\n",
            "Epoch: 1\n",
            "Training loss: 0.008770273998379707 Validation loss: 0.008543252013623714\n",
            "MCC Train: 0.09689428568043382 MCC val: 0.3461963322676938\n",
            "\n",
            "Epoch: 2\n",
            "Training loss: 0.007773312274366617 Validation loss: 0.009131803177297115\n",
            "MCC Train: 0.32684143372504154 MCC val: 0.3205504573260288\n",
            "\n",
            "Epoch: 3\n",
            "Training loss: 0.007011644542217255 Validation loss: 0.0073491246439516544\n",
            "MCC Train: 0.4920820946867133 MCC val: 0.46497024459448466\n",
            "\n",
            "Epoch: 4\n",
            "Training loss: 0.006185921374708414 Validation loss: 0.0063285562209784985\n",
            "MCC Train: 0.5784512204935373 MCC val: 0.5351188264331039\n",
            "\n",
            "Epoch: 5\n",
            "Training loss: 0.0053429752588272095 Validation loss: 0.005606636870652437\n",
            "MCC Train: 0.6186652217322277 MCC val: 0.5909736897749344\n",
            "\n",
            "Epoch: 6\n",
            "Training loss: 0.004744452890008688 Validation loss: 0.005837833508849144\n",
            "MCC Train: 0.6751359307823547 MCC val: 0.6030704234404821\n",
            "\n",
            "Epoch: 7\n",
            "Training loss: 0.004342237953096628 Validation loss: 0.005582563113421202\n",
            "MCC Train: 0.6906736518526818 MCC val: 0.6189168678002784\n",
            "\n",
            "Epoch: 8\n",
            "Training loss: 0.0039736065082252026 Validation loss: 0.006118857767432928\n",
            "MCC Train: 0.7159471613487316 MCC val: 0.586504084286376\n",
            "\n",
            "Epoch: 9\n",
            "Training loss: 0.00399416359141469 Validation loss: 0.00556712131947279\n",
            "MCC Train: 0.7145104371995075 MCC val: 0.6144390279044778\n",
            "\n",
            "Epoch: 10\n",
            "Training loss: 0.003490533446893096 Validation loss: 0.005550070200115442\n",
            "MCC Train: 0.75659368722662 MCC val: 0.609443568482417\n",
            "\n",
            "Epoch: 11\n",
            "Training loss: 0.0033405618742108345 Validation loss: 0.0061089047230780125\n",
            "MCC Train: 0.7688677307540402 MCC val: 0.5973475389502503\n",
            "\n",
            "Epoch: 12\n",
            "Training loss: 0.0032794808503240347 Validation loss: 0.005784487351775169\n",
            "MCC Train: 0.7826055405742692 MCC val: 0.6052183065690195\n",
            "\n",
            "Epoch: 13\n",
            "Training loss: 0.002985459053888917 Validation loss: 0.00588380778208375\n",
            "MCC Train: 0.793252308449246 MCC val: 0.6419066723517941\n",
            "\n",
            "Epoch: 14\n",
            "Training loss: 0.002672662027180195 Validation loss: 0.0059290193021297455\n",
            "MCC Train: 0.8210629130382586 MCC val: 0.6229541489762261\n",
            "\n",
            "Epoch: 15\n",
            "Training loss: 0.0026306083891540766 Validation loss: 0.00659566093236208\n",
            "MCC Train: 0.832383671786059 MCC val: 0.6064961213657347\n",
            "\n",
            "Epoch: 16\n",
            "Training loss: 0.0024056104011833668 Validation loss: 0.007217924110591412\n",
            "MCC Train: 0.8325448427513517 MCC val: 0.5838356488980571\n",
            "\n",
            "Epoch: 17\n",
            "Training loss: 0.002283227862790227 Validation loss: 0.007000764366239309\n",
            "MCC Train: 0.8459712872745054 MCC val: 0.5753154438200078\n",
            "\n",
            "Epoch: 18\n",
            "Training loss: 0.002192773623391986 Validation loss: 0.006475416943430901\n",
            "MCC Train: 0.8609847812540153 MCC val: 0.6048218929361302\n",
            "\n",
            "Epoch: 19\n",
            "Training loss: 0.001892094500362873 Validation loss: 0.007555197924375534\n",
            "MCC Train: 0.8670248245156924 MCC val: 0.5877872728760235\n",
            "\n",
            "Epoch: 20\n",
            "Training loss: 0.0020940883550792933 Validation loss: 0.007115757558494806\n",
            "MCC Train: 0.8658586418111214 MCC val: 0.596929590495981\n",
            "Early stopping\n",
            "\n",
            "0.001\t0.1\t0.005\t3\tFalse\ttrain_losses\tearly_stopping_model_0.001_0.1_0.005_3_False.pt\t0.008770274,0.0077733123,0.0070116445,0.0061859214,0.0053429753,0.004744453,0.004342238,0.0039736065,0.0039941636,0.0034905334,0.0033405619,0.0032794809,0.002985459,0.002672662,0.0026306084,0.0024056104,0.0022832279,0.0021927736,0.0018920945,0.0020940884\n",
            "\n",
            "0.001\t0.1\t0.005\t3\tFalse\tval_losses\tearly_stopping_model_0.001_0.1_0.005_3_False.pt\t0.008543252,0.009131803,0.0073491246,0.006328556,0.005606637,0.0058378335,0.005582563,0.006118858,0.0055671213,0.00555007,0.0061089047,0.0057844874,0.005883808,0.0059290193,0.006595661,0.007217924,0.0070007644,0.006475417,0.007555198,0.0071157576\n",
            "\n",
            "0.001\t0.1\t0.005\t3\tFalse\ttrain_acc\tearly_stopping_model_0.001_0.1_0.005_3_False.pt\t0.7508385241974126,0.7846190704360326,0.8275035936751318,0.8538572113080978,0.866554863440345,0.8847628174413033,0.8897939626257786,0.8979396262577863,0.8974604695735505,0.9113560134163872,0.915428845232391,0.9204599904168663,0.9240536655486344,0.9338763775754672,0.937949209391471,0.9377096310493531,0.9429803545759463,0.9484906564446574,0.9506468615237182,0.9501677048394825\n",
            "\n",
            "0.001\t0.1\t0.005\t3\tFalse\tval_acc\tearly_stopping_model_0.001_0.1_0.005_3_False.pt\t0.7676240208877284,0.6964751958224543,0.8009138381201044,0.835509138381201,0.8570496083550914,0.8590078328981723,0.8642297650130548,0.8472584856396866,0.8524804177545692,0.8590078328981723,0.8459530026109661,0.8518276762402088,0.8707571801566579,0.8622715404699739,0.8550913838120104,0.8426892950391645,0.8348563968668408,0.856396866840731,0.8459530026109661,0.847911227154047\n",
            "\n",
            "0.001 0.1 0.005 3 True\n",
            "loss weight 0.2496406324868232\n",
            "\n",
            "Epoch: 1\n",
            "Training loss: 0.003969733137637377 Validation loss: 0.0036510019563138485\n",
            "MCC Train: 0.15236753406755815 MCC val: 0.2790519524499212\n",
            "\n",
            "Epoch: 2\n",
            "Training loss: 0.0034845243208110332 Validation loss: 0.0033572246320545673\n",
            "MCC Train: 0.33058102708733234 MCC val: 0.29270840554758704\n",
            "\n",
            "Epoch: 3\n",
            "Training loss: 0.003223070641979575 Validation loss: 0.0031070061959326267\n",
            "MCC Train: 0.4466708569979027 MCC val: 0.3788671421648295\n",
            "\n",
            "Epoch: 4\n",
            "Training loss: 0.0028899661265313625 Validation loss: 0.0028596518095582724\n",
            "MCC Train: 0.5289292303671355 MCC val: 0.5085744046188986\n",
            "\n",
            "Epoch: 5\n",
            "Training loss: 0.0026375707238912582 Validation loss: 0.002828679047524929\n",
            "MCC Train: 0.5736929008909325 MCC val: 0.4571659446122001\n",
            "\n",
            "Epoch: 6\n",
            "Training loss: 0.002422068500891328 Validation loss: 0.002569608623161912\n",
            "MCC Train: 0.5898568365853015 MCC val: 0.526470290961496\n",
            "\n",
            "Epoch: 7\n",
            "Training loss: 0.002180524868890643 Validation loss: 0.0024879516568034887\n",
            "MCC Train: 0.6198539390938358 MCC val: 0.5475283650866671\n",
            "\n",
            "Epoch: 8\n",
            "Training loss: 0.0020925092976540327 Validation loss: 0.002563709393143654\n",
            "MCC Train: 0.6292357571002154 MCC val: 0.5604794945879483\n",
            "\n",
            "Epoch: 9\n",
            "Training loss: 0.0019021729240193963 Validation loss: 0.00250444607809186\n",
            "MCC Train: 0.6584268644576766 MCC val: 0.5826486799303736\n",
            "\n",
            "Epoch: 10\n",
            "Training loss: 0.0019298559054732323 Validation loss: 0.0027139002922922373\n",
            "MCC Train: 0.6707641095517612 MCC val: 0.533925394351028\n",
            "\n",
            "Epoch: 11\n",
            "Training loss: 0.0017673514084890485 Validation loss: 0.002919836901128292\n",
            "MCC Train: 0.6784346410856957 MCC val: 0.49423030961471226\n",
            "\n",
            "Epoch: 12\n",
            "Training loss: 0.0017681717872619629 Validation loss: 0.0026546164881438017\n",
            "MCC Train: 0.6971666248667471 MCC val: 0.564891985228738\n",
            "\n",
            "Epoch: 13\n",
            "Training loss: 0.0016509722918272018 Validation loss: 0.0026716573629528284\n",
            "MCC Train: 0.7127020528997854 MCC val: 0.5337090065815788\n",
            "\n",
            "Epoch: 14\n",
            "Training loss: 0.0016624127747491002 Validation loss: 0.002631848445162177\n",
            "MCC Train: 0.7089002018239728 MCC val: 0.6002038745261552\n",
            "\n",
            "Epoch: 15\n",
            "Training loss: 0.0015286114066839218 Validation loss: 0.002839472144842148\n",
            "MCC Train: 0.7515595143877026 MCC val: 0.564060061447016\n",
            "\n",
            "Epoch: 16\n",
            "Training loss: 0.0014600015711039305 Validation loss: 0.0028551635332405567\n",
            "MCC Train: 0.745603587452955 MCC val: 0.5443500110381282\n",
            "\n",
            "Epoch: 17\n",
            "Training loss: 0.0013809864176437259 Validation loss: 0.0029453991446644068\n",
            "MCC Train: 0.7722622269302647 MCC val: 0.5251056002233386\n",
            "Early stopping\n",
            "\n",
            "0.001\t0.1\t0.005\t3\tTrue\ttrain_losses\tearly_stopping_model_0.001_0.1_0.005_3_True.pt\t0.003969733,0.0034845243,0.0032230706,0.0028899661,0.0026375707,0.0024220685,0.0021805249,0.0020925093,0.0019021729,0.0019298559,0.0017673514,0.0017681718,0.0016509723,0.0016624128,0.0015286114,0.0014600016,0.0013809864\n",
            "\n",
            "0.001\t0.1\t0.005\t3\tTrue\tval_losses\tearly_stopping_model_0.001_0.1_0.005_3_True.pt\t0.003651002,0.0033572246,0.0031070062,0.0028596518,0.002828679,0.0025696086,0.0024879517,0.0025637094,0.002504446,0.0027139003,0.002919837,0.0026546165,0.0026716574,0.0026318484,0.0028394721,0.0028551635,0.0029453991\n",
            "\n",
            "0.001\t0.1\t0.005\t3\tTrue\ttrain_acc\tearly_stopping_model_0.001_0.1_0.005_3_True.pt\t0.6075706756109248,0.714422616195496,0.7901293723047437,0.828941063727839,0.8423574508864399,0.8378054623862002,0.8466698610445615,0.8406804024916148,0.855294681360805,0.8612841399137517,0.8639195016770483,0.8735026353617633,0.8792525155725922,0.8768567321514135,0.8977000479156684,0.8936272160996646,0.906085289889794\n",
            "\n",
            "0.001\t0.1\t0.005\t3\tTrue\tval_acc\tearly_stopping_model_0.001_0.1_0.005_3_True.pt\t0.6527415143603134,0.6755874673629243,0.7532637075718016,0.8231070496083551,0.7767624020887729,0.7845953002610966,0.8067885117493473,0.8231070496083551,0.8322454308093995,0.8067885117493473,0.7787206266318538,0.8172323759791122,0.804177545691906,0.8466057441253264,0.8224543080939948,0.8067885117493473,0.7996083550913838\n",
            "\n",
            "0.001 0.5 0.0005 2 False\n",
            "\n",
            "Epoch: 1\n",
            "Training loss: 0.011117505840957165 Validation loss: 0.00946043524891138\n",
            "MCC Train: -0.018136852190439125 MCC val: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:900: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2\n",
            "Training loss: 0.010089042596518993 Validation loss: 0.009380068629980087\n",
            "MCC Train: 0.00577749382800582 MCC val: 0.0\n",
            "\n",
            "Epoch: 3\n",
            "Training loss: 0.009667736478149891 Validation loss: 0.009339360520243645\n",
            "MCC Train: 0.0069036666404937936 MCC val: 0.0\n",
            "\n",
            "Epoch: 4\n",
            "Training loss: 0.009500213898718357 Validation loss: 0.009476261213421822\n",
            "MCC Train: -0.018801840744197718 MCC val: 0.0\n",
            "\n",
            "Epoch: 5\n",
            "Training loss: 0.009265024214982986 Validation loss: 0.009324033744633198\n",
            "MCC Train: 0.018716780558461262 MCC val: 0.0\n",
            "\n",
            "Epoch: 6\n",
            "Training loss: 0.009039200842380524 Validation loss: 0.0091506727039814\n",
            "MCC Train: 0.05227220639759695 MCC val: 0.0\n",
            "\n",
            "Epoch: 7\n",
            "Training loss: 0.008896123617887497 Validation loss: 0.00850972905755043\n",
            "MCC Train: 0.06164485947513095 MCC val: 0.2911902324227551\n",
            "\n",
            "Epoch: 8\n",
            "Training loss: 0.0086708664894104 Validation loss: 0.008597088046371937\n",
            "MCC Train: 0.12198263698085718 MCC val: 0.3398301273938429\n",
            "\n",
            "Epoch: 9\n",
            "Training loss: 0.008357077836990356 Validation loss: 0.008522781543433666\n",
            "MCC Train: 0.16507056916421511 MCC val: 0.33972577864076386\n",
            "\n",
            "Epoch: 10\n",
            "Training loss: 0.008335052989423275 Validation loss: 0.008313970640301704\n",
            "MCC Train: 0.17759266476939511 MCC val: 0.34124018948557644\n",
            "\n",
            "Epoch: 11\n",
            "Training loss: 0.008244798518717289 Validation loss: 0.008335561491549015\n",
            "MCC Train: 0.15962304996603185 MCC val: 0.3354987339022929\n",
            "\n",
            "Epoch: 12\n",
            "Training loss: 0.00824746210128069 Validation loss: 0.008161474019289017\n",
            "MCC Train: 0.17336099405607555 MCC val: 0.34281887949491874\n",
            "\n",
            "Epoch: 13\n",
            "Training loss: 0.008116715587675571 Validation loss: 0.008273739367723465\n",
            "MCC Train: 0.18998756750665208 MCC val: 0.3610649069998656\n",
            "\n",
            "Epoch: 14\n",
            "Training loss: 0.007986338809132576 Validation loss: 0.008068590424954891\n",
            "MCC Train: 0.2446145828447472 MCC val: 0.3646433899708661\n",
            "\n",
            "Epoch: 15\n",
            "Training loss: 0.007975487038493156 Validation loss: 0.008049785159528255\n",
            "MCC Train: 0.25453309722716727 MCC val: 0.36826091878023687\n",
            "\n",
            "Epoch: 16\n",
            "Training loss: 0.007897801697254181 Validation loss: 0.007936978712677956\n",
            "MCC Train: 0.28767839294599146 MCC val: 0.3711694461672127\n",
            "\n",
            "Epoch: 17\n",
            "Training loss: 0.007677201647311449 Validation loss: 0.00783921405673027\n",
            "MCC Train: 0.29385168867769484 MCC val: 0.3894507861460926\n",
            "\n",
            "Epoch: 18\n",
            "Training loss: 0.007489250972867012 Validation loss: 0.0075878263451159\n",
            "MCC Train: 0.3910408434553991 MCC val: 0.4737156386844509\n",
            "\n",
            "Epoch: 19\n",
            "Training loss: 0.006800434086471796 Validation loss: 0.006467784289270639\n",
            "MCC Train: 0.5500750298158561 MCC val: 0.5909736897749344\n",
            "\n",
            "Epoch: 20\n",
            "Training loss: 0.006329129915684462 Validation loss: 0.006614566780626774\n",
            "MCC Train: 0.6003398404676669 MCC val: 0.5836324190926969\n",
            "\n",
            "Epoch: 21\n",
            "Training loss: 0.0060193357057869434 Validation loss: 0.00599362887442112\n",
            "MCC Train: 0.6171453284270146 MCC val: 0.6282846094334015\n",
            "\n",
            "Epoch: 22\n",
            "Training loss: 0.006090741138905287 Validation loss: 0.005941963288933039\n",
            "MCC Train: 0.6232493178945474 MCC val: 0.6282051417186099\n",
            "\n",
            "Epoch: 23\n",
            "Training loss: 0.005973569583147764 Validation loss: 0.0058833276852965355\n",
            "MCC Train: 0.6277489447427554 MCC val: 0.628427680293989\n",
            "\n",
            "Epoch: 24\n",
            "Training loss: 0.005486239213496447 Validation loss: 0.005561999045312405\n",
            "MCC Train: 0.6482727091131654 MCC val: 0.6323903867720934\n",
            "\n",
            "Epoch: 25\n",
            "Training loss: 0.00548098748549819 Validation loss: 0.0054661575704813\n",
            "MCC Train: 0.6525534321581897 MCC val: 0.6245028006476162\n",
            "\n",
            "Epoch: 26\n",
            "Training loss: 0.005435251630842686 Validation loss: 0.005265583284199238\n",
            "MCC Train: 0.644879018030235 MCC val: 0.6323903867720934\n",
            "\n",
            "Epoch: 27\n",
            "Training loss: 0.005292804446071386 Validation loss: 0.0053704832680523396\n",
            "MCC Train: 0.6524165418045582 MCC val: 0.6266678666647042\n",
            "\n",
            "Epoch: 28\n",
            "Training loss: 0.005151819437742233 Validation loss: 0.005488491151481867\n",
            "MCC Train: 0.6557782159278437 MCC val: 0.6226763515904067\n",
            "\n",
            "Epoch: 29\n",
            "Training loss: 0.005164469592273235 Validation loss: 0.005401342175900936\n",
            "MCC Train: 0.6683117910981702 MCC val: 0.6265578848868977\n",
            "\n",
            "Epoch: 30\n",
            "Training loss: 0.005115887150168419 Validation loss: 0.005180325359106064\n",
            "MCC Train: 0.6605168933134364 MCC val: 0.6384334157994912\n",
            "\n",
            "Epoch: 31\n",
            "Training loss: 0.004941991064697504 Validation loss: 0.0052106562070548534\n",
            "MCC Train: 0.6687234931031871 MCC val: 0.6323126734536143\n",
            "\n",
            "Epoch: 32\n",
            "Training loss: 0.004906340502202511 Validation loss: 0.005237828474491835\n",
            "MCC Train: 0.6739580099644068 MCC val: 0.6405003177323029\n",
            "\n",
            "Epoch: 33\n",
            "Training loss: 0.004945483524352312 Validation loss: 0.0051613436080515385\n",
            "MCC Train: 0.6710895433309868 MCC val: 0.6363769159198275\n",
            "\n",
            "Epoch: 34\n",
            "Training loss: 0.004835110157728195 Validation loss: 0.00515280244871974\n",
            "MCC Train: 0.6661250233092171 MCC val: 0.6445995197657896\n",
            "\n",
            "Epoch: 35\n",
            "Training loss: 0.0048070685006678104 Validation loss: 0.005737457424402237\n",
            "MCC Train: 0.6633523039981061 MCC val: 0.6135263655265142\n",
            "\n",
            "Epoch: 36\n",
            "Training loss: 0.004766182973980904 Validation loss: 0.0055499910376966\n",
            "MCC Train: 0.6785222976567412 MCC val: 0.6207492090989428\n",
            "\n",
            "Epoch: 37\n",
            "Training loss: 0.00470756134018302 Validation loss: 0.005443339701741934\n",
            "MCC Train: 0.6854154124273921 MCC val: 0.6408639437640613\n",
            "\n",
            "Epoch: 38\n",
            "Training loss: 0.004543900024145842 Validation loss: 0.005224963650107384\n",
            "MCC Train: 0.680908952139809 MCC val: 0.6505488599842062\n",
            "\n",
            "Epoch: 39\n",
            "Training loss: 0.004580238834023476 Validation loss: 0.0053885579109191895\n",
            "MCC Train: 0.6809820352083451 MCC val: 0.6304763303731399\n",
            "\n",
            "Epoch: 40\n",
            "Training loss: 0.00456503638997674 Validation loss: 0.005240983329713345\n",
            "MCC Train: 0.6780808721870407 MCC val: 0.6363916595804331\n",
            "\n",
            "Epoch: 41\n",
            "Training loss: 0.004517542663961649 Validation loss: 0.0053679789416491985\n",
            "MCC Train: 0.6894800636919504 MCC val: 0.6344324016567204\n",
            "\n",
            "Epoch: 42\n",
            "Training loss: 0.004576332867145538 Validation loss: 0.005262846127152443\n",
            "MCC Train: 0.6837866634462156 MCC val: 0.6527204643222628\n",
            "\n",
            "Epoch: 43\n",
            "Training loss: 0.004302410874515772 Validation loss: 0.005243717227131128\n",
            "MCC Train: 0.7036481902441494 MCC val: 0.6404402117938055\n",
            "\n",
            "Epoch: 44\n",
            "Training loss: 0.004289351869374514 Validation loss: 0.005373459309339523\n",
            "MCC Train: 0.705399421590542 MCC val: 0.6404934917556336\n",
            "Early stopping\n",
            "\n",
            "0.001\t0.5\t0.0005\t2\tFalse\ttrain_losses\tearly_stopping_model_0.001_0.5_0.0005_2_False.pt\t0.011117506,0.010089043,0.0096677365,0.009500214,0.009265024,0.009039201,0.008896124,0.0086708665,0.008357078,0.008335053,0.0082447985,0.008247462,0.008116716,0.007986339,0.007975487,0.007897802,0.0076772016,0.007489251,0.006800434,0.00632913,0.0060193357,0.006090741,0.0059735696,0.005486239,0.0054809875,0.0054352516,0.0052928044,0.0051518194,0.0051644696,0.005115887,0.004941991,0.0049063405,0.0049454835,0.00483511,0.0048070685,0.004766183,0.0047075613,0.0045439,0.004580239,0.0045650364,0.0045175427,0.004576333,0.004302411,0.004289352\n",
            "\n",
            "0.001\t0.5\t0.0005\t2\tFalse\tval_losses\tearly_stopping_model_0.001_0.5_0.0005_2_False.pt\t0.009460435,0.009380069,0.0093393605,0.009476261,0.009324034,0.009150673,0.008509729,0.008597088,0.008522782,0.008313971,0.0083355615,0.008161474,0.008273739,0.00806859,0.008049785,0.007936979,0.007839214,0.0075878263,0.0064677843,0.006614567,0.005993629,0.0059419633,0.0058833277,0.005561999,0.0054661576,0.0052655833,0.0053704833,0.005488491,0.005401342,0.0051803254,0.005210656,0.0052378285,0.0051613436,0.0051528024,0.0057374574,0.005549991,0.0054433397,0.0052249637,0.005388558,0.0052409833,0.005367979,0.005262846,0.005243717,0.0053734593\n",
            "\n",
            "0.001\t0.5\t0.0005\t2\tFalse\ttrain_acc\tearly_stopping_model_0.001_0.5_0.0005_2_False.pt\t0.6420699568758984,0.7103497843794921,0.7187350263536176,0.7216099664590321,0.7323909918543363,0.7448490656444657,0.7431720172496407,0.7496406324868232,0.7532343076185912,0.7541926209870627,0.7494010541447054,0.7503593675131768,0.7563488260661236,0.7628174413033062,0.764973646382367,0.7728797316722569,0.7733588883564926,0.7985146142788692,0.8454719693339722,0.860804983229516,0.8660757067561092,0.8679923334930523,0.8694298035457595,0.8758984187829421,0.8773358888356493,0.8749401054144705,0.8773358888356493,0.8782942022041208,0.8823670340201246,0.8799712505989459,0.8826066123622425,0.8842836607570675,0.883325347388596,0.881648298993771,0.8809295639674174,0.8857211308097748,0.8881169142309535,0.8866794441782463,0.8866794441782463,0.8857211308097748,0.8893148059415429,0.8876377575467178,0.8941063727839004,0.8948251078102539\n",
            "\n",
            "0.001\t0.5\t0.0005\t2\tFalse\tval_acc\tearly_stopping_model_0.001_0.5_0.0005_2_False.pt\t0.75,0.75,0.75,0.75,0.75,0.75,0.7721932114882507,0.7395561357702349,0.7278067885117493,0.7304177545691906,0.7258485639686684,0.7330287206266318,0.7336814621409922,0.741514360313316,0.741514360313316,0.7441253263707572,0.7526109660574413,0.8048302872062664,0.8570496083550914,0.8537859007832899,0.8694516971279374,0.8694516971279374,0.8694516971279374,0.8707571801566579,0.8681462140992167,0.8707571801566579,0.868798955613577,0.8674934725848564,0.868798955613577,0.8727154046997389,0.8707571801566579,0.8733681462140992,0.8720626631853786,0.8746736292428199,0.8642297650130548,0.8668407310704961,0.8733681462140992,0.8766318537859008,0.8701044386422977,0.8720626631853786,0.8714099216710183,0.8772845953002611,0.8733681462140992,0.8733681462140992\n",
            "\n",
            "0.001 0.5 0.0005 2 True\n",
            "loss weight 0.2496406324868232\n",
            "\n",
            "Epoch: 1\n",
            "Training loss: 0.004781849682331085 Validation loss: 0.00393611891195178\n",
            "MCC Train: 0.03348181375918399 MCC val: 0.1909571848992503\n",
            "\n",
            "Epoch: 2\n",
            "Training loss: 0.0044771041721105576 Validation loss: 0.0038965221028774977\n",
            "MCC Train: 0.06088879731343676 MCC val: 0.24102547264479918\n",
            "\n",
            "Epoch: 3\n",
            "Training loss: 0.004415796138346195 Validation loss: 0.003847926389425993\n",
            "MCC Train: 0.043445818195479526 MCC val: 0.2786115336833408\n",
            "\n",
            "Epoch: 4\n",
            "Training loss: 0.0042294347658753395 Validation loss: 0.0037229673471301794\n",
            "MCC Train: 0.06670073275033148 MCC val: 0.29378510593181\n",
            "\n",
            "Epoch: 5\n",
            "Training loss: 0.004121658392250538 Validation loss: 0.0036789800506085157\n",
            "MCC Train: 0.12017054683457389 MCC val: 0.3129873067244695\n",
            "\n",
            "Epoch: 6\n",
            "Training loss: 0.00403007585555315 Validation loss: 0.003668599296361208\n",
            "MCC Train: 0.16755600269194798 MCC val: 0.3209990093523543\n",
            "\n",
            "Epoch: 7\n",
            "Training loss: 0.00394172128289938 Validation loss: 0.003631799714639783\n",
            "MCC Train: 0.19599368135692707 MCC val: 0.3252445426544812\n",
            "\n",
            "Epoch: 8\n",
            "Training loss: 0.0038401749916374683 Validation loss: 0.003620132803916931\n",
            "MCC Train: 0.2205789291059061 MCC val: 0.30934238544997783\n",
            "\n",
            "Epoch: 9\n",
            "Training loss: 0.0038001486100256443 Validation loss: 0.003587693441659212\n",
            "MCC Train: 0.24347895363119182 MCC val: 0.3294527412118056\n",
            "\n",
            "Epoch: 10\n",
            "Training loss: 0.0037137125618755817 Validation loss: 0.0036105269100517035\n",
            "MCC Train: 0.2765078653717249 MCC val: 0.32351981665785934\n",
            "\n",
            "Epoch: 11\n",
            "Training loss: 0.0037081707268953323 Validation loss: 0.003581323428079486\n",
            "MCC Train: 0.2902529045386186 MCC val: 0.32658610732248544\n",
            "\n",
            "Epoch: 12\n",
            "Training loss: 0.0036338823847472668 Validation loss: 0.0035169352777302265\n",
            "MCC Train: 0.3073119394688204 MCC val: 0.3294991738754909\n",
            "\n",
            "Epoch: 13\n",
            "Training loss: 0.003605047706514597 Validation loss: 0.0034227913711220026\n",
            "MCC Train: 0.3179144218157568 MCC val: 0.36016221337864673\n",
            "\n",
            "Epoch: 14\n",
            "Training loss: 0.00347376661375165 Validation loss: 0.003540207864716649\n",
            "MCC Train: 0.35296986976405553 MCC val: 0.306053085758437\n",
            "\n",
            "Epoch: 15\n",
            "Training loss: 0.003391783684492111 Validation loss: 0.003930181730538607\n",
            "MCC Train: 0.3814508918927078 MCC val: 0.24345208336762192\n",
            "\n",
            "Epoch: 16\n",
            "Training loss: 0.003219161182641983 Validation loss: 0.0033337015192955732\n",
            "MCC Train: 0.44767972623286406 MCC val: 0.38451967899128486\n",
            "\n",
            "Epoch: 17\n",
            "Training loss: 0.0030999858863651752 Validation loss: 0.003483036532998085\n",
            "MCC Train: 0.4959274131058111 MCC val: 0.41335699606895204\n",
            "\n",
            "Epoch: 18\n",
            "Training loss: 0.003038592403754592 Validation loss: 0.0031127622351050377\n",
            "MCC Train: 0.5572456008833251 MCC val: 0.5038526096101769\n",
            "\n",
            "Epoch: 19\n",
            "Training loss: 0.0029651352670043707 Validation loss: 0.0032954851631075144\n",
            "MCC Train: 0.5921704492153289 MCC val: 0.42881613451059714\n",
            "\n",
            "Epoch: 20\n",
            "Training loss: 0.0028773960657417774 Validation loss: 0.003084584604948759\n",
            "MCC Train: 0.6021884180667235 MCC val: 0.528934437583143\n",
            "\n",
            "Epoch: 21\n",
            "Training loss: 0.002843857277184725 Validation loss: 0.0028580850921571255\n",
            "MCC Train: 0.6166885235958304 MCC val: 0.6012631661494817\n",
            "\n",
            "Epoch: 22\n",
            "Training loss: 0.0027817431837320328 Validation loss: 0.0027912550140172243\n",
            "MCC Train: 0.6288166757887669 MCC val: 0.6069388717686116\n",
            "\n",
            "Epoch: 23\n",
            "Training loss: 0.002687861444428563 Validation loss: 0.0026582852005958557\n",
            "MCC Train: 0.633492115888715 MCC val: 0.622810656227456\n",
            "\n",
            "Epoch: 24\n",
            "Training loss: 0.002582644112408161 Validation loss: 0.0025374521501362324\n",
            "MCC Train: 0.6372226191120353 MCC val: 0.6181095384495922\n",
            "\n",
            "Epoch: 25\n",
            "Training loss: 0.0025950991548597813 Validation loss: 0.002554904669523239\n",
            "MCC Train: 0.6201051409021366 MCC val: 0.6121284146165853\n",
            "\n",
            "Epoch: 26\n",
            "Training loss: 0.002425919286906719 Validation loss: 0.002499974798411131\n",
            "MCC Train: 0.6181679792211183 MCC val: 0.6232850733026819\n",
            "\n",
            "Epoch: 27\n",
            "Training loss: 0.002436393639072776 Validation loss: 0.0025264162104576826\n",
            "MCC Train: 0.5970876356635144 MCC val: 0.622673571094969\n",
            "\n",
            "Epoch: 28\n",
            "Training loss: 0.0024113873951137066 Validation loss: 0.0025769982021301985\n",
            "MCC Train: 0.5954194516346 MCC val: 0.5997984632768437\n",
            "\n",
            "Epoch: 29\n",
            "Training loss: 0.0023860004730522633 Validation loss: 0.0025811113882809877\n",
            "MCC Train: 0.5910788257090575 MCC val: 0.5904917582521607\n",
            "\n",
            "Epoch: 30\n",
            "Training loss: 0.0023481494281440973 Validation loss: 0.0024655857123434544\n",
            "MCC Train: 0.5890476897138344 MCC val: 0.5283187822162626\n",
            "\n",
            "Epoch: 31\n",
            "Training loss: 0.002359353471547365 Validation loss: 0.0026374361477792263\n",
            "MCC Train: 0.5831424894822214 MCC val: 0.6058746925069677\n",
            "\n",
            "Epoch: 32\n",
            "Training loss: 0.0023265585768967867 Validation loss: 0.0025730845518410206\n",
            "MCC Train: 0.5856493360955126 MCC val: 0.5883718731096027\n",
            "\n",
            "Epoch: 33\n",
            "Training loss: 0.002260843524709344 Validation loss: 0.0025862131733447313\n",
            "MCC Train: 0.5764638943647006 MCC val: 0.541965323845131\n",
            "\n",
            "Epoch: 34\n",
            "Training loss: 0.0022562972735613585 Validation loss: 0.0025723944418132305\n",
            "MCC Train: 0.6013971689364082 MCC val: 0.5296654755269506\n",
            "\n",
            "Epoch: 35\n",
            "Training loss: 0.002204827731475234 Validation loss: 0.0027487461920827627\n",
            "MCC Train: 0.5995380325892142 MCC val: 0.5690902516895475\n",
            "\n",
            "Epoch: 36\n",
            "Training loss: 0.0022379474248737097 Validation loss: 0.0025651673786342144\n",
            "MCC Train: 0.6027864065760268 MCC val: 0.5114716356799353\n",
            "\n",
            "Epoch: 37\n",
            "Training loss: 0.0022662277333438396 Validation loss: 0.0025896502193063498\n",
            "MCC Train: 0.5999306920737149 MCC val: 0.5213070655168734\n",
            "\n",
            "Epoch: 38\n",
            "Training loss: 0.002142711542546749 Validation loss: 0.002594788558781147\n",
            "MCC Train: 0.6106249093332998 MCC val: 0.5215753088562619\n",
            "\n",
            "Epoch: 39\n",
            "Training loss: 0.002123515820130706 Validation loss: 0.003553661983460188\n",
            "MCC Train: 0.613615670243478 MCC val: 0.44998273487884566\n",
            "\n",
            "Epoch: 40\n",
            "Training loss: 0.002211257116869092 Validation loss: 0.0029348095413297415\n",
            "MCC Train: 0.6106350830684979 MCC val: 0.5952554493041363\n",
            "Early stopping\n",
            "\n",
            "0.001\t0.5\t0.0005\t2\tTrue\ttrain_losses\tearly_stopping_model_0.001_0.5_0.0005_2_True.pt\t0.0047818497,0.004477104,0.004415796,0.0042294348,0.0041216584,0.004030076,0.0039417213,0.003840175,0.0038001486,0.0037137126,0.0037081707,0.0036338824,0.0036050477,0.0034737666,0.0033917837,0.0032191612,0.003099986,0.0030385924,0.0029651353,0.002877396,0.0028438573,0.0027817432,0.0026878614,0.002582644,0.0025950992,0.0024259193,0.0024363936,0.0024113874,0.0023860005,0.0023481494,0.0023593535,0.0023265586,0.0022608435,0.0022562973,0.0022048277,0.0022379474,0.0022662277,0.0021427115,0.0021235158,0.0022112571\n",
            "\n",
            "0.001\t0.5\t0.0005\t2\tTrue\tval_losses\tearly_stopping_model_0.001_0.5_0.0005_2_True.pt\t0.003936119,0.003896522,0.0038479264,0.0037229673,0.00367898,0.0036685993,0.0036317997,0.0036201328,0.0035876934,0.003610527,0.0035813234,0.0035169353,0.0034227914,0.0035402079,0.0039301817,0.0033337015,0.0034830365,0.0031127622,0.0032954852,0.0030845846,0.002858085,0.002791255,0.0026582852,0.0025374522,0.0025549047,0.0024999748,0.0025264162,0.0025769982,0.0025811114,0.0024655857,0.0026374361,0.0025730846,0.0025862132,0.0025723944,0.0027487462,0.0025651674,0.0025896502,0.0025947886,0.003553662,0.0029348095\n",
            "\n",
            "0.001\t0.5\t0.0005\t2\tTrue\ttrain_acc\tearly_stopping_model_0.001_0.5_0.0005_2_True.pt\t0.5237182558696694,0.5268327743172018,0.5227599425011978,0.5294681360804984,0.5721130809774796,0.5905606133205559,0.6248203162434116,0.6327264015333014,0.648538572113081,0.6655486344034499,0.6818399616674653,0.6863919501677048,0.6950167704839483,0.7240057498802108,0.7515572592237661,0.7898897939626258,0.8155246765692381,0.8423574508864399,0.8564925730713944,0.8596070915189267,0.8651173933876377,0.8689506468615237,0.8706276952563489,0.8713464302827024,0.8641590800191663,0.8620028749401054,0.8512218495448012,0.8473885960709152,0.8488260661236224,0.8404408241494968,0.8370867273598467,0.8406804024916148,0.8298993770963105,0.8447532343076186,0.8397220891231433,0.8390033540967896,0.8351701006229036,0.838284619070436,0.8378054623862002,0.8342117872544322\n",
            "\n",
            "0.001\t0.5\t0.0005\t2\tTrue\tval_acc\tearly_stopping_model_0.001_0.5_0.0005_2_True.pt\t0.683420365535248,0.6677545691906005,0.7193211488250653,0.7108355091383812,0.693864229765013,0.695822454308094,0.6899477806788512,0.6788511749347258,0.7010443864229765,0.6886422976501305,0.6847258485639687,0.6951697127937336,0.7193211488250653,0.6664490861618799,0.6057441253263708,0.7480417754569191,0.7630548302872062,0.8185378590078329,0.7761096605744126,0.8296344647519582,0.8596605744125326,0.8616187989556136,0.8674934725848564,0.8655352480417755,0.8635770234986945,0.8674934725848564,0.8655352480417755,0.8590078328981723,0.8550913838120104,0.7656657963446475,0.858355091383812,0.8381201044386423,0.7878590078328982,0.779373368146214,0.8283289817232375,0.7637075718015666,0.7734986945169713,0.7852480417754569,0.7441253263707572,0.8453002610966057\n",
            "\n",
            "0.001 0.5 0.0005 3 False\n",
            "\n",
            "Epoch: 1\n",
            "Training loss: 0.011018285527825356 Validation loss: 0.009612053632736206\n",
            "MCC Train: -0.0008261383463226413 MCC val: 0.0\n",
            "\n",
            "Epoch: 2\n",
            "Training loss: 0.009788313880562782 Validation loss: 0.009643829427659512\n",
            "MCC Train: -0.003108376371777571 MCC val: 0.0\n",
            "\n",
            "Epoch: 3\n",
            "Training loss: 0.009570677764713764 Validation loss: 0.00976515468209982\n",
            "MCC Train: 0.003152428205639979 MCC val: 0.0\n",
            "\n",
            "Epoch: 4\n",
            "Training loss: 0.009351561777293682 Validation loss: 0.009869580157101154\n",
            "MCC Train: -0.008698328238096142 MCC val: 0.0\n",
            "\n",
            "Epoch: 5\n",
            "Training loss: 0.009111532010138035 Validation loss: 0.009817706421017647\n",
            "MCC Train: 0.014530995958103938 MCC val: 0.0\n",
            "\n",
            "Epoch: 6\n",
            "Training loss: 0.009268364869058132 Validation loss: 0.009795891121029854\n",
            "MCC Train: -0.02410507865011469 MCC val: 0.0\n",
            "\n",
            "Epoch: 7\n",
            "Training loss: 0.009135427884757519 Validation loss: 0.009743619710206985\n",
            "MCC Train: -0.023251294484775652 MCC val: 0.0\n",
            "\n",
            "Epoch: 8\n",
            "Training loss: 0.009020277298986912 Validation loss: 0.009704566560685635\n",
            "MCC Train: 0.012692578600914113 MCC val: 0.0\n",
            "\n",
            "Epoch: 9\n",
            "Training loss: 0.009039201773703098 Validation loss: 0.009583750739693642\n",
            "MCC Train: -0.01262890890910763 MCC val: 0.0\n",
            "\n",
            "Epoch: 10\n",
            "Training loss: 0.008911805227398872 Validation loss: 0.009417938068509102\n",
            "MCC Train: -0.021884405476620426 MCC val: 0.0\n",
            "\n",
            "Epoch: 11\n",
            "Training loss: 0.008903678506612778 Validation loss: 0.009119192138314247\n",
            "MCC Train: 0.005186039546523385 MCC val: 0.0\n",
            "\n",
            "Epoch: 12\n",
            "Training loss: 0.008778855204582214 Validation loss: 0.008933999575674534\n",
            "MCC Train: -0.00892891709241079 MCC val: 0.0\n",
            "\n",
            "Epoch: 13\n",
            "Training loss: 0.008822827599942684 Validation loss: 0.008670425973832607\n",
            "MCC Train: -0.00892891709241079 MCC val: 0.0\n",
            "\n",
            "Epoch: 14\n",
            "Training loss: 0.008563177660107613 Validation loss: 0.00846088957041502\n",
            "MCC Train: 0.02683816538716948 MCC val: 0.0\n",
            "\n",
            "Epoch: 15\n",
            "Training loss: 0.00861935131251812 Validation loss: 0.008376354351639748\n",
            "MCC Train: 0.044037547642857014 MCC val: 0.0\n",
            "\n",
            "Epoch: 16\n",
            "Training loss: 0.008457965217530727 Validation loss: 0.008188663050532341\n",
            "MCC Train: 0.032646110854007836 MCC val: 0.0\n",
            "\n",
            "Epoch: 17\n",
            "Training loss: 0.008382297120988369 Validation loss: 0.007927444763481617\n",
            "MCC Train: 0.01765475867622704 MCC val: 0.0\n",
            "\n",
            "Epoch: 18\n",
            "Training loss: 0.008257376030087471 Validation loss: 0.007934065535664558\n",
            "MCC Train: 0.07697005403605603 MCC val: 0.0\n",
            "\n",
            "Epoch: 19\n",
            "Training loss: 0.008221535012125969 Validation loss: 0.00790541060268879\n",
            "MCC Train: 0.08271131580642321 MCC val: 0.0\n",
            "\n",
            "Epoch: 20\n",
            "Training loss: 0.008277570828795433 Validation loss: 0.007930330000817776\n",
            "MCC Train: 0.0704954403205031 MCC val: 0.0\n",
            "\n",
            "Epoch: 21\n",
            "Training loss: 0.00811272207647562 Validation loss: 0.007806550711393356\n",
            "MCC Train: 0.11425888599240185 MCC val: 0.12549116102763172\n",
            "\n",
            "Epoch: 22\n",
            "Training loss: 0.008001373149454594 Validation loss: 0.007754651363939047\n",
            "MCC Train: 0.15827780629846555 MCC val: 0.22869011774113743\n",
            "\n",
            "Epoch: 23\n",
            "Training loss: 0.0080724423751235 Validation loss: 0.007754407823085785\n",
            "MCC Train: 0.1706568923228043 MCC val: 0.25878262726467627\n",
            "\n",
            "Epoch: 24\n",
            "Training loss: 0.00809470284730196 Validation loss: 0.007695743348449469\n",
            "MCC Train: 0.1742987103729519 MCC val: 0.2802956689344496\n",
            "\n",
            "Epoch: 25\n",
            "Training loss: 0.008002297952771187 Validation loss: 0.007668937090784311\n",
            "MCC Train: 0.1817583487350283 MCC val: 0.31600071782147127\n",
            "\n",
            "Epoch: 26\n",
            "Training loss: 0.007859669625759125 Validation loss: 0.007606556173413992\n",
            "MCC Train: 0.22256060469716235 MCC val: 0.37413192112552246\n",
            "\n",
            "Epoch: 27\n",
            "Training loss: 0.007752986624836922 Validation loss: 0.0075348312966525555\n",
            "MCC Train: 0.2317257546580769 MCC val: 0.3836684156226796\n",
            "\n",
            "Epoch: 28\n",
            "Training loss: 0.007768887560814619 Validation loss: 0.00745765957981348\n",
            "MCC Train: 0.2614351002831157 MCC val: 0.4066655966587818\n",
            "\n",
            "Epoch: 29\n",
            "Training loss: 0.00776963634416461 Validation loss: 0.007196842227131128\n",
            "MCC Train: 0.2626781663834376 MCC val: 0.4869119238594347\n",
            "\n",
            "Epoch: 30\n",
            "Training loss: 0.007400900591164827 Validation loss: 0.006860502064228058\n",
            "MCC Train: 0.3697277962177758 MCC val: 0.5029293347407703\n",
            "\n",
            "Epoch: 31\n",
            "Training loss: 0.007100368849933147 Validation loss: 0.006374015472829342\n",
            "MCC Train: 0.4576683214906628 MCC val: 0.5763678422129891\n",
            "\n",
            "Epoch: 32\n",
            "Training loss: 0.007046340499073267 Validation loss: 0.00631684809923172\n",
            "MCC Train: 0.502505746832301 MCC val: 0.5966299059294549\n",
            "\n",
            "Epoch: 33\n",
            "Training loss: 0.006471872795373201 Validation loss: 0.005954829044640064\n",
            "MCC Train: 0.5715354065120041 MCC val: 0.6165849656372829\n",
            "\n",
            "Epoch: 34\n",
            "Training loss: 0.006230369210243225 Validation loss: 0.005862434394657612\n",
            "MCC Train: 0.6059230278572771 MCC val: 0.6220615035776137\n",
            "\n",
            "Epoch: 35\n",
            "Training loss: 0.006009389646351337 Validation loss: 0.005592751316726208\n",
            "MCC Train: 0.6244094723066731 MCC val: 0.6284165694671031\n",
            "\n",
            "Epoch: 36\n",
            "Training loss: 0.005669554695487022 Validation loss: 0.005635374691337347\n",
            "MCC Train: 0.6406680828402288 MCC val: 0.6262025468086422\n",
            "\n",
            "Epoch: 37\n",
            "Training loss: 0.0057255178689956665 Validation loss: 0.005513257812708616\n",
            "MCC Train: 0.633991247390823 MCC val: 0.6323685338926504\n",
            "\n",
            "Epoch: 38\n",
            "Training loss: 0.005502810701727867 Validation loss: 0.005163067951798439\n",
            "MCC Train: 0.6406680828402288 MCC val: 0.6348435651236409\n",
            "\n",
            "Epoch: 39\n",
            "Training loss: 0.005528056528419256 Validation loss: 0.005209354218095541\n",
            "MCC Train: 0.6407383814989416 MCC val: 0.6344059392058772\n",
            "\n",
            "Epoch: 40\n",
            "Training loss: 0.005342592019587755 Validation loss: 0.005117385648190975\n",
            "MCC Train: 0.6606451615428243 MCC val: 0.6343350474165466\n",
            "\n",
            "Epoch: 41\n",
            "Training loss: 0.005069488659501076 Validation loss: 0.005179844796657562\n",
            "MCC Train: 0.6716390470879474 MCC val: 0.6343861553883252\n",
            "\n",
            "Epoch: 42\n",
            "Training loss: 0.005206968169659376 Validation loss: 0.005011498928070068\n",
            "MCC Train: 0.6606770774687724 MCC val: 0.6408056374292429\n",
            "\n",
            "Epoch: 43\n",
            "Training loss: 0.005151042714715004 Validation loss: 0.004996594972908497\n",
            "MCC Train: 0.6702834744186915 MCC val: 0.6363724658995444\n",
            "\n",
            "Epoch: 44\n",
            "Training loss: 0.005048968829214573 Validation loss: 0.005079589784145355\n",
            "MCC Train: 0.6657165405391848 MCC val: 0.6404402117938055\n",
            "\n",
            "Epoch: 45\n",
            "Training loss: 0.004751815460622311 Validation loss: 0.005426877643913031\n",
            "MCC Train: 0.6818938655017732 MCC val: 0.6365317470485334\n",
            "\n",
            "Epoch: 46\n",
            "Training loss: 0.004860313143581152 Validation loss: 0.005390252452343702\n",
            "MCC Train: 0.6891411308027743 MCC val: 0.6289777500621003\n",
            "\n",
            "Epoch: 47\n",
            "Training loss: 0.004774031229317188 Validation loss: 0.004997014533728361\n",
            "MCC Train: 0.6730658470195243 MCC val: 0.6545895361331764\n",
            "\n",
            "Epoch: 48\n",
            "Training loss: 0.00475891912356019 Validation loss: 0.005115111358463764\n",
            "MCC Train: 0.6787100275874283 MCC val: 0.6384012977204988\n",
            "\n",
            "Epoch: 49\n",
            "Training loss: 0.004669696558266878 Validation loss: 0.00533522991463542\n",
            "MCC Train: 0.6847212470488945 MCC val: 0.6406769525692139\n",
            "\n",
            "Epoch: 50\n",
            "Training loss: 0.004611203446984291 Validation loss: 0.005703889764845371\n",
            "MCC Train: 0.6852411831842355 MCC val: 0.6355965966466142\n",
            "0.001\t0.5\t0.0005\t3\tFalse\ttrain_losses\tearly_stopping_model_0.001_0.5_0.0005_3_False.pt\t0.0110182855,0.009788314,0.009570678,0.009351562,0.009111532,0.009268365,0.009135428,0.009020277,0.009039202,0.008911805,0.0089036785,0.008778855,0.008822828,0.008563178,0.008619351,0.008457965,0.008382297,0.008257376,0.008221535,0.008277571,0.008112722,0.008001373,0.008072442,0.008094703,0.008002298,0.00785967,0.0077529866,0.0077688876,0.0077696363,0.0074009006,0.007100369,0.0070463405,0.006471873,0.006230369,0.0060093896,0.0056695547,0.005725518,0.0055028107,0.0055280565,0.005342592,0.0050694887,0.005206968,0.0051510427,0.005048969,0.0047518155,0.004860313,0.004774031,0.004758919,0.0046696966,0.0046112034\n",
            "\n",
            "0.001\t0.5\t0.0005\t3\tFalse\tval_losses\tearly_stopping_model_0.001_0.5_0.0005_3_False.pt\t0.009612054,0.009643829,0.009765155,0.00986958,0.009817706,0.009795891,0.00974362,0.009704567,0.009583751,0.009417938,0.009119192,0.008934,0.008670426,0.00846089,0.008376354,0.008188663,0.007927445,0.007934066,0.007905411,0.00793033,0.0078065507,0.0077546514,0.007754408,0.0076957433,0.007668937,0.007606556,0.0075348313,0.0074576596,0.007196842,0.006860502,0.0063740155,0.006316848,0.005954829,0.0058624344,0.0055927513,0.0056353747,0.005513258,0.005163068,0.005209354,0.0051173856,0.005179845,0.005011499,0.004996595,0.00507959,0.0054268776,0.0053902525,0.0049970145,0.0051151114,0.00533523,0.0057038898\n",
            "\n",
            "0.001\t0.5\t0.0005\t3\tFalse\ttrain_acc\tearly_stopping_model_0.001_0.5_0.0005_3_False.pt\t0.6763296597987541,0.7163392429324389,0.73310972688069,0.7390991854336368,0.7450886439865836,0.7448490656444657,0.7458073790129373,0.7498802108289411,0.7498802108289411,0.7489218974604696,0.7501197891710589,0.7501197891710589,0.7501197891710589,0.7505989458552946,0.7510781025395304,0.7501197891710589,0.7484427407762339,0.751796837565884,0.7496406324868232,0.7494010541447054,0.7522759942501198,0.75563009103977,0.7568279827503593,0.7565884044082415,0.7568279827503593,0.7637757546717777,0.7637757546717777,0.7695256348826066,0.770723526593196,0.7946813608049832,0.8186391950167705,0.8315764254911356,0.8519405845711547,0.8624820316243411,0.8682319118351701,0.8735026353617633,0.8713464302827024,0.8735026353617633,0.8735026353617633,0.8799712505989459,0.883564925730714,0.8799712505989459,0.8830857690464782,0.881648298993771,0.8869190225203641,0.8893148059415429,0.8840440824149497,0.8859607091518926,0.8878773358888357,0.8881169142309535\n",
            "\n",
            "0.001\t0.5\t0.0005\t3\tFalse\tval_acc\tearly_stopping_model_0.001_0.5_0.0005_3_False.pt\t0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.7552219321148825,0.7656657963446475,0.7695822454308094,0.7728459530026109,0.7780678851174935,0.7898172323759791,0.793733681462141,0.8035248041775457,0.827023498694517,0.8309399477806788,0.8531331592689295,0.8590078328981723,0.8655352480417755,0.8674934725848564,0.8694516971279374,0.868798955613577,0.8707571801566579,0.8714099216710183,0.8714099216710183,0.8714099216710183,0.8714099216710183,0.8733681462140992,0.8720626631853786,0.8733681462140992,0.8720626631853786,0.8694516971279374,0.8779373368146214,0.8727154046997389,0.8733681462140992,0.8714099216710183\n",
            "\n",
            "0.001 0.5 0.0005 3 True\n",
            "loss weight 0.2496406324868232\n",
            "\n",
            "Epoch: 1\n",
            "Training loss: 0.0049149938859045506 Validation loss: 0.004062632564455271\n",
            "MCC Train: 0.006598338523254923 MCC val: 0.030157166494339218\n",
            "\n",
            "Epoch: 2\n",
            "Training loss: 0.004493672866374254 Validation loss: 0.00405830517411232\n",
            "MCC Train: 0.009959253873430853 MCC val: 0.05689312707743813\n",
            "\n",
            "Epoch: 3\n",
            "Training loss: 0.00428064726293087 Validation loss: 0.004054692108184099\n",
            "MCC Train: 0.04319455098228608 MCC val: 0.07088826169099423\n",
            "\n",
            "Epoch: 4\n",
            "Training loss: 0.004252931103110313 Validation loss: 0.004062139429152012\n",
            "MCC Train: 0.0107628344691669 MCC val: 0.10112849890932502\n",
            "\n",
            "Epoch: 5\n",
            "Training loss: 0.004209726117551327 Validation loss: 0.004058963153511286\n",
            "MCC Train: 0.017154803150575777 MCC val: 0.13162532686712802\n",
            "\n",
            "Epoch: 6\n",
            "Training loss: 0.004216991830617189 Validation loss: 0.004058524966239929\n",
            "MCC Train: -0.005018430949427863 MCC val: 0.07752215151674824\n",
            "\n",
            "Epoch: 7\n",
            "Training loss: 0.004119796212762594 Validation loss: 0.0040595633909106255\n",
            "MCC Train: 0.04032117438667699 MCC val: 0.05830152110652876\n",
            "\n",
            "Epoch: 8\n",
            "Training loss: 0.004142805002629757 Validation loss: 0.004062642343342304\n",
            "MCC Train: 0.003846490555863571 MCC val: 0.05026376923866438\n",
            "\n",
            "Epoch: 9\n",
            "Training loss: 0.004150416236370802 Validation loss: 0.004064397420734167\n",
            "MCC Train: -0.00304651185946296 MCC val: 0.051298917604257706\n",
            "\n",
            "Epoch: 10\n",
            "Training loss: 0.004127054009586573 Validation loss: 0.004065168555825949\n",
            "MCC Train: -0.002997080424325235 MCC val: 0.04896302239959312\n",
            "\n",
            "Epoch: 11\n",
            "Training loss: 0.004139235708862543 Validation loss: 0.004066047258675098\n",
            "MCC Train: 0.01104374083630331 MCC val: 0.07226565506295816\n",
            "\n",
            "Epoch: 12\n",
            "Training loss: 0.004129249136894941 Validation loss: 0.004067219793796539\n",
            "MCC Train: 0.0016598489688424104 MCC val: 0.03620243071279983\n",
            "\n",
            "Epoch: 13\n",
            "Training loss: 0.004131461959332228 Validation loss: 0.004063556436449289\n",
            "MCC Train: 0.0033344111539809623 MCC val: 0.0349735874282808\n",
            "Early stopping\n",
            "\n",
            "0.001\t0.5\t0.0005\t3\tTrue\ttrain_losses\tearly_stopping_model_0.001_0.5_0.0005_3_True.pt\t0.004914994,0.004493673,0.0042806473,0.004252931,0.004209726,0.004216992,0.004119796,0.004142805,0.0041504162,0.004127054,0.0041392357,0.004129249,0.004131462\n",
            "\n",
            "0.001\t0.5\t0.0005\t3\tTrue\tval_losses\tearly_stopping_model_0.001_0.5_0.0005_3_True.pt\t0.0040626326,0.004058305,0.004054692,0.0040621394,0.004058963,0.004058525,0.0040595634,0.0040626423,0.0040643974,0.0040651686,0.0040660473,0.00406722,0.0040635564\n",
            "\n",
            "0.001\t0.5\t0.0005\t3\tTrue\ttrain_acc\tearly_stopping_model_0.001_0.5_0.0005_3_True.pt\t0.5220412074748443,0.5057498802108289,0.514853857211308,0.5265931959750838,0.5091039770004792,0.5076665069477719,0.5471969333972209,0.5110206037374221,0.4992812649736464,0.4825107810253953,0.5301868711068519,0.5009583133684715,0.49760421657882126\n",
            "\n",
            "0.001\t0.5\t0.0005\t3\tTrue\tval_acc\tearly_stopping_model_0.001_0.5_0.0005_3_True.pt\t0.5189295039164491,0.44843342036553524,0.43342036553524804,0.402088772845953,0.49216710182767626,0.35052219321148825,0.3087467362924282,0.27284595300261094,0.25783289817232374,0.260443864229765,0.2689295039164491,0.2539164490861619,0.2591383812010444\n",
            "\n",
            "0.001 0.5 0.005 2 False\n",
            "\n",
            "Epoch: 1\n",
            "Training loss: 0.01147644966840744 Validation loss: 0.009084942750632763\n",
            "MCC Train: 0.0020575770378063103 MCC val: 0.0\n",
            "\n",
            "Epoch: 2\n",
            "Training loss: 0.010070119053125381 Validation loss: 0.009165114723145962\n",
            "MCC Train: -0.004720797444429979 MCC val: 0.0\n",
            "\n",
            "Epoch: 3\n",
            "Training loss: 0.009572772309184074 Validation loss: 0.009174413979053497\n",
            "MCC Train: 0.029160428544841948 MCC val: 0.0\n",
            "\n",
            "Epoch: 4\n",
            "Training loss: 0.009243238717317581 Validation loss: 0.00905136950314045\n",
            "MCC Train: 0.00019206897456990098 MCC val: 0.06262242910851495\n",
            "\n",
            "Epoch: 5\n",
            "Training loss: 0.00888002011924982 Validation loss: 0.008702615275979042\n",
            "MCC Train: 0.10387286718228463 MCC val: 0.2791107306576949\n",
            "\n",
            "Epoch: 6\n",
            "Training loss: 0.008751621469855309 Validation loss: 0.008681061677634716\n",
            "MCC Train: 0.12792643067113108 MCC val: 0.290836793265551\n",
            "\n",
            "Epoch: 7\n",
            "Training loss: 0.008339771069586277 Validation loss: 0.008362987078726292\n",
            "MCC Train: 0.16115621441750935 MCC val: 0.3280611079912318\n",
            "\n",
            "Epoch: 8\n",
            "Training loss: 0.00826241634786129 Validation loss: 0.008141283877193928\n",
            "MCC Train: 0.15725753819338367 MCC val: 0.3819479201530079\n",
            "\n",
            "Epoch: 9\n",
            "Training loss: 0.008106631226837635 Validation loss: 0.00791739858686924\n",
            "MCC Train: 0.17785995578718794 MCC val: 0.3709839952422462\n",
            "\n",
            "Epoch: 10\n",
            "Training loss: 0.008209004066884518 Validation loss: 0.007792986463755369\n",
            "MCC Train: 0.2126255791997053 MCC val: 0.3881553311838754\n",
            "\n",
            "Epoch: 11\n",
            "Training loss: 0.008053184486925602 Validation loss: 0.007781037595123053\n",
            "MCC Train: 0.19727755336480446 MCC val: 0.3709851622136654\n",
            "\n",
            "Epoch: 12\n",
            "Training loss: 0.007952908053994179 Validation loss: 0.0077857356518507\n",
            "MCC Train: 0.22216560591684575 MCC val: 0.3593243900086467\n",
            "\n",
            "Epoch: 13\n",
            "Training loss: 0.007906406186521053 Validation loss: 0.0076516056433320045\n",
            "MCC Train: 0.1993406666938739 MCC val: 0.37899575588922535\n",
            "\n",
            "Epoch: 14\n",
            "Training loss: 0.0078113083727657795 Validation loss: 0.007668498903512955\n",
            "MCC Train: 0.2511270063708028 MCC val: 0.34615568494292526\n",
            "\n",
            "Epoch: 15\n",
            "Training loss: 0.00791086070239544 Validation loss: 0.007601409684866667\n",
            "MCC Train: 0.1971518914779956 MCC val: 0.36423890980543533\n",
            "\n",
            "Epoch: 16\n",
            "Training loss: 0.007652327883988619 Validation loss: 0.0075160362757742405\n",
            "MCC Train: 0.28419136580865667 MCC val: 0.3574794565836809\n",
            "\n",
            "Epoch: 17\n",
            "Training loss: 0.007607833947986364 Validation loss: 0.007458994165062904\n",
            "MCC Train: 0.2833607275184805 MCC val: 0.3864634590332683\n",
            "\n",
            "Epoch: 18\n",
            "Training loss: 0.007592913694679737 Validation loss: 0.0073995706625282764\n",
            "MCC Train: 0.30475458135960226 MCC val: 0.40132774546774375\n",
            "\n",
            "Epoch: 19\n",
            "Training loss: 0.007511748932301998 Validation loss: 0.007470086216926575\n",
            "MCC Train: 0.33371086211927165 MCC val: 0.38397679973183324\n",
            "\n",
            "Epoch: 20\n",
            "Training loss: 0.007567630149424076 Validation loss: 0.007386462297290564\n",
            "MCC Train: 0.32529299809315915 MCC val: 0.4209540248235484\n",
            "\n",
            "Epoch: 21\n",
            "Training loss: 0.007427557371556759 Validation loss: 0.007222503889352083\n",
            "MCC Train: 0.3440949490277047 MCC val: 0.4439438890384142\n",
            "\n",
            "Epoch: 22\n",
            "Training loss: 0.007242277730256319 Validation loss: 0.006800146773457527\n",
            "MCC Train: 0.41899290808955536 MCC val: 0.5349980469279475\n",
            "\n",
            "Epoch: 23\n",
            "Training loss: 0.006650951690971851 Validation loss: 0.0063042775727808475\n",
            "MCC Train: 0.5389918815094252 MCC val: 0.5904660571821411\n",
            "\n",
            "Epoch: 24\n",
            "Training loss: 0.006155829876661301 Validation loss: 0.005768988281488419\n",
            "MCC Train: 0.5880478320349821 MCC val: 0.6223653576261464\n",
            "\n",
            "Epoch: 25\n",
            "Training loss: 0.0059991925954818726 Validation loss: 0.005766114220023155\n",
            "MCC Train: 0.6043934150567052 MCC val: 0.6357185310769162\n",
            "\n",
            "Epoch: 26\n",
            "Training loss: 0.005856441333889961 Validation loss: 0.005782256834208965\n",
            "MCC Train: 0.6269648127282227 MCC val: 0.628435501316599\n",
            "\n",
            "Epoch: 27\n",
            "Training loss: 0.005815813317894936 Validation loss: 0.005671386606991291\n",
            "MCC Train: 0.6269411372480976 MCC val: 0.6266952564844417\n",
            "\n",
            "Epoch: 28\n",
            "Training loss: 0.005724915768951178 Validation loss: 0.005760366562753916\n",
            "MCC Train: 0.6239839356076454 MCC val: 0.6251338039823406\n",
            "\n",
            "Epoch: 29\n",
            "Training loss: 0.00553031824529171 Validation loss: 0.0056604123674333096\n",
            "MCC Train: 0.6374893788899523 MCC val: 0.6321367790689184\n",
            "\n",
            "Epoch: 30\n",
            "Training loss: 0.005583041347563267 Validation loss: 0.005784862674772739\n",
            "MCC Train: 0.6322919656154937 MCC val: 0.618732735033372\n",
            "\n",
            "Epoch: 31\n",
            "Training loss: 0.005517156794667244 Validation loss: 0.00550968199968338\n",
            "MCC Train: 0.6429676401553284 MCC val: 0.6384268315372955\n",
            "\n",
            "Epoch: 32\n",
            "Training loss: 0.005495336838066578 Validation loss: 0.005592183209955692\n",
            "MCC Train: 0.6344345811122941 MCC val: 0.6264123181997561\n",
            "\n",
            "Epoch: 33\n",
            "Training loss: 0.0054108090698719025 Validation loss: 0.005632147658616304\n",
            "MCC Train: 0.640409723682416 MCC val: 0.6324080646415321\n",
            "\n",
            "Epoch: 34\n",
            "Training loss: 0.00538633344694972 Validation loss: 0.00567654799669981\n",
            "MCC Train: 0.6489706696183759 MCC val: 0.6178620943710773\n",
            "\n",
            "Epoch: 35\n",
            "Training loss: 0.005534980446100235 Validation loss: 0.005484890192747116\n",
            "MCC Train: 0.6434352530816865 MCC val: 0.6424934615378488\n",
            "\n",
            "Epoch: 36\n",
            "Training loss: 0.005556061863899231 Validation loss: 0.005615840200334787\n",
            "MCC Train: 0.6392502105744772 MCC val: 0.6187835911074775\n",
            "\n",
            "Epoch: 37\n",
            "Training loss: 0.005423181690275669 Validation loss: 0.005563401151448488\n",
            "MCC Train: 0.6526230726737695 MCC val: 0.6384334157994912\n",
            "\n",
            "Epoch: 38\n",
            "Training loss: 0.005414634943008423 Validation loss: 0.005449927411973476\n",
            "MCC Train: 0.6471485362574424 MCC val: 0.6354988201412477\n",
            "\n",
            "Epoch: 39\n",
            "Training loss: 0.005280615296214819 Validation loss: 0.00561684463173151\n",
            "MCC Train: 0.6501009628056711 MCC val: 0.6312479919128782\n",
            "\n",
            "Epoch: 40\n",
            "Training loss: 0.005216781981289387 Validation loss: 0.005691048223525286\n",
            "MCC Train: 0.6524165418045582 MCC val: 0.622554320127237\n",
            "\n",
            "Epoch: 41\n",
            "Training loss: 0.005265156272798777 Validation loss: 0.00541705684736371\n",
            "MCC Train: 0.6740386322823004 MCC val: 0.6364011156988161\n",
            "\n",
            "Epoch: 42\n",
            "Training loss: 0.005208179354667664 Validation loss: 0.005628911778330803\n",
            "MCC Train: 0.6611650661898029 MCC val: 0.628435501316599\n",
            "\n",
            "Epoch: 43\n",
            "Training loss: 0.005244325380772352 Validation loss: 0.005585784558206797\n",
            "MCC Train: 0.6621116656784076 MCC val: 0.6285067199093326\n",
            "\n",
            "Epoch: 44\n",
            "Training loss: 0.005249653477221727 Validation loss: 0.005612990818917751\n",
            "MCC Train: 0.6604394893707826 MCC val: 0.6340826832786819\n",
            "\n",
            "Epoch: 45\n",
            "Training loss: 0.005251523572951555 Validation loss: 0.005378392990678549\n",
            "MCC Train: 0.6606229955280416 MCC val: 0.658673883664213\n",
            "\n",
            "Epoch: 46\n",
            "Training loss: 0.005215950310230255 Validation loss: 0.005738311447203159\n",
            "MCC Train: 0.6640871064332988 MCC val: 0.6268491793801112\n",
            "\n",
            "Epoch: 47\n",
            "Training loss: 0.005172267556190491 Validation loss: 0.005384749732911587\n",
            "MCC Train: 0.6785222976567412 MCC val: 0.6344059392058772\n",
            "\n",
            "Epoch: 48\n",
            "Training loss: 0.005117999855428934 Validation loss: 0.005686870310455561\n",
            "MCC Train: 0.6677735772706394 MCC val: 0.6223556368755943\n",
            "\n",
            "Epoch: 49\n",
            "Training loss: 0.00510399928316474 Validation loss: 0.005389425903558731\n",
            "MCC Train: 0.6568870068770577 MCC val: 0.632585170259588\n",
            "\n",
            "Epoch: 50\n",
            "Training loss: 0.0050314865075051785 Validation loss: 0.005519676022231579\n",
            "MCC Train: 0.6648547118076925 MCC val: 0.6371623554162409\n",
            "0.001\t0.5\t0.005\t2\tFalse\ttrain_losses\tearly_stopping_model_0.001_0.5_0.005_2_False.pt\t0.01147645,0.010070119,0.009572772,0.009243239,0.00888002,0.0087516215,0.008339771,0.008262416,0.008106631,0.008209004,0.0080531845,0.007952908,0.007906406,0.0078113084,0.007910861,0.007652328,0.007607834,0.0075929137,0.007511749,0.00756763,0.0074275574,0.0072422777,0.0066509517,0.00615583,0.0059991926,0.0058564413,0.0058158133,0.005724916,0.0055303182,0.0055830413,0.005517157,0.005495337,0.005410809,0.0053863334,0.0055349804,0.005556062,0.0054231817,0.005414635,0.0052806153,0.005216782,0.0052651563,0.0052081794,0.0052443254,0.0052496535,0.0052515236,0.0052159503,0.0051722676,0.005118,0.0051039993,0.0050314865\n",
            "\n",
            "0.001\t0.5\t0.005\t2\tFalse\tval_losses\tearly_stopping_model_0.001_0.5_0.005_2_False.pt\t0.009084943,0.009165115,0.009174414,0.0090513695,0.008702615,0.008681062,0.008362987,0.008141284,0.007917399,0.0077929865,0.0077810376,0.0077857357,0.0076516056,0.007668499,0.0076014097,0.0075160363,0.007458994,0.0073995707,0.007470086,0.0073864623,0.007222504,0.006800147,0.0063042776,0.0057689883,0.005766114,0.005782257,0.0056713866,0.0057603666,0.0056604124,0.0057848627,0.005509682,0.005592183,0.0056321477,0.005676548,0.00548489,0.00561584,0.005563401,0.0054499274,0.0056168446,0.005691048,0.005417057,0.005628912,0.0055857846,0.005612991,0.005378393,0.0057383114,0.0053847497,0.0056868703,0.005389426,0.005519676\n",
            "\n",
            "0.001\t0.5\t0.005\t2\tFalse\ttrain_acc\tearly_stopping_model_0.001_0.5_0.005_2_False.pt\t0.6092477240057499,0.697412553905127,0.7247244849065645,0.7249640632486823,0.7472448490656445,0.7484427407762339,0.7498802108289411,0.7465261140392908,0.7529947292764734,0.7592237661715381,0.7577862961188309,0.7637757546717777,0.7568279827503593,0.7666506947771922,0.7580258744609487,0.7735984666986104,0.7731193100143747,0.7783900335409679,0.7836607570675611,0.7803066602779108,0.7865356971729756,0.8068998562529948,0.842117872544322,0.8569717297556301,0.8620028749401054,0.8691902252036416,0.8691902252036416,0.8682319118351701,0.8725443219932918,0.8708672735984667,0.8742213703881169,0.8715860086248203,0.8735026353617633,0.8761379971250599,0.8744609487302348,0.8730234786775275,0.8773358888356493,0.8756588404408242,0.8766171538092956,0.8773358888356493,0.8842836607570675,0.8802108289410637,0.8804504072831816,0.8799712505989459,0.879731672256828,0.8811691423095352,0.8857211308097748,0.8823670340201246,0.8787733588883565,0.8814087206516531\n",
            "\n",
            "0.001\t0.5\t0.005\t2\tFalse\tval_acc\tearly_stopping_model_0.001_0.5_0.005_2_False.pt\t0.75,0.75,0.75,0.7513054830287206,0.7571801566579635,0.7349869451697127,0.72911227154047,0.7630548302872062,0.7637075718015666,0.7787206266318538,0.7898172323759791,0.7872062663185379,0.7904699738903395,0.7748041775456919,0.79177545691906,0.7859007832898173,0.7930809399477807,0.8028720626631853,0.7996083550913838,0.8080939947780679,0.8152741514360313,0.8400783289817232,0.856396866840731,0.8674934725848564,0.8707571801566579,0.8681462140992167,0.868798955613577,0.8681462140992167,0.8701044386422977,0.8648825065274152,0.8727154046997389,0.8674934725848564,0.8701044386422977,0.8648825065274152,0.8733681462140992,0.8655352480417755,0.8727154046997389,0.8714099216710183,0.8701044386422977,0.8674934725848564,0.8720626631853786,0.8681462140992167,0.8694516971279374,0.8701044386422977,0.8792428198433421,0.8674934725848564,0.8714099216710183,0.8661879895561357,0.8707571801566579,0.8720626631853786\n",
            "\n",
            "0.001 0.5 0.005 2 True\n",
            "loss weight 0.2496406324868232\n",
            "\n",
            "Epoch: 1\n",
            "Training loss: 0.0049915611743927 Validation loss: 0.004064733162522316\n",
            "MCC Train: 0.012106899319253211 MCC val: 0.044960171225304484\n",
            "\n",
            "Epoch: 2\n",
            "Training loss: 0.0044669052585959435 Validation loss: 0.004040352068841457\n",
            "MCC Train: 0.02988072644212055 MCC val: 0.0543961138140183\n",
            "\n",
            "Epoch: 3\n",
            "Training loss: 0.0043380288407206535 Validation loss: 0.004025333095341921\n",
            "MCC Train: 0.040458029365527566 MCC val: 0.07296476482485542\n",
            "\n",
            "Epoch: 4\n",
            "Training loss: 0.004283279180526733 Validation loss: 0.004020838066935539\n",
            "MCC Train: 0.016336970693492704 MCC val: 0.07312013336273634\n",
            "\n",
            "Epoch: 5\n",
            "Training loss: 0.004153072834014893 Validation loss: 0.00404631020501256\n",
            "MCC Train: 0.07029639457641126 MCC val: 0.0677468194086346\n",
            "\n",
            "Epoch: 6\n",
            "Training loss: 0.004085540305823088 Validation loss: 0.003959950990974903\n",
            "MCC Train: 0.09277029115113539 MCC val: 0.14413941533896207\n",
            "\n",
            "Epoch: 7\n",
            "Training loss: 0.003968029282987118 Validation loss: 0.003826645202934742\n",
            "MCC Train: 0.1503335992378757 MCC val: 0.23009659050366282\n",
            "\n",
            "Epoch: 8\n",
            "Training loss: 0.003894422436133027 Validation loss: 0.0037355783861130476\n",
            "MCC Train: 0.20184307562669648 MCC val: 0.29876790672625225\n",
            "\n",
            "Epoch: 9\n",
            "Training loss: 0.0038021637592464685 Validation loss: 0.0036382232792675495\n",
            "MCC Train: 0.2448527889750567 MCC val: 0.32815607538802233\n",
            "\n",
            "Epoch: 10\n",
            "Training loss: 0.0037235869094729424 Validation loss: 0.0035940618254244328\n",
            "MCC Train: 0.29609276610372975 MCC val: 0.31473399410970715\n",
            "\n",
            "Epoch: 11\n",
            "Training loss: 0.0036988744977861643 Validation loss: 0.00359515892341733\n",
            "MCC Train: 0.3169034467097308 MCC val: 0.3130731254673687\n",
            "\n",
            "Epoch: 12\n",
            "Training loss: 0.00364508293569088 Validation loss: 0.003511388786137104\n",
            "MCC Train: 0.3209990626156121 MCC val: 0.3436292912153959\n",
            "\n",
            "Epoch: 13\n",
            "Training loss: 0.0036476736422628164 Validation loss: 0.003517762292176485\n",
            "MCC Train: 0.33965148919233507 MCC val: 0.3711841754206971\n",
            "\n",
            "Epoch: 14\n",
            "Training loss: 0.003620798932388425 Validation loss: 0.0035527313593775034\n",
            "MCC Train: 0.33783691449235026 MCC val: 0.3736147596295658\n",
            "\n",
            "Epoch: 15\n",
            "Training loss: 0.003580634482204914 Validation loss: 0.003485847730189562\n",
            "MCC Train: 0.3487400034920496 MCC val: 0.3606505226238911\n",
            "\n",
            "Epoch: 16\n",
            "Training loss: 0.003566734492778778 Validation loss: 0.0034601183142513037\n",
            "MCC Train: 0.3529620508741635 MCC val: 0.3698053260033478\n",
            "\n",
            "Epoch: 17\n",
            "Training loss: 0.0035581730771809816 Validation loss: 0.003458122257143259\n",
            "MCC Train: 0.35064067116491127 MCC val: 0.3669797167529786\n",
            "\n",
            "Epoch: 18\n",
            "Training loss: 0.003515320597216487 Validation loss: 0.003415388986468315\n",
            "MCC Train: 0.3683484546644845 MCC val: 0.3988449352037953\n",
            "\n",
            "Epoch: 19\n",
            "Training loss: 0.003528430825099349 Validation loss: 0.0034042622428387403\n",
            "MCC Train: 0.36565225794564443 MCC val: 0.39353418513409333\n",
            "\n",
            "Epoch: 20\n",
            "Training loss: 0.003509583417326212 Validation loss: 0.0034356534015387297\n",
            "MCC Train: 0.3640782076151901 MCC val: 0.37614940129292146\n",
            "\n",
            "Epoch: 21\n",
            "Training loss: 0.003472933080047369 Validation loss: 0.0034092478454113007\n",
            "MCC Train: 0.37813677668703694 MCC val: 0.39353418513409333\n",
            "\n",
            "Epoch: 22\n",
            "Training loss: 0.0034675265196710825 Validation loss: 0.0034628878347575665\n",
            "MCC Train: 0.37489690008240073 MCC val: 0.4132878037417533\n",
            "\n",
            "Epoch: 23\n",
            "Training loss: 0.003461923450231552 Validation loss: 0.0034579038619995117\n",
            "MCC Train: 0.3646294962558531 MCC val: 0.3930892759220638\n",
            "\n",
            "Epoch: 24\n",
            "Training loss: 0.0033638321328908205 Validation loss: 0.0034384867176413536\n",
            "MCC Train: 0.40984986889277114 MCC val: 0.42969821140618936\n",
            "\n",
            "Epoch: 25\n",
            "Training loss: 0.0034143852535635233 Validation loss: 0.0033912661019712687\n",
            "MCC Train: 0.3767816108503697 MCC val: 0.39185457057009876\n",
            "\n",
            "Epoch: 26\n",
            "Training loss: 0.0033716419711709023 Validation loss: 0.003401105524972081\n",
            "MCC Train: 0.37489690008240073 MCC val: 0.41662754119903106\n",
            "\n",
            "Epoch: 27\n",
            "Training loss: 0.0033753938041627407 Validation loss: 0.003525559324771166\n",
            "MCC Train: 0.40436020282334556 MCC val: 0.4348384063604384\n",
            "\n",
            "Epoch: 28\n",
            "Training loss: 0.0033729171846061945 Validation loss: 0.003444792702794075\n",
            "MCC Train: 0.3894863966039969 MCC val: 0.45793449155800414\n",
            "\n",
            "Epoch: 29\n",
            "Training loss: 0.003280793549492955 Validation loss: 0.003351720981299877\n",
            "MCC Train: 0.4032671691860933 MCC val: 0.4022568471299926\n",
            "\n",
            "Epoch: 30\n",
            "Training loss: 0.0033168820664286613 Validation loss: 0.0035039428621530533\n",
            "MCC Train: 0.4053384265961728 MCC val: 0.2978812861284103\n",
            "\n",
            "Epoch: 31\n",
            "Training loss: 0.0033289326820522547 Validation loss: 0.0033500909339636564\n",
            "MCC Train: 0.41399254304107547 MCC val: 0.46422974835662917\n",
            "\n",
            "Epoch: 32\n",
            "Training loss: 0.003327122889459133 Validation loss: 0.0033459903206676245\n",
            "MCC Train: 0.39566837915476877 MCC val: 0.4389597089132213\n",
            "\n",
            "Epoch: 33\n",
            "Training loss: 0.0032609396148473024 Validation loss: 0.0033023643773049116\n",
            "MCC Train: 0.4219990106617003 MCC val: 0.3978262356927536\n",
            "\n",
            "Epoch: 34\n",
            "Training loss: 0.0032859898637980223 Validation loss: 0.004001910332590342\n",
            "MCC Train: 0.4242838254396365 MCC val: 0.3702843253317676\n",
            "\n",
            "Epoch: 35\n",
            "Training loss: 0.003225459484383464 Validation loss: 0.0033212080597877502\n",
            "MCC Train: 0.42957498356997953 MCC val: 0.4849210456674254\n",
            "\n",
            "Epoch: 36\n",
            "Training loss: 0.003227927489206195 Validation loss: 0.0032945165876299143\n",
            "MCC Train: 0.4143330391787147 MCC val: 0.45862666503447713\n",
            "\n",
            "Epoch: 37\n",
            "Training loss: 0.003238915465772152 Validation loss: 0.0034955935552716255\n",
            "MCC Train: 0.42953770383049994 MCC val: 0.28906266273857767\n",
            "\n",
            "Epoch: 38\n",
            "Training loss: 0.00322892889380455 Validation loss: 0.0032355848234146833\n",
            "MCC Train: 0.4293591385304287 MCC val: 0.4082741579992568\n",
            "\n",
            "Epoch: 39\n",
            "Training loss: 0.0031823646277189255 Validation loss: 0.003309488296508789\n",
            "MCC Train: 0.44415148017313655 MCC val: 0.37849778101836956\n",
            "\n",
            "Epoch: 40\n",
            "Training loss: 0.0032011831644922495 Validation loss: 0.003431932767853141\n",
            "MCC Train: 0.4408803443613122 MCC val: 0.46772141946463475\n",
            "\n",
            "Epoch: 41\n",
            "Training loss: 0.003166909096762538 Validation loss: 0.0034377509728074074\n",
            "MCC Train: 0.4519022850952932 MCC val: 0.42213833944961066\n",
            "\n",
            "Epoch: 42\n",
            "Training loss: 0.003069451078772545 Validation loss: 0.003370165592059493\n",
            "MCC Train: 0.4613651001621912 MCC val: 0.32115520385264945\n",
            "\n",
            "Epoch: 43\n",
            "Training loss: 0.0031698031816631556 Validation loss: 0.0033343620598316193\n",
            "MCC Train: 0.45096721132684026 MCC val: 0.34577512135730937\n",
            "\n",
            "Epoch: 44\n",
            "Training loss: 0.0031597972847521305 Validation loss: 0.0033708433620631695\n",
            "MCC Train: 0.4614769559350985 MCC val: 0.3173189653803379\n",
            "\n",
            "Epoch: 45\n",
            "Training loss: 0.0030805894639343023 Validation loss: 0.003912203013896942\n",
            "MCC Train: 0.4686591646250078 MCC val: 0.3935356234774161\n",
            "\n",
            "Epoch: 46\n",
            "Training loss: 0.0031220335513353348 Validation loss: 0.00322214188054204\n",
            "MCC Train: 0.4566237429373708 MCC val: 0.4746290701639722\n",
            "\n",
            "Epoch: 47\n",
            "Training loss: 0.003060727845877409 Validation loss: 0.0032902713865041733\n",
            "MCC Train: 0.4654747583477798 MCC val: 0.46425033598559773\n",
            "\n",
            "Epoch: 48\n",
            "Training loss: 0.0030775631312280893 Validation loss: 0.0032317349687218666\n",
            "MCC Train: 0.4347090772213452 MCC val: 0.45198932579853485\n",
            "\n",
            "Epoch: 49\n",
            "Training loss: 0.0030856451485306025 Validation loss: 0.0032370213884860277\n",
            "MCC Train: 0.44356354320726 MCC val: 0.4510313023364345\n",
            "\n",
            "Epoch: 50\n",
            "Training loss: 0.003047704230993986 Validation loss: 0.0032474373001605272\n",
            "MCC Train: 0.47352074053559284 MCC val: 0.4745484029793521\n",
            "0.001\t0.5\t0.005\t2\tTrue\ttrain_losses\tearly_stopping_model_0.001_0.5_0.005_2_True.pt\t0.004991561,0.0044669053,0.004338029,0.004283279,0.004153073,0.0040855403,0.0039680293,0.0038944224,0.0038021638,0.003723587,0.0036988745,0.003645083,0.0036476736,0.003620799,0.0035806345,0.0035667345,0.003558173,0.0035153206,0.0035284308,0.0035095834,0.003472933,0.0034675265,0.0034619235,0.0033638321,0.0034143853,0.003371642,0.0033753938,0.0033729172,0.0032807935,0.003316882,0.0033289327,0.003327123,0.0032609396,0.0032859899,0.0032254595,0.0032279275,0.0032389155,0.003228929,0.0031823646,0.0032011832,0.003166909,0.003069451,0.0031698032,0.0031597973,0.0030805895,0.0031220336,0.0030607278,0.0030775631,0.0030856451,0.0030477042\n",
            "\n",
            "0.001\t0.5\t0.005\t2\tTrue\tval_losses\tearly_stopping_model_0.001_0.5_0.005_2_True.pt\t0.004064733,0.004040352,0.004025333,0.004020838,0.00404631,0.003959951,0.0038266452,0.0037355784,0.0036382233,0.0035940618,0.003595159,0.0035113888,0.0035177623,0.0035527314,0.0034858477,0.0034601183,0.0034581223,0.003415389,0.0034042622,0.0034356534,0.0034092478,0.0034628878,0.0034579039,0.0034384867,0.003391266,0.0034011055,0.0035255593,0.0034447927,0.003351721,0.0035039429,0.003350091,0.0033459903,0.0033023644,0.0040019103,0.003321208,0.0032945166,0.0034955936,0.0032355848,0.0033094883,0.0034319328,0.003437751,0.0033701656,0.003334362,0.0033708434,0.003912203,0.0032221419,0.0032902714,0.003231735,0.0032370214,0.0032474373\n",
            "\n",
            "0.001\t0.5\t0.005\t2\tTrue\ttrain_acc\tearly_stopping_model_0.001_0.5_0.005_2_True.pt\t0.5706756109247724,0.5182079540009583,0.5359367513176809,0.5050311451844753,0.5344992812649736,0.53378054623862,0.560134163871586,0.6030186871106852,0.6291327264015333,0.659798754192621,0.6775275515093435,0.686152371825587,0.6990896022999521,0.6995687589841878,0.7072352659319597,0.7081935793004313,0.7110685194058457,0.7223287014853857,0.7220891231432679,0.7189746046957355,0.7225682798275036,0.7216099664590321,0.7213703881169142,0.7414949688548155,0.7232870148538572,0.7216099664590321,0.7338284619070436,0.736942980354576,0.7388596070915189,0.7393387637757547,0.7467656923814088,0.7326305701964543,0.7429324389075228,0.7491614758025874,0.74436990896023,0.7426928605654048,0.751796837565884,0.7522759942501198,0.75563009103977,0.7573071394345952,0.7625778629611883,0.7673694298035457,0.761379971250599,0.7628174413033062,0.7625778629611883,0.7642549113560134,0.7666506947771922,0.7534738859607092,0.7505989458552946,0.7661715380929564\n",
            "\n",
            "0.001\t0.5\t0.005\t2\tTrue\tval_acc\tearly_stopping_model_0.001_0.5_0.005_2_True.pt\t0.2748041775456919,0.27872062663185376,0.30809399477806787,0.31201044386422977,0.2754569190600522,0.42493472584856395,0.5620104438642297,0.6560052219321149,0.6951697127937336,0.6677545691906005,0.6827676240208878,0.7036553524804178,0.7362924281984334,0.7493472584856397,0.7232375979112271,0.7278067885117493,0.7284595300261096,0.7480417754569191,0.7421671018276762,0.7395561357702349,0.7421671018276762,0.7715404699738904,0.7617493472584856,0.7715404699738904,0.7434725848563969,0.7787206266318538,0.8002610966057441,0.8035248041775457,0.7389033942558747,0.6090078328981723,0.7996083550913838,0.7806788511749347,0.7349869451697127,0.7969973890339426,0.8054830287206266,0.7859007832898173,0.6024804177545692,0.7421671018276762,0.7036553524804178,0.8080939947780679,0.7924281984334204,0.6442558746736292,0.6638381201044387,0.6383812010443864,0.8022193211488251,0.7878590078328982,0.7885117493472585,0.7721932114882507,0.77088772845953,0.8015665796344648\n",
            "\n",
            "0.001 0.5 0.005 3 False\n",
            "\n",
            "Epoch: 1\n",
            "Training loss: 0.011625275015830994 Validation loss: 0.009756212122738361\n",
            "MCC Train: 0.017121384708804605 MCC val: 0.0\n",
            "\n",
            "Epoch: 2\n",
            "Training loss: 0.009911492466926575 Validation loss: 0.009614300914108753\n",
            "MCC Train: -0.03357714670457123 MCC val: 0.0\n",
            "\n",
            "Epoch: 3\n",
            "Training loss: 0.009563412517309189 Validation loss: 0.009887589141726494\n",
            "MCC Train: -0.026748017149289132 MCC val: 0.0\n",
            "\n",
            "Epoch: 4\n",
            "Training loss: 0.009348875842988491 Validation loss: 0.009610842913389206\n",
            "MCC Train: -0.007602023629524602 MCC val: 0.0\n",
            "\n",
            "Epoch: 5\n",
            "Training loss: 0.009153394028544426 Validation loss: 0.009698905050754547\n",
            "MCC Train: 0.022507996071876105 MCC val: 0.0\n",
            "\n",
            "Epoch: 6\n",
            "Training loss: 0.008991937153041363 Validation loss: 0.009512141346931458\n",
            "MCC Train: 0.007336806442577801 MCC val: 0.0\n",
            "\n",
            "Epoch: 7\n",
            "Training loss: 0.008929693140089512 Validation loss: 0.009128225967288017\n",
            "MCC Train: 0.005186039546523385 MCC val: 0.0\n",
            "\n",
            "Epoch: 8\n",
            "Training loss: 0.008782893419265747 Validation loss: 0.00864898320287466\n",
            "MCC Train: 0.0 MCC val: 0.0\n",
            "\n",
            "Epoch: 9\n",
            "Training loss: 0.008531393483281136 Validation loss: 0.008398272097110748\n",
            "MCC Train: -0.01262890890910763 MCC val: 0.0\n",
            "\n",
            "Epoch: 10\n",
            "Training loss: 0.008409664034843445 Validation loss: 0.008048138581216335\n",
            "MCC Train: -0.00892891709241079 MCC val: 0.0\n",
            "\n",
            "Epoch: 11\n",
            "Training loss: 0.008275247178971767 Validation loss: 0.008005562238395214\n",
            "MCC Train: 0.0179156893121562 MCC val: 0.0\n",
            "\n",
            "Epoch: 12\n",
            "Training loss: 0.008146552368998528 Validation loss: 0.008000456728041172\n",
            "MCC Train: 0.0527056053489152 MCC val: 0.0\n",
            "\n",
            "Epoch: 13\n",
            "Training loss: 0.00817140843719244 Validation loss: 0.007853815332055092\n",
            "MCC Train: 0.04198181077061537 MCC val: 0.0\n",
            "\n",
            "Epoch: 14\n",
            "Training loss: 0.007949473336338997 Validation loss: 0.00783015787601471\n",
            "MCC Train: 0.08315922293098146 MCC val: 0.0\n",
            "\n",
            "Epoch: 15\n",
            "Training loss: 0.008036420680582523 Validation loss: 0.007689891383051872\n",
            "MCC Train: 0.12975076657740664 MCC val: 0.0\n",
            "\n",
            "Epoch: 16\n",
            "Training loss: 0.007969257421791553 Validation loss: 0.007687753066420555\n",
            "MCC Train: 0.12952696627073235 MCC val: 0.07672157539313466\n",
            "\n",
            "Epoch: 17\n",
            "Training loss: 0.007815561257302761 Validation loss: 0.007609364110976458\n",
            "MCC Train: 0.15635964148320478 MCC val: 0.26723960044982664\n",
            "\n",
            "Epoch: 18\n",
            "Training loss: 0.0077474829740822315 Validation loss: 0.0076559167355299\n",
            "MCC Train: 0.1870134699174963 MCC val: 0.40236180715646214\n",
            "\n",
            "Epoch: 19\n",
            "Training loss: 0.007736001163721085 Validation loss: 0.007609478663653135\n",
            "MCC Train: 0.19984024901427921 MCC val: 0.32453180905962586\n",
            "\n",
            "Epoch: 20\n",
            "Training loss: 0.007711940445005894 Validation loss: 0.007568574044853449\n",
            "MCC Train: 0.25335203870296014 MCC val: 0.32860857350952577\n",
            "\n",
            "Epoch: 21\n",
            "Training loss: 0.007718070410192013 Validation loss: 0.007598533295094967\n",
            "MCC Train: 0.24581229011236314 MCC val: 0.3682875332429917\n",
            "\n",
            "Epoch: 22\n",
            "Training loss: 0.007705693133175373 Validation loss: 0.007477212697267532\n",
            "MCC Train: 0.23186553422019165 MCC val: 0.35642195146286737\n",
            "\n",
            "Epoch: 23\n",
            "Training loss: 0.007584140170365572 Validation loss: 0.007442954462021589\n",
            "MCC Train: 0.27888377658472857 MCC val: 0.38115918773044044\n",
            "\n",
            "Epoch: 24\n",
            "Training loss: 0.007543046027421951 Validation loss: 0.007326674647629261\n",
            "MCC Train: 0.27621841157250904 MCC val: 0.3879308251268715\n",
            "\n",
            "Epoch: 25\n",
            "Training loss: 0.007326657418161631 Validation loss: 0.007521686609834433\n",
            "MCC Train: 0.322554578102717 MCC val: 0.2945137539309163\n",
            "\n",
            "Epoch: 26\n",
            "Training loss: 0.0074373530223965645 Validation loss: 0.00741800619289279\n",
            "MCC Train: 0.3320352316897927 MCC val: 0.38070591723724534\n",
            "\n",
            "Epoch: 27\n",
            "Training loss: 0.007215263321995735 Validation loss: 0.007251092232763767\n",
            "MCC Train: 0.3665294643421035 MCC val: 0.4494866662691324\n",
            "\n",
            "Epoch: 28\n",
            "Training loss: 0.007368935272097588 Validation loss: 0.007246786262840033\n",
            "MCC Train: 0.3681682034809648 MCC val: 0.35612782426827333\n",
            "\n",
            "Epoch: 29\n",
            "Training loss: 0.0072886766865849495 Validation loss: 0.00711998762562871\n",
            "MCC Train: 0.3800117791013039 MCC val: 0.48380834874496775\n",
            "\n",
            "Epoch: 30\n",
            "Training loss: 0.007286664564162493 Validation loss: 0.007875115610659122\n",
            "MCC Train: 0.3682817937028189 MCC val: 0.27076518053694115\n",
            "\n",
            "Epoch: 31\n",
            "Training loss: 0.007106335833668709 Validation loss: 0.007154980208724737\n",
            "MCC Train: 0.4160650160979588 MCC val: 0.4521566449019243\n",
            "\n",
            "Epoch: 32\n",
            "Training loss: 0.007001395337283611 Validation loss: 0.007074323017150164\n",
            "MCC Train: 0.4430742076636762 MCC val: 0.4452116157225833\n",
            "\n",
            "Epoch: 33\n",
            "Training loss: 0.007077738177031279 Validation loss: 0.006912948098033667\n",
            "MCC Train: 0.4303293430876207 MCC val: 0.47851888364366335\n",
            "\n",
            "Epoch: 34\n",
            "Training loss: 0.0068733058869838715 Validation loss: 0.006811109371483326\n",
            "MCC Train: 0.48554086916198647 MCC val: 0.5027620503780009\n",
            "\n",
            "Epoch: 35\n",
            "Training loss: 0.006822845432907343 Validation loss: 0.006704823579639196\n",
            "MCC Train: 0.4923632941305467 MCC val: 0.510775819954732\n",
            "\n",
            "Epoch: 36\n",
            "Training loss: 0.006742106284946203 Validation loss: 0.00961578730493784\n",
            "MCC Train: 0.4981070934781478 MCC val: 0.0\n",
            "\n",
            "Epoch: 37\n",
            "Training loss: 0.00664887111634016 Validation loss: 0.006612973753362894\n",
            "MCC Train: 0.5149732307649779 MCC val: 0.5570853362659381\n",
            "\n",
            "Epoch: 38\n",
            "Training loss: 0.006564207840710878 Validation loss: 0.006882179994136095\n",
            "MCC Train: 0.5020759747525415 MCC val: 0.5216264690932583\n",
            "\n",
            "Epoch: 39\n",
            "Training loss: 0.006519772112369537 Validation loss: 0.006716690957546234\n",
            "MCC Train: 0.5260776749257561 MCC val: 0.5643957382914687\n",
            "\n",
            "Epoch: 40\n",
            "Training loss: 0.006402190774679184 Validation loss: 0.009122366085648537\n",
            "MCC Train: 0.550634533034809 MCC val: 0.06262242910851495\n",
            "\n",
            "Epoch: 41\n",
            "Training loss: 0.006350826006382704 Validation loss: 0.006421645637601614\n",
            "MCC Train: 0.5476525607734869 MCC val: 0.5946741057121668\n",
            "\n",
            "Epoch: 42\n",
            "Training loss: 0.006329068914055824 Validation loss: 0.006733657792210579\n",
            "MCC Train: 0.5568247813434335 MCC val: 0.543931403150314\n",
            "\n",
            "Epoch: 43\n",
            "Training loss: 0.006344298832118511 Validation loss: 0.006504917982965708\n",
            "MCC Train: 0.5667779720041981 MCC val: 0.5751137135705057\n",
            "\n",
            "Epoch: 44\n",
            "Training loss: 0.006175413262099028 Validation loss: 0.006089206784963608\n",
            "MCC Train: 0.5847708616147297 MCC val: 0.6093717937081676\n",
            "\n",
            "Epoch: 45\n",
            "Training loss: 0.006061977241188288 Validation loss: 0.006346515379846096\n",
            "MCC Train: 0.5986365094569461 MCC val: 0.5694167295098063\n",
            "\n",
            "Epoch: 46\n",
            "Training loss: 0.006005047354847193 Validation loss: 0.006193133071064949\n",
            "MCC Train: 0.6173262228761554 MCC val: 0.5814579284923347\n",
            "\n",
            "Epoch: 47\n",
            "Training loss: 0.00594331556931138 Validation loss: 0.006412609945982695\n",
            "MCC Train: 0.6157509824145708 MCC val: 0.5483028875083642\n",
            "\n",
            "Epoch: 48\n",
            "Training loss: 0.005950777791440487 Validation loss: 0.005952821578830481\n",
            "MCC Train: 0.6007628350524501 MCC val: 0.6269348553452835\n",
            "\n",
            "Epoch: 49\n",
            "Training loss: 0.005897458177059889 Validation loss: 0.005689938552677631\n",
            "MCC Train: 0.604485177578513 MCC val: 0.6283426428601165\n",
            "\n",
            "Epoch: 50\n",
            "Training loss: 0.005804514046758413 Validation loss: 0.006606088951230049\n",
            "MCC Train: 0.627921413725929 MCC val: 0.540886729739384\n",
            "0.001\t0.5\t0.005\t3\tFalse\ttrain_losses\tearly_stopping_model_0.001_0.5_0.005_3_False.pt\t0.011625275,0.0099114925,0.0095634125,0.009348876,0.009153394,0.008991937,0.008929693,0.008782893,0.0085313935,0.008409664,0.008275247,0.008146552,0.008171408,0.007949473,0.008036421,0.007969257,0.007815561,0.007747483,0.007736001,0.0077119404,0.0077180704,0.007705693,0.00758414,0.007543046,0.0073266574,0.007437353,0.0072152633,0.0073689353,0.0072886767,0.0072866646,0.007106336,0.0070013953,0.007077738,0.006873306,0.0068228454,0.0067421063,0.006648871,0.006564208,0.006519772,0.006402191,0.006350826,0.006329069,0.006344299,0.0061754133,0.0060619772,0.0060050474,0.0059433156,0.005950778,0.005897458,0.005804514\n",
            "\n",
            "0.001\t0.5\t0.005\t3\tFalse\tval_losses\tearly_stopping_model_0.001_0.5_0.005_3_False.pt\t0.009756212,0.009614301,0.009887589,0.009610843,0.009698905,0.009512141,0.009128226,0.008648983,0.008398272,0.008048139,0.008005562,0.008000457,0.007853815,0.007830158,0.0076898914,0.007687753,0.007609364,0.0076559167,0.0076094787,0.007568574,0.0075985333,0.0074772127,0.0074429545,0.0073266746,0.0075216866,0.007418006,0.007251092,0.0072467863,0.0071199876,0.007875116,0.00715498,0.007074323,0.006912948,0.0068111094,0.0067048236,0.009615787,0.0066129738,0.00688218,0.006716691,0.009122366,0.0064216456,0.006733658,0.006504918,0.006089207,0.0063465154,0.006193133,0.00641261,0.0059528216,0.0056899386,0.006606089\n",
            "\n",
            "0.001\t0.5\t0.005\t3\tFalse\ttrain_acc\tearly_stopping_model_0.001_0.5_0.005_3_False.pt\t0.6459032103497844,0.7069956875898419,0.7271202683277431,0.7414949688548155,0.7486823191183517,0.7498802108289411,0.7501197891710589,0.7503593675131768,0.7498802108289411,0.7501197891710589,0.7503593675131768,0.7513176808816483,0.7494010541447054,0.7522759942501198,0.7561092477240058,0.7532343076185912,0.7549113560134164,0.7601820795400096,0.7597029228557738,0.7685673215141351,0.7654528030666028,0.7628174413033062,0.7726401533301389,0.7716818399616675,0.7786296118830858,0.7815045519885002,0.7891710589362722,0.7906085289889794,0.7915668423574509,0.7908481073310972,0.802587446094873,0.8100143747005271,0.806420699568759,0.8251078102539531,0.8253473885960709,0.8287014853857211,0.832774317201725,0.8275035936751318,0.8368471490177288,0.8445136559655008,0.8442740776233828,0.8457115476760901,0.849784379492094,0.8555342597029229,0.8598466698610445,0.8660757067561092,0.8655965500718735,0.860804983229516,0.8620028749401054,0.8691902252036416\n",
            "\n",
            "0.001\t0.5\t0.005\t3\tFalse\tval_acc\tearly_stopping_model_0.001_0.5_0.005_3_False.pt\t0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.7519582245430809,0.7748041775456919,0.7996083550913838,0.7865535248041775,0.7865535248041775,0.7878590078328982,0.793733681462141,0.7989556135770235,0.7976501305483029,0.7800261096605744,0.7983028720626631,0.8015665796344648,0.793733681462141,0.8178851174934726,0.7748041775456919,0.816579634464752,0.8152741514360313,0.8244125326370757,0.8309399477806788,0.8335509138381201,0.75,0.8466057441253264,0.835509138381201,0.8433420365535248,0.7513054830287206,0.8577023498694517,0.8413838120104439,0.8511749347258486,0.8629242819843342,0.8498694516971279,0.8531331592689295,0.8426892950391645,0.8681462140992167,0.8694516971279374,0.8400783289817232\n",
            "\n",
            "0.001 0.5 0.005 3 True\n",
            "loss weight 0.2496406324868232\n",
            "\n",
            "Epoch: 1\n",
            "Training loss: 0.004835786763578653 Validation loss: 0.004073183983564377\n",
            "MCC Train: -0.02582104623495599 MCC val: -0.03666503109107835\n",
            "\n",
            "Epoch: 2\n",
            "Training loss: 0.004270236473530531 Validation loss: 0.00407148664817214\n",
            "MCC Train: 0.007304936426594496 MCC val: 0.03610587061377286\n",
            "\n",
            "Epoch: 3\n",
            "Training loss: 0.004157764371484518 Validation loss: 0.004073694348335266\n",
            "MCC Train: 0.022557468996242228 MCC val: -0.11141896207961348\n",
            "\n",
            "Epoch: 4\n",
            "Training loss: 0.004151918925344944 Validation loss: 0.004071484785526991\n",
            "MCC Train: 0.005805682792232244 MCC val: 0.016884780835833654\n",
            "\n",
            "Epoch: 5\n",
            "Training loss: 0.0041490234434604645 Validation loss: 0.004071349743753672\n",
            "MCC Train: 0.017476498918505865 MCC val: 0.024231052334274143\n",
            "\n",
            "Epoch: 6\n",
            "Training loss: 0.004103702958673239 Validation loss: 0.004069345071911812\n",
            "MCC Train: 0.010893931687353406 MCC val: 0.04648599100075556\n",
            "\n",
            "Epoch: 7\n",
            "Training loss: 0.00411094818264246 Validation loss: 0.00406868290156126\n",
            "MCC Train: -1.5914201873143026e-06 MCC val: 0.03419927840283847\n",
            "\n",
            "Epoch: 8\n",
            "Training loss: 0.004099560435861349 Validation loss: 0.004068436101078987\n",
            "MCC Train: 0.02466621682153614 MCC val: 0.04909882603878657\n",
            "\n",
            "Epoch: 9\n",
            "Training loss: 0.0040932693518698215 Validation loss: 0.004068297334015369\n",
            "MCC Train: 0.03544666692049576 MCC val: 0.05341117865042615\n",
            "\n",
            "Epoch: 10\n",
            "Training loss: 0.0040900977328419685 Validation loss: 0.00406673876568675\n",
            "MCC Train: 0.034627379505500065 MCC val: 0.04855713604861532\n",
            "\n",
            "Epoch: 11\n",
            "Training loss: 0.00408999715000391 Validation loss: 0.004068776965141296\n",
            "MCC Train: 0.01806350667525597 MCC val: 0.051298917604257706\n",
            "\n",
            "Epoch: 12\n",
            "Training loss: 0.0041152918711304665 Validation loss: 0.004068759735673666\n",
            "MCC Train: -0.013577759710192079 MCC val: 0.056281632786039\n",
            "\n",
            "Epoch: 13\n",
            "Training loss: 0.004125511739403009 Validation loss: 0.0040698000229895115\n",
            "MCC Train: 0.029192331539050185 MCC val: 0.051298917604257706\n",
            "\n",
            "Epoch: 14\n",
            "Training loss: 0.004116160329431295 Validation loss: 0.004068606533110142\n",
            "MCC Train: 0.028350540547787132 MCC val: 0.041830387009210566\n",
            "\n",
            "Epoch: 15\n",
            "Training loss: 0.0041111973114311695 Validation loss: 0.004068224225193262\n",
            "MCC Train: 0.030228453743912198 MCC val: 0.03303732352489702\n",
            "\n",
            "Epoch: 16\n",
            "Training loss: 0.004112365189939737 Validation loss: 0.004068189300596714\n",
            "MCC Train: 0.018925627238262868 MCC val: 0.0\n",
            "\n",
            "Epoch: 17\n",
            "Training loss: 0.004112475086003542 Validation loss: 0.004068431444466114\n",
            "MCC Train: 0.0273699750069992 MCC val: 0.0\n",
            "\n",
            "Epoch: 18\n",
            "Training loss: 0.004112199880182743 Validation loss: 0.0040682097896933556\n",
            "MCC Train: 0.014799224546911464 MCC val: 0.0\n",
            "\n",
            "Epoch: 19\n",
            "Training loss: 0.004098834469914436 Validation loss: 0.004070306662470102\n",
            "MCC Train: 0.008635403727493381 MCC val: 0.0\n",
            "\n",
            "Epoch: 20\n",
            "Training loss: 0.004103193990886211 Validation loss: 0.004070106893777847\n",
            "MCC Train: 0.006485464395846596 MCC val: 0.09158579774312331\n",
            "Early stopping\n",
            "\n",
            "0.001\t0.5\t0.005\t3\tTrue\ttrain_losses\tearly_stopping_model_0.001_0.5_0.005_3_True.pt\t0.0048357868,0.0042702365,0.0041577644,0.004151919,0.0041490234,0.004103703,0.004110948,0.0040995604,0.0040932694,0.0040900977,0.004089997,0.004115292,0.0041255117,0.0041161603,0.0041111973,0.004112365,0.004112475,0.0041122,0.0040988345,0.004103194\n",
            "\n",
            "0.001\t0.5\t0.005\t3\tTrue\tval_losses\tearly_stopping_model_0.001_0.5_0.005_3_True.pt\t0.004073184,0.0040714866,0.0040736943,0.004071485,0.0040713497,0.004069345,0.004068683,0.004068436,0.0040682973,0.0040667388,0.004068777,0.0040687597,0.0040698,0.0040686065,0.004068224,0.0040681893,0.0040684314,0.00406821,0.0040703067,0.004070107\n",
            "\n",
            "0.001\t0.5\t0.005\t3\tTrue\ttrain_acc\tearly_stopping_model_0.001_0.5_0.005_3_True.pt\t0.45951126018207955,0.4798754192620987,0.48969813128893147,0.5045519885002395,0.49880210828941063,0.48490656444657404,0.5004791566842357,0.5035936751317681,0.5110206037374221,0.5088643986583613,0.4940105414470532,0.49832295160517487,0.4465740297077144,0.4075227599425012,0.4175850503114518,0.29516051748921895,0.2755150934355534,0.2783900335409679,0.3121705797795879,0.3804504072831816\n",
            "\n",
            "0.001\t0.5\t0.005\t3\tTrue\tval_acc\tearly_stopping_model_0.001_0.5_0.005_3_True.pt\t0.2898172323759791,0.34073107049608353,0.4131853785900783,0.35704960835509136,0.26566579634464754,0.26240208877284593,0.2565274151436031,0.25718015665796345,0.2584856396866841,0.2630548302872063,0.25783289817232374,0.26827676240208875,0.25783289817232374,0.25522193211488253,0.25326370757180156,0.25,0.25,0.25,0.25,0.36945169712793735\n",
            "\n",
            "0.0001 0.1 0.0005 2 False\n",
            "\n",
            "Epoch: 1\n",
            "Training loss: 0.01060702558606863 Validation loss: 0.009721299633383751\n",
            "MCC Train: 0.007970095548307809 MCC val: 0.19957575371487393\n",
            "\n",
            "Epoch: 2\n",
            "Training loss: 0.00946017075330019 Validation loss: 0.009058674797415733\n",
            "MCC Train: 0.09120055140942315 MCC val: 0.29865073905197564\n",
            "\n",
            "Epoch: 3\n",
            "Training loss: 0.009070063009858131 Validation loss: 0.008786909282207489\n",
            "MCC Train: 0.134434556768684 MCC val: 0.31992115366392027\n",
            "\n",
            "Epoch: 4\n",
            "Training loss: 0.008773320354521275 Validation loss: 0.008518812246620655\n",
            "MCC Train: 0.18197380005307576 MCC val: 0.32928694013680837\n",
            "\n",
            "Epoch: 5\n",
            "Training loss: 0.008514458313584328 Validation loss: 0.008407585322856903\n",
            "MCC Train: 0.19169164559217106 MCC val: 0.3317253141119927\n",
            "\n",
            "Epoch: 6\n",
            "Training loss: 0.008288712240755558 Validation loss: 0.008309442549943924\n",
            "MCC Train: 0.26003650277155316 MCC val: 0.33649989739234903\n",
            "\n",
            "Epoch: 7\n",
            "Training loss: 0.008112182840704918 Validation loss: 0.008198697119951248\n",
            "MCC Train: 0.30156293057360606 MCC val: 0.3558470144980877\n",
            "\n",
            "Epoch: 8\n",
            "Training loss: 0.007892785593867302 Validation loss: 0.008123616687953472\n",
            "MCC Train: 0.3309595486678213 MCC val: 0.3807986180617216\n",
            "\n",
            "Epoch: 9\n",
            "Training loss: 0.007905371487140656 Validation loss: 0.008020525798201561\n",
            "MCC Train: 0.34568538509443153 MCC val: 0.38992592122379355\n",
            "\n",
            "Epoch: 10\n",
            "Training loss: 0.007701869122684002 Validation loss: 0.007590545807033777\n",
            "MCC Train: 0.3856461492468674 MCC val: 0.4564346938247884\n",
            "\n",
            "Epoch: 11\n",
            "Training loss: 0.00744833005592227 Validation loss: 0.007450742647051811\n",
            "MCC Train: 0.4334959257374817 MCC val: 0.4532882119165448\n",
            "\n",
            "Epoch: 12\n",
            "Training loss: 0.007208837196230888 Validation loss: 0.007546828128397465\n",
            "MCC Train: 0.4651803322934666 MCC val: 0.44107148059986345\n",
            "\n",
            "Epoch: 13\n",
            "Training loss: 0.007109104655683041 Validation loss: 0.0072433240711688995\n",
            "MCC Train: 0.46741157864661353 MCC val: 0.4715905892888206\n",
            "\n",
            "Epoch: 14\n",
            "Training loss: 0.006952368188649416 Validation loss: 0.007238319609314203\n",
            "MCC Train: 0.47768509570363904 MCC val: 0.4646347576334894\n",
            "\n",
            "Epoch: 15\n",
            "Training loss: 0.006570257246494293 Validation loss: 0.0067633395083248615\n",
            "MCC Train: 0.513036519310693 MCC val: 0.5194149690075197\n",
            "\n",
            "Epoch: 16\n",
            "Training loss: 0.00650345953181386 Validation loss: 0.006828880403190851\n",
            "MCC Train: 0.5246000953888817 MCC val: 0.5053309754048895\n",
            "\n",
            "Epoch: 17\n",
            "Training loss: 0.006383790634572506 Validation loss: 0.006554726045578718\n",
            "MCC Train: 0.549333160229948 MCC val: 0.5178261232660983\n",
            "\n",
            "Epoch: 18\n",
            "Training loss: 0.00606894725933671 Validation loss: 0.006500318180769682\n",
            "MCC Train: 0.5562927965516465 MCC val: 0.5264050918480009\n",
            "\n",
            "Epoch: 19\n",
            "Training loss: 0.006101476494222879 Validation loss: 0.006306610070168972\n",
            "MCC Train: 0.5690766837639184 MCC val: 0.5388775512011958\n",
            "\n",
            "Epoch: 20\n",
            "Training loss: 0.0056688981130719185 Validation loss: 0.006253416649997234\n",
            "MCC Train: 0.6064522481337857 MCC val: 0.553620642863463\n",
            "\n",
            "Epoch: 21\n",
            "Training loss: 0.005534055642783642 Validation loss: 0.006422937847673893\n",
            "MCC Train: 0.618740092664198 MCC val: 0.5519540371683463\n",
            "\n",
            "Epoch: 22\n",
            "Training loss: 0.005348202306777239 Validation loss: 0.006088066380470991\n",
            "MCC Train: 0.6433939775232955 MCC val: 0.5900757370389316\n",
            "\n",
            "Epoch: 23\n",
            "Training loss: 0.005139583256095648 Validation loss: 0.00593046098947525\n",
            "MCC Train: 0.6545907731596095 MCC val: 0.5968164409836993\n",
            "\n",
            "Epoch: 24\n",
            "Training loss: 0.005049722269177437 Validation loss: 0.0060468935407698154\n",
            "MCC Train: 0.6524046025503811 MCC val: 0.5948253060174788\n",
            "\n",
            "Epoch: 25\n",
            "Training loss: 0.004817022010684013 Validation loss: 0.005875310394912958\n",
            "MCC Train: 0.6648234789445513 MCC val: 0.6148510103417887\n",
            "\n",
            "Epoch: 26\n",
            "Training loss: 0.004728229250758886 Validation loss: 0.006007050629705191\n",
            "MCC Train: 0.6680528445670846 MCC val: 0.6047752707871185\n",
            "\n",
            "Epoch: 27\n",
            "Training loss: 0.004523590672761202 Validation loss: 0.005836330354213715\n",
            "MCC Train: 0.6754159583672055 MCC val: 0.6297770364913456\n",
            "\n",
            "Epoch: 28\n",
            "Training loss: 0.004514782689511776 Validation loss: 0.005911166779696941\n",
            "MCC Train: 0.6799133651700288 MCC val: 0.6268004703302003\n",
            "\n",
            "Epoch: 29\n",
            "Training loss: 0.004298801068216562 Validation loss: 0.005883850622922182\n",
            "MCC Train: 0.6995168192480393 MCC val: 0.6455089883799753\n",
            "\n",
            "Epoch: 30\n",
            "Training loss: 0.004265755880624056 Validation loss: 0.005889853462576866\n",
            "MCC Train: 0.7008364356857096 MCC val: 0.6475993376645184\n",
            "\n",
            "Epoch: 31\n",
            "Training loss: 0.004179752431809902 Validation loss: 0.006020248401910067\n",
            "MCC Train: 0.729118876430794 MCC val: 0.6375287226441619\n",
            "\n",
            "Epoch: 32\n",
            "Training loss: 0.004132614471018314 Validation loss: 0.006135624833405018\n",
            "MCC Train: 0.7178590890023085 MCC val: 0.6166721366018042\n",
            "\n",
            "Epoch: 33\n",
            "Training loss: 0.004012034274637699 Validation loss: 0.006116245407611132\n",
            "MCC Train: 0.7216926310196496 MCC val: 0.619571821007537\n",
            "\n",
            "Epoch: 34\n",
            "Training loss: 0.003912610467523336 Validation loss: 0.00612420029938221\n",
            "MCC Train: 0.725354762235585 MCC val: 0.6270173459847003\n",
            "\n",
            "Epoch: 35\n",
            "Training loss: 0.0037995583843439817 Validation loss: 0.006229962222278118\n",
            "MCC Train: 0.7418096550404258 MCC val: 0.6220815287120642\n",
            "\n",
            "Epoch: 36\n",
            "Training loss: 0.0036874113138765097 Validation loss: 0.0060779256746172905\n",
            "MCC Train: 0.7441604821446226 MCC val: 0.6440636326359852\n",
            "\n",
            "Epoch: 37\n",
            "Training loss: 0.003561439923942089 Validation loss: 0.006449039094150066\n",
            "MCC Train: 0.7432264451236478 MCC val: 0.6193754578937852\n",
            "Early stopping\n",
            "\n",
            "0.0001\t0.1\t0.0005\t2\tFalse\ttrain_losses\tearly_stopping_model_0.0001_0.1_0.0005_2_False.pt\t0.010607026,0.009460171,0.009070063,0.00877332,0.008514458,0.008288712,0.008112183,0.007892786,0.0079053715,0.007701869,0.00744833,0.007208837,0.0071091047,0.006952368,0.0065702572,0.0065034595,0.0063837906,0.0060689473,0.0061014765,0.005668898,0.0055340556,0.0053482023,0.0051395833,0.0050497223,0.004817022,0.0047282293,0.0045235907,0.0045147827,0.004298801,0.004265756,0.0041797524,0.0041326145,0.0040120343,0.0039126105,0.0037995584,0.0036874113,0.00356144\n",
            "\n",
            "0.0001\t0.1\t0.0005\t2\tFalse\tval_losses\tearly_stopping_model_0.0001_0.1_0.0005_2_False.pt\t0.0097213,0.009058675,0.008786909,0.008518812,0.008407585,0.008309443,0.008198697,0.008123617,0.008020526,0.007590546,0.0074507426,0.007546828,0.007243324,0.0072383196,0.0067633395,0.0068288804,0.006554726,0.006500318,0.00630661,0.0062534166,0.006422938,0.0060880664,0.005930461,0.0060468935,0.0058753104,0.0060070506,0.0058363304,0.005911167,0.0058838506,0.0058898535,0.0060202484,0.006135625,0.0061162454,0.0061242003,0.006229962,0.0060779257,0.006449039\n",
            "\n",
            "0.0001\t0.1\t0.0005\t2\tFalse\ttrain_acc\tearly_stopping_model_0.0001_0.1_0.0005_2_False.pt\t0.6171538092956397,0.6945376137997125,0.7218495448011499,0.7405366554863441,0.7438907522759942,0.7642549113560134,0.7728797316722569,0.7798275035936751,0.7853378054623862,0.7958792525155726,0.8102539530426449,0.8186391950167705,0.8195975083852419,0.8227120268327743,0.8332534738859607,0.8368471490177288,0.8447532343076186,0.8469094393866794,0.8509822712026833,0.8627216099664591,0.866554863440345,0.8744609487302348,0.8780546238620028,0.8773358888356493,0.8814087206516531,0.8823670340201246,0.8847628174413033,0.8862002874940106,0.8926689027311931,0.8931480594154289,0.9027311931001437,0.8986583612841399,0.9000958313368471,0.9012937230474365,0.9068040249161475,0.907762338284619,0.9072831816003833\n",
            "\n",
            "0.0001\t0.1\t0.0005\t2\tFalse\tval_acc\tearly_stopping_model_0.0001_0.1_0.0005_2_False.pt\t0.72911227154047,0.7421671018276762,0.7480417754569191,0.7506527415143603,0.7460835509138382,0.7454308093994778,0.7519582245430809,0.762402088772846,0.7663185378590078,0.8015665796344648,0.7996083550913838,0.7930809399477807,0.8087467362924282,0.8054830287206266,0.8302872062663186,0.8244125326370757,0.8296344647519582,0.8328981723237598,0.837467362924282,0.8426892950391645,0.8400783289817232,0.8544386422976501,0.856396866840731,0.8544386422976501,0.8616187989556136,0.8577023498694517,0.8661879895561357,0.8655352480417755,0.8701044386422977,0.8714099216710183,0.8661879895561357,0.8577023498694517,0.8590078328981723,0.8609660574412533,0.8590078328981723,0.868798955613577,0.858355091383812\n",
            "\n",
            "0.0001 0.1 0.0005 2 True\n",
            "loss weight 0.2496406324868232\n",
            "\n",
            "Epoch: 1\n",
            "Training loss: 0.004906788468360901 Validation loss: 0.003995727747678757\n",
            "MCC Train: 0.015688819017726795 MCC val: 0.1333925672818626\n",
            "\n",
            "Epoch: 2\n",
            "Training loss: 0.004352441988885403 Validation loss: 0.0037922398187220097\n",
            "MCC Train: 0.1086073190935078 MCC val: 0.2600120801294871\n",
            "\n",
            "Epoch: 3\n",
            "Training loss: 0.004131769295781851 Validation loss: 0.0037061315961182117\n",
            "MCC Train: 0.1703651698735998 MCC val: 0.2658234289407016\n",
            "\n",
            "Epoch: 4\n",
            "Training loss: 0.004013793542981148 Validation loss: 0.003662005765363574\n",
            "MCC Train: 0.18796033415066474 MCC val: 0.2598040252567526\n",
            "\n",
            "Epoch: 5\n",
            "Training loss: 0.0038591662887483835 Validation loss: 0.0036397017538547516\n",
            "MCC Train: 0.23657990932217252 MCC val: 0.27113488442510386\n",
            "\n",
            "Epoch: 6\n",
            "Training loss: 0.003803515573963523 Validation loss: 0.003621015464887023\n",
            "MCC Train: 0.2514589833546122 MCC val: 0.275212481387186\n",
            "\n",
            "Epoch: 7\n",
            "Training loss: 0.003718866966664791 Validation loss: 0.0035739829763770103\n",
            "MCC Train: 0.27882191695674996 MCC val: 0.2962175521928998\n",
            "\n",
            "Epoch: 8\n",
            "Training loss: 0.0037041993346065283 Validation loss: 0.003574179718270898\n",
            "MCC Train: 0.28276672605234054 MCC val: 0.2923455445189075\n",
            "\n",
            "Epoch: 9\n",
            "Training loss: 0.0036923750303685665 Validation loss: 0.0034930333495140076\n",
            "MCC Train: 0.29945689390277025 MCC val: 0.2978426980912858\n",
            "\n",
            "Epoch: 10\n",
            "Training loss: 0.0035834694281220436 Validation loss: 0.003499357495456934\n",
            "MCC Train: 0.32053702117230426 MCC val: 0.2876450780722724\n",
            "\n",
            "Epoch: 11\n",
            "Training loss: 0.0035368443932384253 Validation loss: 0.0034690815955400467\n",
            "MCC Train: 0.32583223541697104 MCC val: 0.28413697842705093\n",
            "\n",
            "Epoch: 12\n",
            "Training loss: 0.0035237472038716078 Validation loss: 0.003495133249089122\n",
            "MCC Train: 0.33751406684970364 MCC val: 0.2590507700358373\n",
            "\n",
            "Epoch: 13\n",
            "Training loss: 0.0034642077516764402 Validation loss: 0.0034788770135492086\n",
            "MCC Train: 0.3356113493697611 MCC val: 0.2662000625015029\n",
            "\n",
            "Epoch: 14\n",
            "Training loss: 0.00341275823302567 Validation loss: 0.003371432889252901\n",
            "MCC Train: 0.3534472394026081 MCC val: 0.29479697788682463\n",
            "\n",
            "Epoch: 15\n",
            "Training loss: 0.003405144205316901 Validation loss: 0.0033758434001356363\n",
            "MCC Train: 0.3524769911997652 MCC val: 0.29507145348178976\n",
            "\n",
            "Epoch: 16\n",
            "Training loss: 0.0032949286978691816 Validation loss: 0.0033367557916790247\n",
            "MCC Train: 0.36910290580053634 MCC val: 0.2973808570665904\n",
            "\n",
            "Epoch: 17\n",
            "Training loss: 0.003214426338672638 Validation loss: 0.003350184066221118\n",
            "MCC Train: 0.3963304948374459 MCC val: 0.2871707075446058\n",
            "\n",
            "Epoch: 18\n",
            "Training loss: 0.0032376449089497328 Validation loss: 0.003285490209236741\n",
            "MCC Train: 0.38297998055947924 MCC val: 0.32436656955414184\n",
            "\n",
            "Epoch: 19\n",
            "Training loss: 0.0031650355085730553 Validation loss: 0.003234738251194358\n",
            "MCC Train: 0.40322701471258654 MCC val: 0.34982675961175963\n",
            "\n",
            "Epoch: 20\n",
            "Training loss: 0.003191814525052905 Validation loss: 0.003261919366195798\n",
            "MCC Train: 0.4079213463670834 MCC val: 0.3410530377107469\n",
            "\n",
            "Epoch: 21\n",
            "Training loss: 0.0030827189330011606 Validation loss: 0.003173213452100754\n",
            "MCC Train: 0.4425898708213171 MCC val: 0.37580252267071557\n",
            "\n",
            "Epoch: 22\n",
            "Training loss: 0.003046827856451273 Validation loss: 0.0031152602750808\n",
            "MCC Train: 0.4427207329456972 MCC val: 0.4122436815054616\n",
            "\n",
            "Epoch: 23\n",
            "Training loss: 0.0030450341291725636 Validation loss: 0.003212208626791835\n",
            "MCC Train: 0.4555037819777224 MCC val: 0.3604602425932157\n",
            "\n",
            "Epoch: 24\n",
            "Training loss: 0.002852445701137185 Validation loss: 0.0031604093965142965\n",
            "MCC Train: 0.4754504731357309 MCC val: 0.3909164830950648\n",
            "\n",
            "Epoch: 25\n",
            "Training loss: 0.002918834099546075 Validation loss: 0.003199988743290305\n",
            "MCC Train: 0.46892310228147666 MCC val: 0.36043806344126467\n",
            "\n",
            "Epoch: 26\n",
            "Training loss: 0.002843134803697467 Validation loss: 0.003031764645129442\n",
            "MCC Train: 0.4974051108676262 MCC val: 0.41204997645189995\n",
            "\n",
            "Epoch: 27\n",
            "Training loss: 0.002802846021950245 Validation loss: 0.0030404566787183285\n",
            "MCC Train: 0.5038169238881769 MCC val: 0.4035591283961726\n",
            "\n",
            "Epoch: 28\n",
            "Training loss: 0.0027704238891601562 Validation loss: 0.0029686465859413147\n",
            "MCC Train: 0.5186740142741926 MCC val: 0.43261835469288334\n",
            "\n",
            "Epoch: 29\n",
            "Training loss: 0.0027020785491913557 Validation loss: 0.0030376522336155176\n",
            "MCC Train: 0.542598406242897 MCC val: 0.4125843939005557\n",
            "\n",
            "Epoch: 30\n",
            "Training loss: 0.002630390226840973 Validation loss: 0.002937640994787216\n",
            "MCC Train: 0.5314456693898166 MCC val: 0.42992464049917894\n",
            "\n",
            "Epoch: 31\n",
            "Training loss: 0.0026000034995377064 Validation loss: 0.0029105511493980885\n",
            "MCC Train: 0.5451499201758352 MCC val: 0.4549521913180058\n",
            "\n",
            "Epoch: 32\n",
            "Training loss: 0.0025470175314694643 Validation loss: 0.002915178192779422\n",
            "MCC Train: 0.5430634071070124 MCC val: 0.4452164954062388\n",
            "\n",
            "Epoch: 33\n",
            "Training loss: 0.002467123093083501 Validation loss: 0.0028573949821293354\n",
            "MCC Train: 0.5808083975217254 MCC val: 0.4679740787260346\n",
            "\n",
            "Epoch: 34\n",
            "Training loss: 0.0023569208569824696 Validation loss: 0.002867420669645071\n",
            "MCC Train: 0.5907838968200808 MCC val: 0.4777825343042292\n",
            "\n",
            "Epoch: 35\n",
            "Training loss: 0.0022989644203335047 Validation loss: 0.0028563968371599913\n",
            "MCC Train: 0.6133555587242914 MCC val: 0.473483761543852\n",
            "\n",
            "Epoch: 36\n",
            "Training loss: 0.0022665977012366056 Validation loss: 0.002845462877303362\n",
            "MCC Train: 0.6049773415661743 MCC val: 0.49874995051468013\n",
            "\n",
            "Epoch: 37\n",
            "Training loss: 0.0022069725673645735 Validation loss: 0.002840984845533967\n",
            "MCC Train: 0.6105814099701478 MCC val: 0.5096260563958794\n",
            "\n",
            "Epoch: 38\n",
            "Training loss: 0.0021611382253468037 Validation loss: 0.0028553358279168606\n",
            "MCC Train: 0.6264465585164695 MCC val: 0.5036523161954903\n",
            "\n",
            "Epoch: 39\n",
            "Training loss: 0.0020510905887931585 Validation loss: 0.002831832505762577\n",
            "MCC Train: 0.6481734889143906 MCC val: 0.5036483463166351\n",
            "\n",
            "Epoch: 40\n",
            "Training loss: 0.002004058100283146 Validation loss: 0.002858359832316637\n",
            "MCC Train: 0.6460890785627393 MCC val: 0.5187699080788514\n",
            "\n",
            "Epoch: 41\n",
            "Training loss: 0.0019511568825691938 Validation loss: 0.0028671587351709604\n",
            "MCC Train: 0.6727834043646336 MCC val: 0.5267820181256245\n",
            "\n",
            "Epoch: 42\n",
            "Training loss: 0.0018833066569641232 Validation loss: 0.0029035652987658978\n",
            "MCC Train: 0.6837694184154967 MCC val: 0.5222039432915462\n",
            "\n",
            "Epoch: 43\n",
            "Training loss: 0.0018533605616539717 Validation loss: 0.0029436673503369093\n",
            "MCC Train: 0.6926299517118151 MCC val: 0.5178415127218784\n",
            "\n",
            "Epoch: 44\n",
            "Training loss: 0.0018480170983821154 Validation loss: 0.00294032646343112\n",
            "MCC Train: 0.6904796422348404 MCC val: 0.5165378493575785\n",
            "\n",
            "Epoch: 45\n",
            "Training loss: 0.0018304695840924978 Validation loss: 0.0029218776617199183\n",
            "MCC Train: 0.696234529776471 MCC val: 0.5222039432915462\n",
            "\n",
            "Epoch: 46\n",
            "Training loss: 0.0017019306542351842 Validation loss: 0.0029487935826182365\n",
            "MCC Train: 0.7123646469137176 MCC val: 0.5254575504148581\n",
            "\n",
            "Epoch: 47\n",
            "Training loss: 0.001688155229203403 Validation loss: 0.0030101926531642675\n",
            "MCC Train: 0.7068607593502186 MCC val: 0.5352183717847935\n",
            "\n",
            "Epoch: 48\n",
            "Training loss: 0.0016536879120394588 Validation loss: 0.00301716779358685\n",
            "MCC Train: 0.7151220723662326 MCC val: 0.5318715696642825\n",
            "\n",
            "Epoch: 49\n",
            "Training loss: 0.0015765748685225844 Validation loss: 0.0030444783624261618\n",
            "MCC Train: 0.7271920139879641 MCC val: 0.5275967688485071\n",
            "Early stopping\n",
            "\n",
            "0.0001\t0.1\t0.0005\t2\tTrue\ttrain_losses\tearly_stopping_model_0.0001_0.1_0.0005_2_True.pt\t0.0049067885,0.004352442,0.0041317693,0.0040137935,0.0038591663,0.0038035156,0.003718867,0.0037041993,0.003692375,0.0035834694,0.0035368444,0.0035237472,0.0034642078,0.0034127582,0.0034051442,0.0032949287,0.0032144263,0.003237645,0.0031650355,0.0031918145,0.003082719,0.0030468279,0.0030450341,0.0028524457,0.002918834,0.0028431348,0.002802846,0.002770424,0.0027020785,0.0026303902,0.0026000035,0.0025470175,0.002467123,0.0023569209,0.0022989644,0.0022665977,0.0022069726,0.0021611382,0.0020510906,0.002004058,0.0019511569,0.0018833067,0.0018533606,0.0018480171,0.0018304696,0.0017019307,0.0016881552,0.0016536879,0.0015765749\n",
            "\n",
            "0.0001\t0.1\t0.0005\t2\tTrue\tval_losses\tearly_stopping_model_0.0001_0.1_0.0005_2_True.pt\t0.0039957277,0.0037922398,0.0037061316,0.0036620058,0.0036397018,0.0036210155,0.003573983,0.0035741797,0.0034930333,0.0034993575,0.0034690816,0.0034951332,0.003478877,0.003371433,0.0033758434,0.0033367558,0.003350184,0.0032854902,0.0032347383,0.0032619194,0.0031732135,0.0031152603,0.0032122086,0.0031604094,0.0031999887,0.0030317646,0.0030404567,0.0029686466,0.0030376522,0.002937641,0.0029105511,0.0029151782,0.002857395,0.0028674207,0.0028563968,0.0028454629,0.0028409848,0.0028553358,0.0028318325,0.0028583598,0.0028671587,0.0029035653,0.0029436674,0.0029403265,0.0029218777,0.0029487936,0.0030101927,0.0030171678,0.0030444784\n",
            "\n",
            "0.0001\t0.1\t0.0005\t2\tTrue\ttrain_acc\tearly_stopping_model_0.0001_0.1_0.0005_2_True.pt\t0.6871106851940585,0.6789650215620507,0.6727359846669861,0.6545280306660278,0.6600383325347389,0.6600383325347389,0.6701006229036895,0.6648298993770964,0.6777671298514615,0.682319118351701,0.6863919501677048,0.69932918064207,0.6911835170100623,0.7081935793004313,0.7081935793004313,0.7153809295639674,0.735026353617633,0.7283181600383325,0.7410158121705798,0.7417345471969334,0.7601820795400096,0.7628174413033062,0.7733588883564926,0.7793483469094394,0.7788691902252036,0.7934834690943938,0.7965979875419262,0.8033061811212266,0.8126497364638237,0.808337326305702,0.8143267848586487,0.8131288931480594,0.8287014853857211,0.8315764254911356,0.844034499281265,0.8378054623862002,0.8423574508864399,0.8476281744130331,0.8557738380450407,0.8548155246765692,0.8663152850982271,0.8703881169142309,0.8735026353617633,0.8742213703881169,0.8749401054144705,0.8818878773358888,0.8775754671777671,0.8840440824149497,0.8873981792046\n",
            "\n",
            "0.0001\t0.1\t0.0005\t2\tTrue\tval_acc\tearly_stopping_model_0.0001_0.1_0.0005_2_True.pt\t0.7219321148825065,0.6932114882506527,0.664490861618799,0.652088772845953,0.652088772845953,0.6553524804177546,0.672976501305483,0.664490861618799,0.6795039164490861,0.6618798955613577,0.6579634464751958,0.6364229765013055,0.6422976501305483,0.6697127937336814,0.6599216710182768,0.6651436031331592,0.6546997389033943,0.6840731070496083,0.7043080939947781,0.6977806788511749,0.7284595300261096,0.7513054830287206,0.7101827676240209,0.7336814621409922,0.70822454308094,0.7519582245430809,0.7447780678851175,0.7643603133159269,0.7467362924281984,0.7604438642297651,0.7767624020887729,0.7650130548302873,0.7819843342036553,0.783289817232376,0.7813315926892951,0.7976501305483029,0.8015665796344648,0.793733681462141,0.7924281984334204,0.8002610966057441,0.8067885117493473,0.8035248041775457,0.8015665796344648,0.7963446475195822,0.8035248041775457,0.8048302872062664,0.8087467362924282,0.8067885117493473,0.8054830287206266\n",
            "\n",
            "0.0001 0.1 0.0005 3 False\n",
            "\n",
            "Epoch: 1\n",
            "Training loss: 0.01028044056147337 Validation loss: 0.00961538590490818\n",
            "MCC Train: 0.021217333248479825 MCC val: 0.009359702441069916\n",
            "\n",
            "Epoch: 2\n",
            "Training loss: 0.009249208495020866 Validation loss: 0.00889628566801548\n",
            "MCC Train: 0.05113107191046927 MCC val: 0.10259783520851541\n",
            "\n",
            "Epoch: 3\n",
            "Training loss: 0.00881446897983551 Validation loss: 0.00864710845053196\n",
            "MCC Train: 0.054366261606982776 MCC val: 0.27295045731297485\n",
            "\n",
            "Epoch: 4\n",
            "Training loss: 0.008600130677223206 Validation loss: 0.008390317671000957\n",
            "MCC Train: 0.13133780377243193 MCC val: 0.3078076615594094\n",
            "\n",
            "Epoch: 5\n",
            "Training loss: 0.0084060775116086 Validation loss: 0.008278943598270416\n",
            "MCC Train: 0.15859389047345102 MCC val: 0.3245171928354504\n",
            "\n",
            "Epoch: 6\n",
            "Training loss: 0.008192096836864948 Validation loss: 0.00804900098592043\n",
            "MCC Train: 0.22084487906150113 MCC val: 0.3542867803642923\n",
            "\n",
            "Epoch: 7\n",
            "Training loss: 0.00812513753771782 Validation loss: 0.007913701236248016\n",
            "MCC Train: 0.2691232695137513 MCC val: 0.40930987273472647\n",
            "\n",
            "Epoch: 8\n",
            "Training loss: 0.00783019419759512 Validation loss: 0.007749573793262243\n",
            "MCC Train: 0.3131719656369848 MCC val: 0.453439022283502\n",
            "\n",
            "Epoch: 9\n",
            "Training loss: 0.007605011574923992 Validation loss: 0.007706054486334324\n",
            "MCC Train: 0.3771497313484369 MCC val: 0.44972176226702665\n",
            "\n",
            "Epoch: 10\n",
            "Training loss: 0.0075648813508450985 Validation loss: 0.007348703686147928\n",
            "MCC Train: 0.4007327839045819 MCC val: 0.5122192977848823\n",
            "\n",
            "Epoch: 11\n",
            "Training loss: 0.007378766778856516 Validation loss: 0.0073629869148135185\n",
            "MCC Train: 0.4134007194621031 MCC val: 0.49758724352002964\n",
            "\n",
            "Epoch: 12\n",
            "Training loss: 0.0070700012147426605 Validation loss: 0.007156632374972105\n",
            "MCC Train: 0.477691846589935 MCC val: 0.5350692292845797\n",
            "\n",
            "Epoch: 13\n",
            "Training loss: 0.007054599467664957 Validation loss: 0.007209845818579197\n",
            "MCC Train: 0.4955709383531653 MCC val: 0.49469442576566575\n",
            "\n",
            "Epoch: 14\n",
            "Training loss: 0.006848120130598545 Validation loss: 0.007011075038462877\n",
            "MCC Train: 0.5075888835364822 MCC val: 0.5249992854330131\n",
            "\n",
            "Epoch: 15\n",
            "Training loss: 0.00686182826757431 Validation loss: 0.006809484213590622\n",
            "MCC Train: 0.5095325063172444 MCC val: 0.544497646535212\n",
            "\n",
            "Epoch: 16\n",
            "Training loss: 0.006703552324324846 Validation loss: 0.006805758457630873\n",
            "MCC Train: 0.5280885990369055 MCC val: 0.5466624630546338\n",
            "\n",
            "Epoch: 17\n",
            "Training loss: 0.006584805436432362 Validation loss: 0.00659007765352726\n",
            "MCC Train: 0.5425736985947895 MCC val: 0.5581767007986098\n",
            "\n",
            "Epoch: 18\n",
            "Training loss: 0.0064482009038329124 Validation loss: 0.006480389274656773\n",
            "MCC Train: 0.554000420338347 MCC val: 0.5774709106869362\n",
            "\n",
            "Epoch: 19\n",
            "Training loss: 0.006435881368815899 Validation loss: 0.006532200146466494\n",
            "MCC Train: 0.550232712601273 MCC val: 0.5547137597379089\n",
            "\n",
            "Epoch: 20\n",
            "Training loss: 0.006162617821246386 Validation loss: 0.006343158893287182\n",
            "MCC Train: 0.579049119422522 MCC val: 0.5830144481618039\n",
            "\n",
            "Epoch: 21\n",
            "Training loss: 0.006105962675064802 Validation loss: 0.006410870235413313\n",
            "MCC Train: 0.5791377550513358 MCC val: 0.574461929986768\n",
            "\n",
            "Epoch: 22\n",
            "Training loss: 0.005828340072184801 Validation loss: 0.006285316776484251\n",
            "MCC Train: 0.6132914282576569 MCC val: 0.581158166963732\n",
            "\n",
            "Epoch: 23\n",
            "Training loss: 0.005756453610956669 Validation loss: 0.006210010498762131\n",
            "MCC Train: 0.6110179986580281 MCC val: 0.5960808908808727\n",
            "\n",
            "Epoch: 24\n",
            "Training loss: 0.005713026039302349 Validation loss: 0.006238944828510284\n",
            "MCC Train: 0.6034122813712318 MCC val: 0.5888648195465092\n",
            "\n",
            "Epoch: 25\n",
            "Training loss: 0.005582286510616541 Validation loss: 0.006189665757119656\n",
            "MCC Train: 0.6194571288066687 MCC val: 0.5928503682405634\n",
            "\n",
            "Epoch: 26\n",
            "Training loss: 0.005492462310940027 Validation loss: 0.006075218319892883\n",
            "MCC Train: 0.6178542040214189 MCC val: 0.5978732174798241\n",
            "\n",
            "Epoch: 27\n",
            "Training loss: 0.005464845336973667 Validation loss: 0.005972716491669416\n",
            "MCC Train: 0.6291826131309753 MCC val: 0.5999686075217755\n",
            "\n",
            "Epoch: 28\n",
            "Training loss: 0.005207068286836147 Validation loss: 0.0060105049051344395\n",
            "MCC Train: 0.6494599262956404 MCC val: 0.5905258020499514\n",
            "\n",
            "Epoch: 29\n",
            "Training loss: 0.005253135226666927 Validation loss: 0.00606697890907526\n",
            "MCC Train: 0.6412978295476418 MCC val: 0.5909736897749344\n",
            "\n",
            "Epoch: 30\n",
            "Training loss: 0.004959020763635635 Validation loss: 0.0059585850685834885\n",
            "MCC Train: 0.6659072364170335 MCC val: 0.5909736897749344\n",
            "\n",
            "Epoch: 31\n",
            "Training loss: 0.004831111058592796 Validation loss: 0.005950198043137789\n",
            "MCC Train: 0.670181952513708 MCC val: 0.5966299059294549\n",
            "\n",
            "Epoch: 32\n",
            "Training loss: 0.0047058360651135445 Validation loss: 0.005837881006300449\n",
            "MCC Train: 0.6796584891196692 MCC val: 0.6160037013279052\n",
            "\n",
            "Epoch: 33\n",
            "Training loss: 0.004668571054935455 Validation loss: 0.0059736622497439384\n",
            "MCC Train: 0.6812430945579839 MCC val: 0.5912139846884243\n",
            "\n",
            "Epoch: 34\n",
            "Training loss: 0.004431974608451128 Validation loss: 0.005819540470838547\n",
            "MCC Train: 0.6825534125565281 MCC val: 0.5989329313880647\n",
            "\n",
            "Epoch: 35\n",
            "Training loss: 0.004424787126481533 Validation loss: 0.005973481107503176\n",
            "MCC Train: 0.6878992267044773 MCC val: 0.6045745788742399\n",
            "\n",
            "Epoch: 36\n",
            "Training loss: 0.0042924294248223305 Validation loss: 0.0060553536750376225\n",
            "MCC Train: 0.6856533119239844 MCC val: 0.6015721463650937\n",
            "\n",
            "Epoch: 37\n",
            "Training loss: 0.004153864458203316 Validation loss: 0.005931962747126818\n",
            "MCC Train: 0.70111604799431 MCC val: 0.615395388830496\n",
            "\n",
            "Epoch: 38\n",
            "Training loss: 0.004039956256747246 Validation loss: 0.00610299501568079\n",
            "MCC Train: 0.7109269638218569 MCC val: 0.6116861007928469\n",
            "\n",
            "Epoch: 39\n",
            "Training loss: 0.00406758114695549 Validation loss: 0.005982964299619198\n",
            "MCC Train: 0.6911350648951657 MCC val: 0.6214584446320618\n",
            "\n",
            "Epoch: 40\n",
            "Training loss: 0.004011576529592276 Validation loss: 0.006126559339463711\n",
            "MCC Train: 0.7106887953151659 MCC val: 0.614294742053401\n",
            "\n",
            "Epoch: 41\n",
            "Training loss: 0.003820906626060605 Validation loss: 0.006120765116065741\n",
            "MCC Train: 0.7175343963243513 MCC val: 0.6192835386235622\n",
            "\n",
            "Epoch: 42\n",
            "Training loss: 0.0037488758098334074 Validation loss: 0.006237239111214876\n",
            "MCC Train: 0.7261132726125911 MCC val: 0.6308166188562717\n",
            "\n",
            "Epoch: 43\n",
            "Training loss: 0.0034650727175176144 Validation loss: 0.0063957893289625645\n",
            "MCC Train: 0.7443949517895905 MCC val: 0.6177432843242373\n",
            "\n",
            "Epoch: 44\n",
            "Training loss: 0.0034675372298806906 Validation loss: 0.006523614749312401\n",
            "MCC Train: 0.7417704868065181 MCC val: 0.6234225583004682\n",
            "Early stopping\n",
            "\n",
            "0.0001\t0.1\t0.0005\t3\tFalse\ttrain_losses\tearly_stopping_model_0.0001_0.1_0.0005_3_False.pt\t0.010280441,0.0092492085,0.008814469,0.008600131,0.0084060775,0.008192097,0.008125138,0.007830194,0.0076050116,0.0075648814,0.007378767,0.007070001,0.0070545995,0.00684812,0.0068618283,0.0067035523,0.0065848054,0.006448201,0.0064358814,0.006162618,0.0061059627,0.00582834,0.0057564536,0.005713026,0.0055822865,0.0054924623,0.0054648453,0.0052070683,0.005253135,0.0049590208,0.004831111,0.004705836,0.004668571,0.0044319746,0.004424787,0.0042924294,0.0041538645,0.0040399563,0.004067581,0.0040115765,0.0038209066,0.0037488758,0.0034650727,0.0034675372\n",
            "\n",
            "0.0001\t0.1\t0.0005\t3\tFalse\tval_losses\tearly_stopping_model_0.0001_0.1_0.0005_3_False.pt\t0.009615386,0.008896286,0.008647108,0.008390318,0.008278944,0.008049001,0.007913701,0.007749574,0.0077060545,0.0073487037,0.007362987,0.0071566324,0.007209846,0.007011075,0.006809484,0.0068057585,0.0065900777,0.0064803893,0.0065322,0.006343159,0.0064108702,0.006285317,0.0062100105,0.006238945,0.0061896658,0.0060752183,0.0059727165,0.006010505,0.006066979,0.005958585,0.005950198,0.005837881,0.0059736622,0.0058195405,0.005973481,0.0060553537,0.0059319627,0.006102995,0.0059829643,0.0061265593,0.006120765,0.006237239,0.0063957893,0.0065236147\n",
            "\n",
            "0.0001\t0.1\t0.0005\t3\tFalse\ttrain_acc\tearly_stopping_model_0.0001_0.1_0.0005_3_False.pt\t0.6262577862961188,0.7316722568279828,0.7436511739338764,0.7534738859607092,0.7549113560134164,0.7632965979875419,0.7735984666986104,0.7795879252515573,0.7973167225682798,0.8021082894106373,0.8057019645424054,0.8234307618591279,0.828941063727839,0.8320555821753713,0.832774317201725,0.8378054623862002,0.8423574508864399,0.8464302827024437,0.8452323909918543,0.8540967896502156,0.8540967896502156,0.8648778150455199,0.8641590800191663,0.8617632965979876,0.8667944417824629,0.8663152850982271,0.8699089602299952,0.8763775754671778,0.8737422137038812,0.881648298993771,0.8830857690464782,0.8862002874940106,0.8866794441782463,0.887158600862482,0.8888356492573072,0.8881169142309535,0.8933876377575467,0.8965021562050791,0.8900335409678966,0.8965021562050791,0.8988979396262577,0.9017728797316723,0.9080019166267369,0.9070436032582655\n",
            "\n",
            "0.0001\t0.1\t0.0005\t3\tFalse\tval_acc\tearly_stopping_model_0.0001_0.1_0.0005_3_False.pt\t0.7473890339425587,0.7539164490861618,0.7754569190600522,0.7748041775456919,0.7682767624020888,0.7734986945169713,0.7898172323759791,0.804177545691906,0.7996083550913838,0.8283289817232375,0.8198433420365535,0.8361618798955613,0.8178851174934726,0.8315926892950392,0.8400783289817232,0.8407310704960835,0.8453002610966057,0.8524804177545692,0.8439947780678851,0.8544386422976501,0.8511749347258486,0.8537859007832899,0.8590078328981723,0.856396866840731,0.8577023498694517,0.8596605744125326,0.860313315926893,0.8570496083550914,0.8570496083550914,0.8570496083550914,0.8590078328981723,0.8655352480417755,0.8570496083550914,0.8596605744125326,0.8609660574412533,0.8596605744125326,0.8648825065274152,0.8629242819843342,0.8661879895561357,0.8622715404699739,0.8635770234986945,0.8674934725848564,0.8609660574412533,0.8629242819843342\n",
            "\n",
            "0.0001 0.1 0.0005 3 True\n",
            "loss weight 0.2496406324868232\n",
            "\n",
            "Epoch: 1\n",
            "Training loss: 0.004339681472629309 Validation loss: 0.004012008663266897\n",
            "MCC Train: 0.061473218202595464 MCC val: 0.13565708054583386\n",
            "\n",
            "Epoch: 2\n",
            "Training loss: 0.004238084424287081 Validation loss: 0.003924025688320398\n",
            "MCC Train: 0.07002699731049802 MCC val: 0.16928981062405926\n",
            "\n",
            "Epoch: 3\n",
            "Training loss: 0.004058950114995241 Validation loss: 0.003810200374573469\n",
            "MCC Train: 0.11270444715415297 MCC val: 0.22603405684491681\n",
            "\n",
            "Epoch: 4\n",
            "Training loss: 0.003918527625501156 Validation loss: 0.0037365336902439594\n",
            "MCC Train: 0.17741377108599596 MCC val: 0.2495941820785207\n",
            "\n",
            "Epoch: 5\n",
            "Training loss: 0.0038804244250059128 Validation loss: 0.0036849116440862417\n",
            "MCC Train: 0.22159419398873062 MCC val: 0.2754654220056336\n",
            "\n",
            "Epoch: 6\n",
            "Training loss: 0.0038029938004910946 Validation loss: 0.003631532657891512\n",
            "MCC Train: 0.22751660444435534 MCC val: 0.2967144782487266\n",
            "\n",
            "Epoch: 7\n",
            "Training loss: 0.0037620384246110916 Validation loss: 0.003612661734223366\n",
            "MCC Train: 0.24679908566895867 MCC val: 0.2853777202468623\n",
            "\n",
            "Epoch: 8\n",
            "Training loss: 0.0036396654322743416 Validation loss: 0.0035794347058981657\n",
            "MCC Train: 0.296792788896317 MCC val: 0.291270393997092\n",
            "\n",
            "Epoch: 9\n",
            "Training loss: 0.003662318456918001 Validation loss: 0.0035571230109781027\n",
            "MCC Train: 0.27733567757482924 MCC val: 0.28676705429559596\n",
            "\n",
            "Epoch: 10\n",
            "Training loss: 0.0035697633866220713 Validation loss: 0.0035208011977374554\n",
            "MCC Train: 0.3135937690200967 MCC val: 0.29287540019066877\n",
            "\n",
            "Epoch: 11\n",
            "Training loss: 0.003524627536535263 Validation loss: 0.003516363212838769\n",
            "MCC Train: 0.31599030988732435 MCC val: 0.2800319029240635\n",
            "\n",
            "Epoch: 12\n",
            "Training loss: 0.003539440454915166 Validation loss: 0.0034450313542038202\n",
            "MCC Train: 0.32658954269139245 MCC val: 0.2933346364450918\n",
            "\n",
            "Epoch: 13\n",
            "Training loss: 0.003449773881584406 Validation loss: 0.003455108730122447\n",
            "MCC Train: 0.34612105309210406 MCC val: 0.281503020296168\n",
            "\n",
            "Epoch: 14\n",
            "Training loss: 0.003407188458368182 Validation loss: 0.0034446220379322767\n",
            "MCC Train: 0.3592485929651943 MCC val: 0.2829080227290231\n",
            "\n",
            "Epoch: 15\n",
            "Training loss: 0.0033369045704603195 Validation loss: 0.003415210172533989\n",
            "MCC Train: 0.36881087217112807 MCC val: 0.2930687471213998\n",
            "\n",
            "Epoch: 16\n",
            "Training loss: 0.003238979959860444 Validation loss: 0.0033299396745860577\n",
            "MCC Train: 0.38963575334063344 MCC val: 0.3223624095853329\n",
            "\n",
            "Epoch: 17\n",
            "Training loss: 0.003235240699723363 Validation loss: 0.003272975329309702\n",
            "MCC Train: 0.39229388341477867 MCC val: 0.3380604739925164\n",
            "\n",
            "Epoch: 18\n",
            "Training loss: 0.0031690222676843405 Validation loss: 0.003339961403980851\n",
            "MCC Train: 0.4208471647705658 MCC val: 0.3214114050122885\n",
            "\n",
            "Epoch: 19\n",
            "Training loss: 0.003082515439018607 Validation loss: 0.003237731521949172\n",
            "MCC Train: 0.44533525678389224 MCC val: 0.3650247600259207\n",
            "\n",
            "Epoch: 20\n",
            "Training loss: 0.003084431402385235 Validation loss: 0.0030551920644938946\n",
            "MCC Train: 0.4394596010190663 MCC val: 0.40045505242105145\n",
            "\n",
            "Epoch: 21\n",
            "Training loss: 0.0029630111530423164 Validation loss: 0.0030921248253434896\n",
            "MCC Train: 0.4639910220493596 MCC val: 0.39771438030878076\n",
            "\n",
            "Epoch: 22\n",
            "Training loss: 0.0029100326355546713 Validation loss: 0.0030171845573931932\n",
            "MCC Train: 0.4839845169593402 MCC val: 0.418963956674677\n",
            "\n",
            "Epoch: 23\n",
            "Training loss: 0.0028090192936360836 Validation loss: 0.0028398167341947556\n",
            "MCC Train: 0.5100113514060567 MCC val: 0.48361490997053674\n",
            "\n",
            "Epoch: 24\n",
            "Training loss: 0.0027424031868577003 Validation loss: 0.002869240241125226\n",
            "MCC Train: 0.5354410986885566 MCC val: 0.4885580245214795\n",
            "\n",
            "Epoch: 25\n",
            "Training loss: 0.0026148080360144377 Validation loss: 0.00279657612554729\n",
            "MCC Train: 0.5598869024711911 MCC val: 0.5144804634490179\n",
            "\n",
            "Epoch: 26\n",
            "Training loss: 0.002490309067070484 Validation loss: 0.0027434476651251316\n",
            "MCC Train: 0.57858558349558 MCC val: 0.5318715696642825\n",
            "\n",
            "Epoch: 27\n",
            "Training loss: 0.0024248489644378424 Validation loss: 0.0026915869675576687\n",
            "MCC Train: 0.6001959979127943 MCC val: 0.5272521522396506\n",
            "\n",
            "Epoch: 28\n",
            "Training loss: 0.002358660800382495 Validation loss: 0.0026983143761754036\n",
            "MCC Train: 0.6123087958982991 MCC val: 0.5233587512119383\n",
            "\n",
            "Epoch: 29\n",
            "Training loss: 0.002247052965685725 Validation loss: 0.002643272513523698\n",
            "MCC Train: 0.6263436702801837 MCC val: 0.5401489342628045\n",
            "\n",
            "Epoch: 30\n",
            "Training loss: 0.002118106698617339 Validation loss: 0.0026891117449849844\n",
            "MCC Train: 0.6530219354839382 MCC val: 0.543275509414857\n",
            "\n",
            "Epoch: 31\n",
            "Training loss: 0.0021124877966940403 Validation loss: 0.002711983397603035\n",
            "MCC Train: 0.6565950443955658 MCC val: 0.5486103943266418\n",
            "\n",
            "Epoch: 32\n",
            "Training loss: 0.0020071829203516245 Validation loss: 0.002769134007394314\n",
            "MCC Train: 0.6745772489379884 MCC val: 0.5411664373959527\n",
            "\n",
            "Epoch: 33\n",
            "Training loss: 0.0019615269266068935 Validation loss: 0.0027466993778944016\n",
            "MCC Train: 0.6809119886342786 MCC val: 0.549666667616418\n",
            "\n",
            "Epoch: 34\n",
            "Training loss: 0.0019123677629977465 Validation loss: 0.002763089258223772\n",
            "MCC Train: 0.6747979537101597 MCC val: 0.5593013356512836\n",
            "\n",
            "Epoch: 35\n",
            "Training loss: 0.0018736216006800532 Validation loss: 0.0028191215824335814\n",
            "MCC Train: 0.6919322234000604 MCC val: 0.574928376494638\n",
            "\n",
            "Epoch: 36\n",
            "Training loss: 0.001768744783475995 Validation loss: 0.0028304019942879677\n",
            "MCC Train: 0.6911486552937343 MCC val: 0.5507635605054404\n",
            "\n",
            "Epoch: 37\n",
            "Training loss: 0.0017900257371366024 Validation loss: 0.002874811412766576\n",
            "MCC Train: 0.6957174835607018 MCC val: 0.5422481549342468\n",
            "\n",
            "Epoch: 38\n",
            "Training loss: 0.0016413952689617872 Validation loss: 0.002923480235040188\n",
            "MCC Train: 0.7211577966672343 MCC val: 0.5560961704039983\n",
            "\n",
            "Epoch: 39\n",
            "Training loss: 0.0016501015052199364 Validation loss: 0.0029743611812591553\n",
            "MCC Train: 0.7142947114867716 MCC val: 0.559401673717678\n",
            "Early stopping\n",
            "\n",
            "0.0001\t0.1\t0.0005\t3\tTrue\ttrain_losses\tearly_stopping_model_0.0001_0.1_0.0005_3_True.pt\t0.0043396815,0.0042380844,0.00405895,0.0039185276,0.0038804244,0.0038029938,0.0037620384,0.0036396654,0.0036623185,0.0035697634,0.0035246275,0.0035394405,0.0034497739,0.0034071885,0.0033369046,0.00323898,0.0032352407,0.0031690223,0.0030825154,0.0030844314,0.0029630112,0.0029100326,0.0028090193,0.0027424032,0.002614808,0.002490309,0.002424849,0.0023586608,0.002247053,0.0021181067,0.0021124878,0.002007183,0.001961527,0.0019123678,0.0018736216,0.0017687448,0.0017900257,0.0016413953,0.0016501015\n",
            "\n",
            "0.0001\t0.1\t0.0005\t3\tTrue\tval_losses\tearly_stopping_model_0.0001_0.1_0.0005_3_True.pt\t0.0040120087,0.0039240257,0.0038102004,0.0037365337,0.0036849116,0.0036315327,0.0036126617,0.0035794347,0.003557123,0.0035208012,0.0035163632,0.0034450314,0.0034551087,0.003444622,0.0034152102,0.0033299397,0.0032729753,0.0033399614,0.0032377315,0.003055192,0.0030921248,0.0030171846,0.0028398167,0.0028692402,0.0027965761,0.0027434477,0.002691587,0.0026983144,0.0026432725,0.0026891117,0.0027119834,0.002769134,0.0027466994,0.0027630893,0.0028191216,0.002830402,0.0028748114,0.0029234802,0.0029743612\n",
            "\n",
            "0.0001\t0.1\t0.0005\t3\tTrue\ttrain_acc\tearly_stopping_model_0.0001_0.1_0.0005_3_True.pt\t0.45400095831336845,0.5294681360804984,0.5424053665548635,0.5975083852419741,0.6257786296118831,0.6288931480594154,0.6432678485864878,0.672975563009104,0.663392429324389,0.6847149017728797,0.6780067081935793,0.6919022520364159,0.7053186391950168,0.7134643028270244,0.7206516530905606,0.7326305701964543,0.7436511739338764,0.7525155725922377,0.7716818399616675,0.7738380450407283,0.7877335888835649,0.7973167225682798,0.8097747963584092,0.8205558217537134,0.8294202204120747,0.8387637757546718,0.8469094393866794,0.8512218495448012,0.8545759463344513,0.8641590800191663,0.8629611883085769,0.8720651653090561,0.8713464302827024,0.868471490177288,0.8754192620987062,0.8735026353617633,0.8758984187829421,0.8873981792046,0.8840440824149497\n",
            "\n",
            "0.0001\t0.1\t0.0005\t3\tTrue\tval_acc\tearly_stopping_model_0.0001_0.1_0.0005_3_True.pt\t0.49869451697127937,0.5019582245430809,0.5783289817232375,0.6005221932114883,0.6318537859007833,0.6566579634464752,0.6377284595300261,0.6533942558746736,0.6364229765013055,0.6546997389033943,0.6344647519582245,0.6527415143603134,0.6344647519582245,0.6331592689295039,0.6429503916449086,0.6814621409921671,0.6945169712793734,0.6697127937336814,0.7154046997389034,0.7467362924281984,0.7408616187989556,0.7571801566579635,0.7930809399477807,0.7878590078328982,0.7989556135770235,0.8067885117493473,0.8009138381201044,0.7930809399477807,0.8067885117493473,0.806135770234987,0.8080939947780679,0.8028720626631853,0.8080939947780679,0.8126631853785901,0.8231070496083551,0.8093994778067886,0.8028720626631853,0.8113577023498695,0.8139686684073107\n",
            "\n",
            "0.0001 0.1 0.005 2 False\n",
            "\n",
            "Epoch: 1\n",
            "Training loss: 0.012132013216614723 Validation loss: 0.010395134799182415\n",
            "MCC Train: 0.014105911729776339 MCC val: 0.1422316150170883\n",
            "\n",
            "Epoch: 2\n",
            "Training loss: 0.010535715147852898 Validation loss: 0.00950255710631609\n",
            "MCC Train: 0.10017826502278476 MCC val: 0.23551219382558716\n",
            "\n",
            "Epoch: 3\n",
            "Training loss: 0.009756285697221756 Validation loss: 0.009225813671946526\n",
            "MCC Train: 0.14128833684251657 MCC val: 0.29459819852493435\n",
            "\n",
            "Epoch: 4\n",
            "Training loss: 0.009079535491764545 Validation loss: 0.008746408857405186\n",
            "MCC Train: 0.19504609603135525 MCC val: 0.33738886721369704\n",
            "\n",
            "Epoch: 5\n",
            "Training loss: 0.008760341443121433 Validation loss: 0.008371151983737946\n",
            "MCC Train: 0.23085106165357294 MCC val: 0.3977059317567977\n",
            "\n",
            "Epoch: 6\n",
            "Training loss: 0.008428093045949936 Validation loss: 0.008018439635634422\n",
            "MCC Train: 0.26252820380472197 MCC val: 0.453439022283502\n",
            "\n",
            "Epoch: 7\n",
            "Training loss: 0.008286891505122185 Validation loss: 0.008042245171964169\n",
            "MCC Train: 0.284771573266794 MCC val: 0.41736284895247155\n",
            "\n",
            "Epoch: 8\n",
            "Training loss: 0.008105489425361156 Validation loss: 0.007709564175456762\n",
            "MCC Train: 0.3172886324311191 MCC val: 0.48430223551568574\n",
            "\n",
            "Epoch: 9\n",
            "Training loss: 0.007926706224679947 Validation loss: 0.0076392232440412045\n",
            "MCC Train: 0.35061411298673495 MCC val: 0.46772141946463475\n",
            "\n",
            "Epoch: 10\n",
            "Training loss: 0.007865349762141705 Validation loss: 0.007454821839928627\n",
            "MCC Train: 0.3934945873577585 MCC val: 0.48218746144933883\n",
            "\n",
            "Epoch: 11\n",
            "Training loss: 0.007605537306517363 Validation loss: 0.007444607559591532\n",
            "MCC Train: 0.3962624581814287 MCC val: 0.48218746144933883\n",
            "\n",
            "Epoch: 12\n",
            "Training loss: 0.007386023178696632 Validation loss: 0.007375223096460104\n",
            "MCC Train: 0.44542152850917177 MCC val: 0.48452453832833803\n",
            "\n",
            "Epoch: 13\n",
            "Training loss: 0.007154548540711403 Validation loss: 0.0070757558569312096\n",
            "MCC Train: 0.4796365292023561 MCC val: 0.5029476736451317\n",
            "\n",
            "Epoch: 14\n",
            "Training loss: 0.007167471572756767 Validation loss: 0.006936079356819391\n",
            "MCC Train: 0.45386263433016705 MCC val: 0.5206277009919601\n",
            "\n",
            "Epoch: 15\n",
            "Training loss: 0.007036109920591116 Validation loss: 0.006869327276945114\n",
            "MCC Train: 0.47491906812160267 MCC val: 0.5237935602652075\n",
            "\n",
            "Epoch: 16\n",
            "Training loss: 0.0069512417539954185 Validation loss: 0.006805507466197014\n",
            "MCC Train: 0.5076533283507844 MCC val: 0.5280173375963225\n",
            "\n",
            "Epoch: 17\n",
            "Training loss: 0.006732585374265909 Validation loss: 0.006754150148481131\n",
            "MCC Train: 0.5291355371076372 MCC val: 0.5237935602652075\n",
            "\n",
            "Epoch: 18\n",
            "Training loss: 0.006610121112316847 Validation loss: 0.006557967513799667\n",
            "MCC Train: 0.5184221893770022 MCC val: 0.552557148858144\n",
            "\n",
            "Epoch: 19\n",
            "Training loss: 0.006413815077394247 Validation loss: 0.006838626228272915\n",
            "MCC Train: 0.546486442989562 MCC val: 0.5079203998475647\n",
            "\n",
            "Epoch: 20\n",
            "Training loss: 0.006302701309323311 Validation loss: 0.006638583727180958\n",
            "MCC Train: 0.5749245194345548 MCC val: 0.5297485051371877\n",
            "\n",
            "Epoch: 21\n",
            "Training loss: 0.006222084164619446 Validation loss: 0.00649501197040081\n",
            "MCC Train: 0.573233790782444 MCC val: 0.5542869676919993\n",
            "\n",
            "Epoch: 22\n",
            "Training loss: 0.006115644238889217 Validation loss: 0.006609998177736998\n",
            "MCC Train: 0.5801716126860442 MCC val: 0.5372429040458467\n",
            "\n",
            "Epoch: 23\n",
            "Training loss: 0.006039085332304239 Validation loss: 0.006487136706709862\n",
            "MCC Train: 0.5791001383194376 MCC val: 0.552193726344897\n",
            "\n",
            "Epoch: 24\n",
            "Training loss: 0.0058811260387301445 Validation loss: 0.006454550661146641\n",
            "MCC Train: 0.5819848218359759 MCC val: 0.5594495542400858\n",
            "\n",
            "Epoch: 25\n",
            "Training loss: 0.0057925996370613575 Validation loss: 0.006349848583340645\n",
            "MCC Train: 0.606597182671444 MCC val: 0.5624719941398377\n",
            "\n",
            "Epoch: 26\n",
            "Training loss: 0.0055766175501048565 Validation loss: 0.006366530433297157\n",
            "MCC Train: 0.6188155563395098 MCC val: 0.5573006655567453\n",
            "\n",
            "Epoch: 27\n",
            "Training loss: 0.005629881750792265 Validation loss: 0.006369269452989101\n",
            "MCC Train: 0.6144938011543343 MCC val: 0.5701470413666182\n",
            "\n",
            "Epoch: 28\n",
            "Training loss: 0.0054328260011971 Validation loss: 0.006253881845623255\n",
            "MCC Train: 0.6291854921377926 MCC val: 0.5765290832578133\n",
            "\n",
            "Epoch: 29\n",
            "Training loss: 0.0052514998242259026 Validation loss: 0.006369651295244694\n",
            "MCC Train: 0.6269814226126607 MCC val: 0.56581780885383\n",
            "\n",
            "Epoch: 30\n",
            "Training loss: 0.005143546033650637 Validation loss: 0.00618395721539855\n",
            "MCC Train: 0.64342570862758 MCC val: 0.5752777999074996\n",
            "\n",
            "Epoch: 31\n",
            "Training loss: 0.005023675039410591 Validation loss: 0.006430052686482668\n",
            "MCC Train: 0.6456260871160562 MCC val: 0.5540997596885072\n",
            "\n",
            "Epoch: 32\n",
            "Training loss: 0.005011276341974735 Validation loss: 0.006161942612379789\n",
            "MCC Train: 0.6494584084283386 MCC val: 0.5811989399441535\n",
            "\n",
            "Epoch: 33\n",
            "Training loss: 0.004933845717459917 Validation loss: 0.00617126002907753\n",
            "MCC Train: 0.6568065388045786 MCC val: 0.5771153358192975\n",
            "\n",
            "Epoch: 34\n",
            "Training loss: 0.004906885325908661 Validation loss: 0.006170468404889107\n",
            "MCC Train: 0.6553869556400812 MCC val: 0.5806859111811784\n",
            "\n",
            "Epoch: 35\n",
            "Training loss: 0.004669723566621542 Validation loss: 0.006229370832443237\n",
            "MCC Train: 0.6757886007510824 MCC val: 0.576409661868331\n",
            "\n",
            "Epoch: 36\n",
            "Training loss: 0.004645312670618296 Validation loss: 0.006077387370169163\n",
            "MCC Train: 0.672976025133332 MCC val: 0.5875128105239951\n",
            "\n",
            "Epoch: 37\n",
            "Training loss: 0.004485102836042643 Validation loss: 0.006118290591984987\n",
            "MCC Train: 0.6781319375542216 MCC val: 0.5916639038173239\n",
            "\n",
            "Epoch: 38\n",
            "Training loss: 0.004360629245638847 Validation loss: 0.00640243012458086\n",
            "MCC Train: 0.6960810860759679 MCC val: 0.5591226170537482\n",
            "\n",
            "Epoch: 39\n",
            "Training loss: 0.0042439899407327175 Validation loss: 0.006118748802691698\n",
            "MCC Train: 0.6889326105158408 MCC val: 0.5907343375069466\n",
            "\n",
            "Epoch: 40\n",
            "Training loss: 0.00426358450204134 Validation loss: 0.006138787139207125\n",
            "MCC Train: 0.7140065049715094 MCC val: 0.5948242325068267\n",
            "\n",
            "Epoch: 41\n",
            "Training loss: 0.004012458026409149 Validation loss: 0.006241722963750362\n",
            "MCC Train: 0.71965746715691 MCC val: 0.5786207538795398\n",
            "\n",
            "Epoch: 42\n",
            "Training loss: 0.003957531414926052 Validation loss: 0.005915489979088306\n",
            "MCC Train: 0.7155625867589108 MCC val: 0.6016158113197271\n",
            "\n",
            "Epoch: 43\n",
            "Training loss: 0.0038605143781751394 Validation loss: 0.006060143932700157\n",
            "MCC Train: 0.7247352162560323 MCC val: 0.5828394038980665\n",
            "\n",
            "Epoch: 44\n",
            "Training loss: 0.0037117921747267246 Validation loss: 0.006218557711690664\n",
            "MCC Train: 0.7352882916329628 MCC val: 0.5855635659481077\n",
            "\n",
            "Epoch: 45\n",
            "Training loss: 0.003586204256862402 Validation loss: 0.00632195919752121\n",
            "MCC Train: 0.7443489709028444 MCC val: 0.5681157559818382\n",
            "\n",
            "Epoch: 46\n",
            "Training loss: 0.003547554137185216 Validation loss: 0.0061132959090173244\n",
            "MCC Train: 0.748665640419151 MCC val: 0.5980049139685705\n",
            "\n",
            "Epoch: 47\n",
            "Training loss: 0.0033812217880040407 Validation loss: 0.006061164196580648\n",
            "MCC Train: 0.7530281975160747 MCC val: 0.5945825581528459\n",
            "\n",
            "Epoch: 48\n",
            "Training loss: 0.0034022117033600807 Validation loss: 0.006031970959156752\n",
            "MCC Train: 0.7670628417565099 MCC val: 0.6065101310885747\n",
            "\n",
            "Epoch: 49\n",
            "Training loss: 0.0031524747610092163 Validation loss: 0.006127653643488884\n",
            "MCC Train: 0.7744761512859223 MCC val: 0.5945825581528459\n",
            "\n",
            "Epoch: 50\n",
            "Training loss: 0.0031107559334486723 Validation loss: 0.006141531281173229\n",
            "MCC Train: 0.785367367614791 MCC val: 0.5737758503797458\n",
            "0.0001\t0.1\t0.005\t2\tFalse\ttrain_losses\tearly_stopping_model_0.0001_0.1_0.005_2_False.pt\t0.012132013,0.010535715,0.009756286,0.0090795355,0.008760341,0.008428093,0.0082868915,0.008105489,0.007926706,0.00786535,0.0076055373,0.007386023,0.0071545485,0.0071674716,0.00703611,0.0069512418,0.0067325854,0.006610121,0.006413815,0.0063027013,0.006222084,0.0061156442,0.0060390853,0.005881126,0.0057925996,0.0055766176,0.0056298818,0.005432826,0.0052515,0.005143546,0.005023675,0.0050112763,0.0049338457,0.0049068853,0.0046697236,0.0046453127,0.004485103,0.0043606292,0.00424399,0.0042635845,0.004012458,0.0039575314,0.0038605144,0.0037117922,0.0035862043,0.0035475541,0.0033812218,0.0034022117,0.0031524748,0.003110756\n",
            "\n",
            "0.0001\t0.1\t0.005\t2\tFalse\tval_losses\tearly_stopping_model_0.0001_0.1_0.005_2_False.pt\t0.010395135,0.009502557,0.009225814,0.008746409,0.008371152,0.00801844,0.008042245,0.007709564,0.0076392232,0.007454822,0.0074446076,0.007375223,0.007075756,0.0069360794,0.0068693273,0.0068055075,0.00675415,0.0065579675,0.006838626,0.0066385837,0.006495012,0.006609998,0.0064871367,0.0064545507,0.0063498486,0.0063665304,0.0063692695,0.006253882,0.0063696513,0.006183957,0.0064300527,0.0061619426,0.00617126,0.0061704684,0.006229371,0.0060773874,0.0061182906,0.00640243,0.006118749,0.006138787,0.006241723,0.00591549,0.006060144,0.0062185577,0.006321959,0.006113296,0.006061164,0.006031971,0.0061276536,0.0061415313\n",
            "\n",
            "0.0001\t0.1\t0.005\t2\tFalse\ttrain_acc\tearly_stopping_model_0.0001_0.1_0.005_2_False.pt\t0.509343555342597,0.6229036895064686,0.667465261140393,0.7146621945376138,0.7383804504072832,0.7534738859607092,0.761379971250599,0.7728797316722569,0.7848586487781505,0.7970771442261619,0.7982750359367513,0.8124101581217058,0.8229516051748922,0.8148059415428845,0.8210349784379493,0.8315764254911356,0.8385241974125539,0.8351701006229036,0.8435553425970292,0.8526593195975084,0.8521801629132726,0.8543363679923335,0.8538572113080978,0.8550551030186871,0.8627216099664591,0.866554863440345,0.8651173933876377,0.8699089602299952,0.8691902252036416,0.8744609487302348,0.8751796837565884,0.8763775754671778,0.8787733588883565,0.8782942022041208,0.8850023957834212,0.8840440824149497,0.8857211308097748,0.8917105893627216,0.8893148059415429,0.8977000479156684,0.8996166746526114,0.8981792045999042,0.9012937230474365,0.9048873981792046,0.9080019166267369,0.9094393866794441,0.9108768567321515,0.9156684235745088,0.9183037853378054,0.9221370388116914\n",
            "\n",
            "0.0001\t0.1\t0.005\t2\tFalse\tval_acc\tearly_stopping_model_0.0001_0.1_0.005_2_False.pt\t0.6155352480417755,0.7010443864229765,0.7245430809399478,0.7506527415143603,0.7774151436031331,0.804177545691906,0.7839425587467362,0.8159268929503917,0.8080939947780679,0.8139686684073107,0.8139686684073107,0.8139686684073107,0.8231070496083551,0.8302872062663186,0.8315926892950392,0.8335509138381201,0.8315926892950392,0.8433420365535248,0.8237597911227154,0.8335509138381201,0.8439947780678851,0.8368146214099217,0.8426892950391645,0.8453002610966057,0.8466057441253264,0.8446475195822454,0.8485639686684073,0.8505221932114883,0.8459530026109661,0.8498694516971279,0.8407310704960835,0.8518276762402088,0.8498694516971279,0.8505221932114883,0.847911227154047,0.8524804177545692,0.8531331592689295,0.839425587467363,0.8518276762402088,0.8537859007832899,0.8466057441253264,0.856396866840731,0.847911227154047,0.8485639686684073,0.8407310704960835,0.8544386422976501,0.8511749347258486,0.856396866840731,0.8511749347258486,0.8426892950391645\n",
            "\n",
            "0.0001 0.1 0.005 2 True\n",
            "loss weight 0.2496406324868232\n",
            "\n",
            "Epoch: 1\n",
            "Training loss: 0.005092053208500147 Validation loss: 0.004065440967679024\n",
            "MCC Train: 0.039404761966567496 MCC val: 0.07535245288081964\n",
            "\n",
            "Epoch: 2\n",
            "Training loss: 0.004633436445146799 Validation loss: 0.003881702432408929\n",
            "MCC Train: 0.043923899753390824 MCC val: 0.14326105276898105\n",
            "\n",
            "Epoch: 3\n",
            "Training loss: 0.004347075708210468 Validation loss: 0.0037535622250288725\n",
            "MCC Train: 0.08103996675340439 MCC val: 0.20665765800289054\n",
            "\n",
            "Epoch: 4\n",
            "Training loss: 0.004115086514502764 Validation loss: 0.00369049608707428\n",
            "MCC Train: 0.1384232203134338 MCC val: 0.250338634979612\n",
            "\n",
            "Epoch: 5\n",
            "Training loss: 0.003970095422118902 Validation loss: 0.0036158913280814886\n",
            "MCC Train: 0.1841398723518069 MCC val: 0.2750202188562863\n",
            "\n",
            "Epoch: 6\n",
            "Training loss: 0.003825125750154257 Validation loss: 0.003586370963603258\n",
            "MCC Train: 0.21783681697535998 MCC val: 0.2766272564561787\n",
            "\n",
            "Epoch: 7\n",
            "Training loss: 0.0037496669683605433 Validation loss: 0.0035345773212611675\n",
            "MCC Train: 0.2540951313485627 MCC val: 0.2944156760521607\n",
            "\n",
            "Epoch: 8\n",
            "Training loss: 0.0037375823594629765 Validation loss: 0.0034982364159077406\n",
            "MCC Train: 0.23255160169333824 MCC val: 0.3028075581846253\n",
            "\n",
            "Epoch: 9\n",
            "Training loss: 0.0036315363831818104 Validation loss: 0.003460645442828536\n",
            "MCC Train: 0.28267084097397505 MCC val: 0.3116489966694857\n",
            "\n",
            "Epoch: 10\n",
            "Training loss: 0.0035359859466552734 Validation loss: 0.0034240372478961945\n",
            "MCC Train: 0.30138293962943374 MCC val: 0.32554089811765086\n",
            "\n",
            "Epoch: 11\n",
            "Training loss: 0.0034741945564746857 Validation loss: 0.003402134170755744\n",
            "MCC Train: 0.3107543097369502 MCC val: 0.31402972909260396\n",
            "\n",
            "Epoch: 12\n",
            "Training loss: 0.0035343351773917675 Validation loss: 0.0033545938786119223\n",
            "MCC Train: 0.30434005577838835 MCC val: 0.34896133682061153\n",
            "\n",
            "Epoch: 13\n",
            "Training loss: 0.003404243616387248 Validation loss: 0.0033270888961851597\n",
            "MCC Train: 0.32110270608430724 MCC val: 0.33099963421739165\n",
            "\n",
            "Epoch: 14\n",
            "Training loss: 0.0033415460493415594 Validation loss: 0.003293807851150632\n",
            "MCC Train: 0.3543977285897004 MCC val: 0.3370584501612696\n",
            "\n",
            "Epoch: 15\n",
            "Training loss: 0.0033796897623687983 Validation loss: 0.003264644183218479\n",
            "MCC Train: 0.3546551656655055 MCC val: 0.37614940129292146\n",
            "\n",
            "Epoch: 16\n",
            "Training loss: 0.003234995761886239 Validation loss: 0.0032549514435231686\n",
            "MCC Train: 0.3761602344288924 MCC val: 0.37660691655602185\n",
            "\n",
            "Epoch: 17\n",
            "Training loss: 0.003218800062313676 Validation loss: 0.003213358810171485\n",
            "MCC Train: 0.3721002976468245 MCC val: 0.40158783026547623\n",
            "\n",
            "Epoch: 18\n",
            "Training loss: 0.003144890535622835 Validation loss: 0.0032102635595947504\n",
            "MCC Train: 0.3993307467477185 MCC val: 0.38700443319212413\n",
            "\n",
            "Epoch: 19\n",
            "Training loss: 0.0030761011876165867 Validation loss: 0.003167735645547509\n",
            "MCC Train: 0.4154870469868883 MCC val: 0.42974824593791555\n",
            "\n",
            "Epoch: 20\n",
            "Training loss: 0.0030730797443538904 Validation loss: 0.00314724282361567\n",
            "MCC Train: 0.42552139988874205 MCC val: 0.4274927933549862\n",
            "\n",
            "Epoch: 21\n",
            "Training loss: 0.0029659217689186335 Validation loss: 0.0031322964932769537\n",
            "MCC Train: 0.44572849270496123 MCC val: 0.42863056977053376\n",
            "\n",
            "Epoch: 22\n",
            "Training loss: 0.0028893817216157913 Validation loss: 0.003109381766989827\n",
            "MCC Train: 0.4550933787348544 MCC val: 0.4434726836340905\n",
            "\n",
            "Epoch: 23\n",
            "Training loss: 0.0028930800035595894 Validation loss: 0.0030802038963884115\n",
            "MCC Train: 0.4575203026263348 MCC val: 0.48566757222579765\n",
            "\n",
            "Epoch: 24\n",
            "Training loss: 0.0028814615216106176 Validation loss: 0.003075910033658147\n",
            "MCC Train: 0.45880688580454365 MCC val: 0.469717916025055\n",
            "\n",
            "Epoch: 25\n",
            "Training loss: 0.0028469793032854795 Validation loss: 0.003030128078535199\n",
            "MCC Train: 0.47934562787278645 MCC val: 0.4721096040143711\n",
            "\n",
            "Epoch: 26\n",
            "Training loss: 0.002726455219089985 Validation loss: 0.0030192912090569735\n",
            "MCC Train: 0.5009165152926369 MCC val: 0.5004488965200021\n",
            "\n",
            "Epoch: 27\n",
            "Training loss: 0.002639179117977619 Validation loss: 0.002988338703289628\n",
            "MCC Train: 0.5278900906707159 MCC val: 0.4926251994241128\n",
            "\n",
            "Epoch: 28\n",
            "Training loss: 0.0025867298245429993 Validation loss: 0.0030170907266438007\n",
            "MCC Train: 0.5329264292765442 MCC val: 0.5268828673966078\n",
            "\n",
            "Epoch: 29\n",
            "Training loss: 0.0025322078727185726 Validation loss: 0.002990138018503785\n",
            "MCC Train: 0.5596166767078773 MCC val: 0.5151793211612729\n",
            "\n",
            "Epoch: 30\n",
            "Training loss: 0.002472745953127742 Validation loss: 0.002994480077177286\n",
            "MCC Train: 0.5572788658854212 MCC val: 0.5270578346003835\n",
            "\n",
            "Epoch: 31\n",
            "Training loss: 0.0024640175979584455 Validation loss: 0.0029780520126223564\n",
            "MCC Train: 0.566102677209521 MCC val: 0.5302562910467881\n",
            "\n",
            "Epoch: 32\n",
            "Training loss: 0.0024125296622514725 Validation loss: 0.0029909838922321796\n",
            "MCC Train: 0.5919045682425912 MCC val: 0.5004061783682809\n",
            "\n",
            "Epoch: 33\n",
            "Training loss: 0.002339698141440749 Validation loss: 0.002945117186754942\n",
            "MCC Train: 0.5952680678442771 MCC val: 0.5319988887845467\n",
            "\n",
            "Epoch: 34\n",
            "Training loss: 0.0023495815694332123 Validation loss: 0.002948059933260083\n",
            "MCC Train: 0.5869129205931106 MCC val: 0.5530407863943189\n",
            "\n",
            "Epoch: 35\n",
            "Training loss: 0.0022780962754040956 Validation loss: 0.0029273228719830513\n",
            "MCC Train: 0.601583609486802 MCC val: 0.5400943285222348\n",
            "\n",
            "Epoch: 36\n",
            "Training loss: 0.0021663280203938484 Validation loss: 0.0029425788670778275\n",
            "MCC Train: 0.6248196944931451 MCC val: 0.5168705798294371\n",
            "\n",
            "Epoch: 37\n",
            "Training loss: 0.002132550347596407 Validation loss: 0.002927245106548071\n",
            "MCC Train: 0.6248196944931451 MCC val: 0.5125692857821982\n",
            "\n",
            "Epoch: 38\n",
            "Training loss: 0.002082611434161663 Validation loss: 0.0029916041530668736\n",
            "MCC Train: 0.6419202464936475 MCC val: 0.5169759193738531\n",
            "\n",
            "Epoch: 39\n",
            "Training loss: 0.0020540920086205006 Validation loss: 0.0029573484789580107\n",
            "MCC Train: 0.6536824168435774 MCC val: 0.5403329417554557\n",
            "\n",
            "Epoch: 40\n",
            "Training loss: 0.0020458525978028774 Validation loss: 0.002993379719555378\n",
            "MCC Train: 0.6609051436711962 MCC val: 0.5385477444628751\n",
            "\n",
            "Epoch: 41\n",
            "Training loss: 0.0019041933119297028 Validation loss: 0.0029435167089104652\n",
            "MCC Train: 0.7023780405322648 MCC val: 0.542815534758785\n",
            "\n",
            "Epoch: 42\n",
            "Training loss: 0.0018972402904182673 Validation loss: 0.0029171365313231945\n",
            "MCC Train: 0.679413165474743 MCC val: 0.5396770417422587\n",
            "\n",
            "Epoch: 43\n",
            "Training loss: 0.0019042881904169917 Validation loss: 0.0030033006332814693\n",
            "MCC Train: 0.6743657861888229 MCC val: 0.5612420596317526\n",
            "\n",
            "Epoch: 44\n",
            "Training loss: 0.0018422264838591218 Validation loss: 0.00296835508197546\n",
            "MCC Train: 0.7047618623190978 MCC val: 0.5393702941891104\n",
            "\n",
            "Epoch: 45\n",
            "Training loss: 0.001842656871303916 Validation loss: 0.002938065677881241\n",
            "MCC Train: 0.6958888295120229 MCC val: 0.5622340125789164\n",
            "\n",
            "Epoch: 46\n",
            "Training loss: 0.0017208770150318742 Validation loss: 0.0030207931995391846\n",
            "MCC Train: 0.7125346580411455 MCC val: 0.5533047167605191\n",
            "\n",
            "Epoch: 47\n",
            "Training loss: 0.0017630779184401035 Validation loss: 0.0029490909073501825\n",
            "MCC Train: 0.6975180808200916 MCC val: 0.5609519845650939\n",
            "\n",
            "Epoch: 48\n",
            "Training loss: 0.0017186974873766303 Validation loss: 0.0029697094578295946\n",
            "MCC Train: 0.7355450879827055 MCC val: 0.5736830552488502\n",
            "\n",
            "Epoch: 49\n",
            "Training loss: 0.0016318375710397959 Validation loss: 0.0030134511180222034\n",
            "MCC Train: 0.7448641250389555 MCC val: 0.5694584634870847\n",
            "\n",
            "Epoch: 50\n",
            "Training loss: 0.0016090228455141187 Validation loss: 0.0030587429646402597\n",
            "MCC Train: 0.7411536077540617 MCC val: 0.5525739454321038\n",
            "0.0001\t0.1\t0.005\t2\tTrue\ttrain_losses\tearly_stopping_model_0.0001_0.1_0.005_2_True.pt\t0.005092053,0.0046334364,0.0043470757,0.0041150865,0.0039700954,0.0038251258,0.003749667,0.0037375824,0.0036315364,0.003535986,0.0034741946,0.0035343352,0.0034042436,0.003341546,0.0033796898,0.0032349958,0.0032188,0.0031448905,0.0030761012,0.0030730797,0.0029659218,0.0028893817,0.00289308,0.0028814615,0.0028469793,0.0027264552,0.0026391791,0.0025867298,0.0025322079,0.002472746,0.0024640176,0.0024125297,0.0023396981,0.0023495816,0.0022780963,0.002166328,0.0021325503,0.0020826114,0.002054092,0.0020458526,0.0019041933,0.0018972403,0.0019042882,0.0018422265,0.0018426569,0.001720877,0.0017630779,0.0017186975,0.0016318376,0.0016090228\n",
            "\n",
            "0.0001\t0.1\t0.005\t2\tTrue\tval_losses\tearly_stopping_model_0.0001_0.1_0.005_2_True.pt\t0.004065441,0.0038817024,0.0037535622,0.003690496,0.0036158913,0.003586371,0.0035345773,0.0034982364,0.0034606454,0.0034240372,0.0034021342,0.0033545939,0.003327089,0.0032938079,0.0032646442,0.0032549514,0.0032133588,0.0032102636,0.0031677356,0.0031472428,0.0031322965,0.0031093818,0.003080204,0.00307591,0.003030128,0.0030192912,0.0029883387,0.0030170907,0.002990138,0.00299448,0.002978052,0.002990984,0.0029451172,0.00294806,0.0029273229,0.0029425789,0.002927245,0.0029916042,0.0029573485,0.0029933797,0.0029435167,0.0029171365,0.0030033006,0.002968355,0.0029380657,0.0030207932,0.002949091,0.0029697095,0.0030134511,0.003058743\n",
            "\n",
            "0.0001\t0.1\t0.005\t2\tTrue\ttrain_acc\tearly_stopping_model_0.0001_0.1_0.005_2_True.pt\t0.315764254911356,0.3543363679923335,0.4202204120747484,0.4784379492093915,0.5335409678965022,0.5728318160038333,0.6078102539530427,0.6073310972688069,0.6427886919022521,0.6564446574029708,0.6698610445615716,0.667225682798275,0.6804024916147581,0.6978917105893627,0.7022041207474844,0.7149017728797317,0.7129851461427887,0.7355055103018687,0.7431720172496407,0.7505989458552946,0.7599425011978918,0.7666506947771922,0.7690464781983709,0.7656923814087206,0.7812649736463824,0.7930043124101581,0.8042644944896982,0.8049832295160517,0.8188787733588884,0.8181600383325347,0.8203162434115956,0.8318160038332535,0.832534738859607,0.8291806420699569,0.8349305222807858,0.8454719693339722,0.8454719693339722,0.851461427886919,0.8572113080977479,0.8612841399137517,0.8770963104935314,0.8682319118351701,0.8653569717297557,0.8770963104935314,0.8761379971250599,0.8799712505989459,0.8730234786775275,0.8917105893627216,0.8933876377575467,0.892908481073311\n",
            "\n",
            "0.0001\t0.1\t0.005\t2\tTrue\tval_acc\tearly_stopping_model_0.0001_0.1_0.005_2_True.pt\t0.3877284595300261,0.49216710182767626,0.5802872062663186,0.6155352480417755,0.6618798955613577,0.6553524804177546,0.6768929503916449,0.6801566579634465,0.693864229765013,0.7030026109660574,0.6886422976501305,0.7186684073107049,0.7069190600522193,0.7121409921671018,0.7395561357702349,0.7382506527415144,0.7565274151436031,0.7434725848563969,0.7741514360313316,0.7715404699738904,0.7734986945169713,0.7826370757180157,0.8067885117493473,0.7943864229765013,0.7956919060052219,0.8133159268929504,0.806135770234987,0.8218015665796344,0.8172323759791122,0.8231070496083551,0.8204960835509139,0.8009138381201044,0.8204960835509139,0.8302872062663186,0.8237597911227154,0.8100522193211488,0.8087467362924282,0.8074412532637075,0.8211488250652742,0.8211488250652742,0.8224543080939948,0.8198433420365535,0.8335509138381201,0.8191906005221932,0.8315926892950392,0.8283289817232375,0.8309399477806788,0.8381201044386423,0.8368146214099217,0.8257180156657964\n",
            "\n",
            "0.0001 0.1 0.005 3 False\n",
            "\n",
            "Epoch: 1\n",
            "Training loss: 0.009590711444616318 Validation loss: 0.009796378202736378\n",
            "MCC Train: 0.020598546490074515 MCC val: 0.10364299116664\n",
            "\n",
            "Epoch: 2\n",
            "Training loss: 0.009079891256988049 Validation loss: 0.009114744141697884\n",
            "MCC Train: 0.026914269197042304 MCC val: 0.2289832815843079\n",
            "\n",
            "Epoch: 3\n",
            "Training loss: 0.008993559516966343 Validation loss: 0.008951323106884956\n",
            "MCC Train: 0.05921120286972204 MCC val: 0.29533597823536745\n",
            "\n",
            "Epoch: 4\n",
            "Training loss: 0.008777853101491928 Validation loss: 0.008883321657776833\n",
            "MCC Train: 0.055700779600712076 MCC val: 0.3449517155781279\n",
            "\n",
            "Epoch: 5\n",
            "Training loss: 0.008539346978068352 Validation loss: 0.00852209236472845\n",
            "MCC Train: 0.12173894566868017 MCC val: 0.39616068780582775\n",
            "\n",
            "Epoch: 6\n",
            "Training loss: 0.008392970077693462 Validation loss: 0.008474570699036121\n",
            "MCC Train: 0.15086854256786572 MCC val: 0.34854839615856487\n",
            "\n",
            "Epoch: 7\n",
            "Training loss: 0.008265200071036816 Validation loss: 0.008282269351184368\n",
            "MCC Train: 0.16812845978439905 MCC val: 0.37983317506954334\n",
            "\n",
            "Epoch: 8\n",
            "Training loss: 0.008216723799705505 Validation loss: 0.007988397032022476\n",
            "MCC Train: 0.2511837892546016 MCC val: 0.42400687479248367\n",
            "\n",
            "Epoch: 9\n",
            "Training loss: 0.007890870794653893 Validation loss: 0.008169668726623058\n",
            "MCC Train: 0.3000875944518088 MCC val: 0.40036192103390716\n",
            "\n",
            "Epoch: 10\n",
            "Training loss: 0.0077321529388427734 Validation loss: 0.007964398711919785\n",
            "MCC Train: 0.347223626671739 MCC val: 0.4440343116176301\n",
            "\n",
            "Epoch: 11\n",
            "Training loss: 0.007641309406608343 Validation loss: 0.007619917392730713\n",
            "MCC Train: 0.36578961080044503 MCC val: 0.4677106327577077\n",
            "\n",
            "Epoch: 12\n",
            "Training loss: 0.007591958157718182 Validation loss: 0.007520005106925964\n",
            "MCC Train: 0.4128547594617272 MCC val: 0.4816756905825872\n",
            "\n",
            "Epoch: 13\n",
            "Training loss: 0.007300931960344315 Validation loss: 0.00740951020270586\n",
            "MCC Train: 0.4444356031867219 MCC val: 0.4931879358550272\n",
            "\n",
            "Epoch: 14\n",
            "Training loss: 0.007210935465991497 Validation loss: 0.007267866283655167\n",
            "MCC Train: 0.45030565438989056 MCC val: 0.505836464037247\n",
            "\n",
            "Epoch: 15\n",
            "Training loss: 0.007081721443682909 Validation loss: 0.007234535180032253\n",
            "MCC Train: 0.470232268161558 MCC val: 0.5019910062527372\n",
            "\n",
            "Epoch: 16\n",
            "Training loss: 0.006960718892514706 Validation loss: 0.006930528208613396\n",
            "MCC Train: 0.4873698887914198 MCC val: 0.5312609073679634\n",
            "\n",
            "Epoch: 17\n",
            "Training loss: 0.006791041232645512 Validation loss: 0.006862442474812269\n",
            "MCC Train: 0.515134837218531 MCC val: 0.5285882979766714\n",
            "\n",
            "Epoch: 18\n",
            "Training loss: 0.0067276619374752045 Validation loss: 0.006733202841132879\n",
            "MCC Train: 0.5092454897334802 MCC val: 0.5440164630886352\n",
            "\n",
            "Epoch: 19\n",
            "Training loss: 0.006697368808090687 Validation loss: 0.0066250963136553764\n",
            "MCC Train: 0.5331020552049933 MCC val: 0.5569783927567084\n",
            "\n",
            "Epoch: 20\n",
            "Training loss: 0.006527604069560766 Validation loss: 0.0065165115520358086\n",
            "MCC Train: 0.538353215959421 MCC val: 0.5655847169849753\n",
            "\n",
            "Epoch: 21\n",
            "Training loss: 0.006336474325507879 Validation loss: 0.006372497417032719\n",
            "MCC Train: 0.5570869672766137 MCC val: 0.5769081734643465\n",
            "\n",
            "Epoch: 22\n",
            "Training loss: 0.006221138872206211 Validation loss: 0.0064829206094145775\n",
            "MCC Train: 0.5697641301782302 MCC val: 0.5440164630886352\n",
            "\n",
            "Epoch: 23\n",
            "Training loss: 0.005999103654175997 Validation loss: 0.006176610942929983\n",
            "MCC Train: 0.5712917166354484 MCC val: 0.5801644344474106\n",
            "\n",
            "Epoch: 24\n",
            "Training loss: 0.005827840883284807 Validation loss: 0.006238373462110758\n",
            "MCC Train: 0.5886324404206856 MCC val: 0.5716834918295849\n",
            "\n",
            "Epoch: 25\n",
            "Training loss: 0.005882639903575182 Validation loss: 0.006108473986387253\n",
            "MCC Train: 0.5878560110439207 MCC val: 0.5827612008474319\n",
            "\n",
            "Epoch: 26\n",
            "Training loss: 0.005752567667514086 Validation loss: 0.005973272491246462\n",
            "MCC Train: 0.5918532927878486 MCC val: 0.6056243753210593\n",
            "\n",
            "Epoch: 27\n",
            "Training loss: 0.005557186435908079 Validation loss: 0.0060369595885276794\n",
            "MCC Train: 0.6034844746780875 MCC val: 0.5888648195465092\n",
            "\n",
            "Epoch: 28\n",
            "Training loss: 0.005453246179968119 Validation loss: 0.006107471417635679\n",
            "MCC Train: 0.6164413561712907 MCC val: 0.5910799785862472\n",
            "\n",
            "Epoch: 29\n",
            "Training loss: 0.005245869513601065 Validation loss: 0.005922348704189062\n",
            "MCC Train: 0.6167365013568428 MCC val: 0.6044545566460876\n",
            "\n",
            "Epoch: 30\n",
            "Training loss: 0.005143884569406509 Validation loss: 0.006041570566594601\n",
            "MCC Train: 0.6276874126423149 MCC val: 0.6018905549065751\n",
            "\n",
            "Epoch: 31\n",
            "Training loss: 0.005128613673150539 Validation loss: 0.005875715054571629\n",
            "MCC Train: 0.6217942232662189 MCC val: 0.6238625056315997\n",
            "\n",
            "Epoch: 32\n",
            "Training loss: 0.004889751318842173 Validation loss: 0.005850326269865036\n",
            "MCC Train: 0.636674754161961 MCC val: 0.6243021636109887\n",
            "\n",
            "Epoch: 33\n",
            "Training loss: 0.004786454141139984 Validation loss: 0.00594725739210844\n",
            "MCC Train: 0.6515577166813357 MCC val: 0.635572591151521\n",
            "\n",
            "Epoch: 34\n",
            "Training loss: 0.0047308108769357204 Validation loss: 0.0059095523320138454\n",
            "MCC Train: 0.6465075765072024 MCC val: 0.6215949629106383\n",
            "\n",
            "Epoch: 35\n",
            "Training loss: 0.004515578970313072 Validation loss: 0.005916711408644915\n",
            "MCC Train: 0.6574909879786556 MCC val: 0.6243690757700282\n",
            "\n",
            "Epoch: 36\n",
            "Training loss: 0.004552355036139488 Validation loss: 0.00596958352252841\n",
            "MCC Train: 0.6787635942472805 MCC val: 0.6167868855890865\n",
            "\n",
            "Epoch: 37\n",
            "Training loss: 0.004404689650982618 Validation loss: 0.005947381258010864\n",
            "MCC Train: 0.679526023115014 MCC val: 0.6472499320402901\n",
            "\n",
            "Epoch: 38\n",
            "Training loss: 0.004261606372892857 Validation loss: 0.005983367096632719\n",
            "MCC Train: 0.6635524994304509 MCC val: 0.6287594988817412\n",
            "\n",
            "Epoch: 39\n",
            "Training loss: 0.004200775641947985 Validation loss: 0.006089390255510807\n",
            "MCC Train: 0.7044011019602225 MCC val: 0.6262912812314233\n",
            "\n",
            "Epoch: 40\n",
            "Training loss: 0.004090567119419575 Validation loss: 0.006037048064172268\n",
            "MCC Train: 0.7076894078640925 MCC val: 0.6271168146401059\n",
            "\n",
            "Epoch: 41\n",
            "Training loss: 0.0040880474261939526 Validation loss: 0.006136698182672262\n",
            "MCC Train: 0.7001149074562315 MCC val: 0.6116215966831562\n",
            "\n",
            "Epoch: 42\n",
            "Training loss: 0.0038922373205423355 Validation loss: 0.006160849239677191\n",
            "MCC Train: 0.6954119399283344 MCC val: 0.6223906209301582\n",
            "Early stopping\n",
            "\n",
            "0.0001\t0.1\t0.005\t3\tFalse\ttrain_losses\tearly_stopping_model_0.0001_0.1_0.005_3_False.pt\t0.009590711,0.009079891,0.0089935595,0.008777853,0.008539347,0.00839297,0.0082652,0.008216724,0.007890871,0.007732153,0.0076413094,0.007591958,0.007300932,0.0072109355,0.0070817214,0.006960719,0.006791041,0.006727662,0.006697369,0.006527604,0.0063364743,0.006221139,0.0059991037,0.005827841,0.00588264,0.0057525677,0.0055571864,0.005453246,0.0052458695,0.0051438846,0.0051286137,0.0048897513,0.004786454,0.004730811,0.004515579,0.004552355,0.0044046897,0.0042616064,0.0042007756,0.004090567,0.0040880474,0.0038922373\n",
            "\n",
            "0.0001\t0.1\t0.005\t3\tFalse\tval_losses\tearly_stopping_model_0.0001_0.1_0.005_3_False.pt\t0.009796378,0.009114744,0.008951323,0.008883322,0.008522092,0.008474571,0.008282269,0.007988397,0.008169669,0.007964399,0.0076199174,0.007520005,0.00740951,0.0072678663,0.007234535,0.006930528,0.0068624425,0.006733203,0.0066250963,0.0065165116,0.0063724974,0.0064829206,0.006176611,0.0062383735,0.006108474,0.0059732725,0.0060369596,0.0061074714,0.0059223487,0.0060415706,0.005875715,0.0058503263,0.0059472574,0.0059095523,0.0059167114,0.0059695835,0.0059473813,0.005983367,0.0060893903,0.006037048,0.006136698,0.0061608492\n",
            "\n",
            "0.0001\t0.1\t0.005\t3\tFalse\ttrain_acc\tearly_stopping_model_0.0001_0.1_0.005_3_False.pt\t0.6890273119310014,0.7357450886439866,0.7465261140392908,0.7455678006708194,0.752036415908002,0.753713464302827,0.7534738859607092,0.7690464781983709,0.7791087685673215,0.7896502156205079,0.7930043124101581,0.8049832295160517,0.8136080498322952,0.8140872065165309,0.8210349784379493,0.8255869669381888,0.8342117872544322,0.832534738859607,0.8397220891231433,0.8416387158600862,0.8473885960709152,0.8512218495448012,0.8517010062290369,0.8569717297556301,0.8567321514135122,0.8581696214662194,0.8617632965979876,0.8658361284139914,0.8658361284139914,0.8694298035457595,0.8675131768088165,0.8723047436511739,0.8770963104935314,0.8754192620987062,0.8790129372304744,0.8859607091518926,0.8862002874940106,0.8809295639674174,0.8943459511260182,0.8955438428366076,0.892908481073311,0.8912314326784858\n",
            "\n",
            "0.0001\t0.1\t0.005\t3\tFalse\tval_acc\tearly_stopping_model_0.0001_0.1_0.005_3_False.pt\t0.7408616187989556,0.7689295039164491,0.7800261096605744,0.7806788511749347,0.79177545691906,0.7610966057441253,0.7734986945169713,0.793733681462141,0.7715404699738904,0.7950391644908616,0.806135770234987,0.8126631853785901,0.8178851174934726,0.8237597911227154,0.8211488250652742,0.8348563968668408,0.8335509138381201,0.8400783289817232,0.8453002610966057,0.8485639686684073,0.8524804177545692,0.8400783289817232,0.8537859007832899,0.8505221932114883,0.8544386422976501,0.8622715404699739,0.856396866840731,0.856396866840731,0.8616187989556136,0.8596605744125326,0.8674934725848564,0.8674934725848564,0.8707571801566579,0.8655352480417755,0.8661879895561357,0.8629242819843342,0.8740208877284595,0.8668407310704961,0.8661879895561357,0.8661879895561357,0.858355091383812,0.8629242819843342\n",
            "\n",
            "0.0001 0.1 0.005 3 True\n",
            "loss weight 0.2496406324868232\n",
            "\n",
            "Epoch: 1\n",
            "Training loss: 0.004352215211838484 Validation loss: 0.004045257344841957\n",
            "MCC Train: -0.008372135741694861 MCC val: 0.06144902392263528\n",
            "\n",
            "Epoch: 2\n",
            "Training loss: 0.004166965372860432 Validation loss: 0.003951323684304953\n",
            "MCC Train: 0.05703326947561737 MCC val: 0.1654063140973207\n",
            "\n",
            "Epoch: 3\n",
            "Training loss: 0.004113714210689068 Validation loss: 0.0038810616824775934\n",
            "MCC Train: 0.08392380900710025 MCC val: 0.20825867477345203\n",
            "\n",
            "Epoch: 4\n",
            "Training loss: 0.0040674167685210705 Validation loss: 0.0038128304295241833\n",
            "MCC Train: 0.11969428573500915 MCC val: 0.2337658957555709\n",
            "\n",
            "Epoch: 5\n",
            "Training loss: 0.003970352932810783 Validation loss: 0.0037396608386188745\n",
            "MCC Train: 0.1584321295412953 MCC val: 0.23780365635699582\n",
            "\n",
            "Epoch: 6\n",
            "Training loss: 0.003886117832735181 Validation loss: 0.003684681374579668\n",
            "MCC Train: 0.18486982966802523 MCC val: 0.26606060245345553\n",
            "\n",
            "Epoch: 7\n",
            "Training loss: 0.003829971654340625 Validation loss: 0.00363612431101501\n",
            "MCC Train: 0.23379730792774264 MCC val: 0.2628726777894154\n",
            "\n",
            "Epoch: 8\n",
            "Training loss: 0.0037538434844464064 Validation loss: 0.0035594075452536345\n",
            "MCC Train: 0.23885624838006014 MCC val: 0.27216127993061634\n",
            "\n",
            "Epoch: 9\n",
            "Training loss: 0.0036518920678645372 Validation loss: 0.0034964277874678373\n",
            "MCC Train: 0.27261666083135466 MCC val: 0.2713465078270013\n",
            "\n",
            "Epoch: 10\n",
            "Training loss: 0.003583317855373025 Validation loss: 0.003427911316975951\n",
            "MCC Train: 0.30384794824042416 MCC val: 0.29081326330259427\n",
            "\n",
            "Epoch: 11\n",
            "Training loss: 0.0035354006104171276 Validation loss: 0.003432897850871086\n",
            "MCC Train: 0.31693986144443076 MCC val: 0.28200469287884816\n",
            "\n",
            "Epoch: 12\n",
            "Training loss: 0.003436945378780365 Validation loss: 0.0033838534727692604\n",
            "MCC Train: 0.3425007461856804 MCC val: 0.2931711161431284\n",
            "\n",
            "Epoch: 13\n",
            "Training loss: 0.0034187568817287683 Validation loss: 0.0033129663206636906\n",
            "MCC Train: 0.334097458426039 MCC val: 0.3047480622228718\n",
            "\n",
            "Epoch: 14\n",
            "Training loss: 0.0033171053510159254 Validation loss: 0.0032445015385746956\n",
            "MCC Train: 0.3856871676286432 MCC val: 0.33236839203544566\n",
            "\n",
            "Epoch: 15\n",
            "Training loss: 0.0033572001848369837 Validation loss: 0.0032603307627141476\n",
            "MCC Train: 0.36195214755122956 MCC val: 0.3192327907322756\n",
            "\n",
            "Epoch: 16\n",
            "Training loss: 0.0032340004108846188 Validation loss: 0.0031739044934511185\n",
            "MCC Train: 0.40487908321837623 MCC val: 0.38570839021455605\n",
            "\n",
            "Epoch: 17\n",
            "Training loss: 0.00317866331897676 Validation loss: 0.003192899515852332\n",
            "MCC Train: 0.4075026548768104 MCC val: 0.35685294572468945\n",
            "\n",
            "Epoch: 18\n",
            "Training loss: 0.003165879752486944 Validation loss: 0.0031576177570968866\n",
            "MCC Train: 0.43474580036994126 MCC val: 0.39441867812944653\n",
            "\n",
            "Epoch: 19\n",
            "Training loss: 0.003164940048009157 Validation loss: 0.0031766099855303764\n",
            "MCC Train: 0.43389082607253365 MCC val: 0.37487708500094435\n",
            "\n",
            "Epoch: 20\n",
            "Training loss: 0.0030532239470630884 Validation loss: 0.0030818518716841936\n",
            "MCC Train: 0.4565527590305825 MCC val: 0.42197675133894574\n",
            "\n",
            "Epoch: 21\n",
            "Training loss: 0.0030004160944372416 Validation loss: 0.0030604747589677572\n",
            "MCC Train: 0.484808895414818 MCC val: 0.4242431257031764\n",
            "\n",
            "Epoch: 22\n",
            "Training loss: 0.0030265762470662594 Validation loss: 0.0031640634406358004\n",
            "MCC Train: 0.47239499157700043 MCC val: 0.38279483720766677\n",
            "\n",
            "Epoch: 23\n",
            "Training loss: 0.002916023600846529 Validation loss: 0.0030344685073941946\n",
            "MCC Train: 0.4890481509990516 MCC val: 0.44231695334085586\n",
            "\n",
            "Epoch: 24\n",
            "Training loss: 0.0029007059056311846 Validation loss: 0.0030276102479547262\n",
            "MCC Train: 0.5091175456324589 MCC val: 0.43972306015697743\n",
            "\n",
            "Epoch: 25\n",
            "Training loss: 0.002803996205329895 Validation loss: 0.003014654852449894\n",
            "MCC Train: 0.5152079637295333 MCC val: 0.44242815213570774\n",
            "\n",
            "Epoch: 26\n",
            "Training loss: 0.0028026155196130276 Validation loss: 0.002988202730193734\n",
            "MCC Train: 0.538905640008837 MCC val: 0.4460630569446566\n",
            "\n",
            "Epoch: 27\n",
            "Training loss: 0.0027456479147076607 Validation loss: 0.0029674244578927755\n",
            "MCC Train: 0.5400923023226807 MCC val: 0.46771335092017524\n",
            "\n",
            "Epoch: 28\n",
            "Training loss: 0.0027136930730193853 Validation loss: 0.0030083847232162952\n",
            "MCC Train: 0.5481549957114982 MCC val: 0.4518038145943981\n",
            "\n",
            "Epoch: 29\n",
            "Training loss: 0.0026064736302942038 Validation loss: 0.003109624842181802\n",
            "MCC Train: 0.5772589193269579 MCC val: 0.41114759139184476\n",
            "\n",
            "Epoch: 30\n",
            "Training loss: 0.002598499646410346 Validation loss: 0.003032607724890113\n",
            "MCC Train: 0.5833903762924747 MCC val: 0.45019196671945544\n",
            "\n",
            "Epoch: 31\n",
            "Training loss: 0.0025585321709513664 Validation loss: 0.002961770398542285\n",
            "MCC Train: 0.5750246436678822 MCC val: 0.4720991494481081\n",
            "\n",
            "Epoch: 32\n",
            "Training loss: 0.00247441534884274 Validation loss: 0.0030858737882226706\n",
            "MCC Train: 0.595628336440033 MCC val: 0.43963928704417127\n",
            "\n",
            "Epoch: 33\n",
            "Training loss: 0.0024608734529465437 Validation loss: 0.0030672098509967327\n",
            "MCC Train: 0.5927969418865254 MCC val: 0.438598722555895\n",
            "\n",
            "Epoch: 34\n",
            "Training loss: 0.002393839880824089 Validation loss: 0.002985153114423156\n",
            "MCC Train: 0.6110190825797173 MCC val: 0.4901387659442809\n",
            "\n",
            "Epoch: 35\n",
            "Training loss: 0.002318881219252944 Validation loss: 0.0030781400855630636\n",
            "MCC Train: 0.6228726021039493 MCC val: 0.46597946061441464\n",
            "\n",
            "Epoch: 36\n",
            "Training loss: 0.002323252148926258 Validation loss: 0.003052267013117671\n",
            "MCC Train: 0.6038267620815125 MCC val: 0.469717916025055\n",
            "\n",
            "Epoch: 37\n",
            "Training loss: 0.0022091600112617016 Validation loss: 0.0030317206401377916\n",
            "MCC Train: 0.6448244365296152 MCC val: 0.47456629379080056\n",
            "\n",
            "Epoch: 38\n",
            "Training loss: 0.0021900099236518145 Validation loss: 0.0030752713792026043\n",
            "MCC Train: 0.6490675696603155 MCC val: 0.46363053289018546\n",
            "\n",
            "Epoch: 39\n",
            "Training loss: 0.0021353147458285093 Validation loss: 0.003040553769096732\n",
            "MCC Train: 0.6546757941439212 MCC val: 0.49078521219067284\n",
            "\n",
            "Epoch: 40\n",
            "Training loss: 0.002139637479558587 Validation loss: 0.0031665407586842775\n",
            "MCC Train: 0.6490172384051578 MCC val: 0.4332270540175661\n",
            "\n",
            "Epoch: 41\n",
            "Training loss: 0.0021050034556537867 Validation loss: 0.003014830406755209\n",
            "MCC Train: 0.6599213020103863 MCC val: 0.5019780652733017\n",
            "Early stopping\n",
            "\n",
            "0.0001\t0.1\t0.005\t3\tTrue\ttrain_losses\tearly_stopping_model_0.0001_0.1_0.005_3_True.pt\t0.004352215,0.0041669654,0.004113714,0.004067417,0.003970353,0.0038861178,0.0038299717,0.0037538435,0.003651892,0.0035833179,0.0035354006,0.0034369454,0.0034187569,0.0033171054,0.0033572002,0.0032340004,0.0031786633,0.0031658798,0.00316494,0.003053224,0.003000416,0.0030265762,0.0029160236,0.002900706,0.0028039962,0.0028026155,0.002745648,0.002713693,0.0026064736,0.0025984996,0.0025585322,0.0024744153,0.0024608735,0.0023938399,0.0023188812,0.0023232521,0.00220916,0.00219001,0.0021353147,0.0021396375,0.0021050035\n",
            "\n",
            "0.0001\t0.1\t0.005\t3\tTrue\tval_losses\tearly_stopping_model_0.0001_0.1_0.005_3_True.pt\t0.0040452573,0.0039513237,0.0038810617,0.0038128304,0.0037396608,0.0036846814,0.0036361243,0.0035594075,0.0034964278,0.0034279113,0.0034328979,0.0033838535,0.0033129663,0.0032445015,0.0032603308,0.0031739045,0.0031928995,0.0031576178,0.00317661,0.0030818519,0.0030604748,0.0031640634,0.0030344685,0.0030276102,0.0030146549,0.0029882027,0.0029674245,0.0030083847,0.0031096248,0.0030326077,0.0029617704,0.0030858738,0.0030672099,0.002985153,0.00307814,0.003052267,0.0030317206,0.0030752714,0.0030405538,0.0031665408,0.0030148304\n",
            "\n",
            "0.0001\t0.1\t0.005\t3\tTrue\ttrain_acc\tearly_stopping_model_0.0001_0.1_0.005_3_True.pt\t0.43195975083852417,0.5210828941063728,0.5486344034499281,0.5651653090560613,0.5795400095831337,0.6078102539530427,0.6348826066123623,0.6329659798754192,0.6653090560613321,0.6811212266411116,0.6942980354575946,0.708672735984667,0.7036415908001916,0.7362242453282223,0.7275994250119789,0.7472448490656445,0.7515572592237661,0.7664111164350743,0.7704839482510781,0.783900335409679,0.7942022041207475,0.7922855773838045,0.8009103977000479,0.8092956396741735,0.8114518447532343,0.8236703402012459,0.8212745567800671,0.8267848586487782,0.8378054623862002,0.842117872544322,0.8390033540967896,0.8478677527551509,0.8454719693339722,0.8521801629132726,0.8579300431241016,0.8488260661236224,0.8643986583612842,0.8677527551509343,0.8699089602299952,0.8675131768088165,0.8723047436511739\n",
            "\n",
            "0.0001\t0.1\t0.005\t3\tTrue\tval_acc\tearly_stopping_model_0.0001_0.1_0.005_3_True.pt\t0.5548302872062664,0.5998694516971279,0.6449086161879896,0.6449086161879896,0.643603133159269,0.6710182767624021,0.6383812010443864,0.6494778067885117,0.6533942558746736,0.6762402088772846,0.6481723237597912,0.6651436031331592,0.6847258485639687,0.7160574412532638,0.6984334203655352,0.7480417754569191,0.7258485639686684,0.7513054830287206,0.7362924281984334,0.7702349869451697,0.7728459530026109,0.741514360313316,0.7819843342036553,0.7780678851174935,0.7826370757180157,0.7852480417754569,0.7969973890339426,0.7878590078328982,0.762402088772846,0.7852480417754569,0.7983028720626631,0.7767624020887729,0.7774151436031331,0.8048302872062664,0.79177545691906,0.7943864229765013,0.7996083550913838,0.7904699738903395,0.804177545691906,0.7682767624020888,0.8100522193211488\n",
            "\n",
            "0.0001 0.5 0.0005 2 False\n",
            "\n",
            "Epoch: 1\n",
            "Training loss: 0.012096780352294445 Validation loss: 0.010075998492538929\n",
            "MCC Train: 0.01437736281898071 MCC val: 0.021561540911771697\n",
            "\n",
            "Epoch: 2\n",
            "Training loss: 0.01158247608691454 Validation loss: 0.009883500635623932\n",
            "MCC Train: 0.007109862875843804 MCC val: 0.0920956702004365\n",
            "\n",
            "Epoch: 3\n",
            "Training loss: 0.010991944931447506 Validation loss: 0.009804504923522472\n",
            "MCC Train: 0.012122328623145273 MCC val: 0.03444636999836995\n",
            "\n",
            "Epoch: 4\n",
            "Training loss: 0.010857327841222286 Validation loss: 0.009565250016748905\n",
            "MCC Train: 0.03304415318496099 MCC val: 0.02087414303617165\n",
            "\n",
            "Epoch: 5\n",
            "Training loss: 0.010712874121963978 Validation loss: 0.00954468548297882\n",
            "MCC Train: 0.013718795829409056 MCC val: 0.02087414303617165\n",
            "\n",
            "Epoch: 6\n",
            "Training loss: 0.010581127367913723 Validation loss: 0.00937732495367527\n",
            "MCC Train: 0.009116604209047212 MCC val: 0.0\n",
            "\n",
            "Epoch: 7\n",
            "Training loss: 0.010683896020054817 Validation loss: 0.009286073036491871\n",
            "MCC Train: -0.008110769318933595 MCC val: 0.0\n",
            "\n",
            "Epoch: 8\n",
            "Training loss: 0.010330894961953163 Validation loss: 0.00936545804142952\n",
            "MCC Train: 0.01970276490811361 MCC val: 0.0\n",
            "\n",
            "Epoch: 9\n",
            "Training loss: 0.01024774182587862 Validation loss: 0.009398280642926693\n",
            "MCC Train: -0.0009343249191691501 MCC val: 0.0\n",
            "\n",
            "Epoch: 10\n",
            "Training loss: 0.010272572748363018 Validation loss: 0.009268845431506634\n",
            "MCC Train: 0.03351534526860855 MCC val: 0.0\n",
            "\n",
            "Epoch: 11\n",
            "Training loss: 0.010124363005161285 Validation loss: 0.009390496648848057\n",
            "MCC Train: 0.01729637198300798 MCC val: 0.0\n",
            "\n",
            "Epoch: 12\n",
            "Training loss: 0.010196817107498646 Validation loss: 0.009298364631831646\n",
            "MCC Train: 0.017376037618575278 MCC val: 0.0\n",
            "\n",
            "Epoch: 13\n",
            "Training loss: 0.010127444751560688 Validation loss: 0.00933313462883234\n",
            "MCC Train: -0.006722591491290412 MCC val: 0.0\n",
            "\n",
            "Epoch: 14\n",
            "Training loss: 0.010016405954957008 Validation loss: 0.009267862886190414\n",
            "MCC Train: 0.027323705968959992 MCC val: 0.0\n",
            "\n",
            "Epoch: 15\n",
            "Training loss: 0.00991053692996502 Validation loss: 0.009353899396955967\n",
            "MCC Train: 0.01636177855363008 MCC val: 0.0\n",
            "\n",
            "Epoch: 16\n",
            "Training loss: 0.010061908513307571 Validation loss: 0.00925751868635416\n",
            "MCC Train: 0.025325879687710478 MCC val: 0.0\n",
            "\n",
            "Epoch: 17\n",
            "Training loss: 0.009993715211749077 Validation loss: 0.009367411024868488\n",
            "MCC Train: -0.0021523059000667227 MCC val: 0.0\n",
            "\n",
            "Epoch: 18\n",
            "Training loss: 0.009898925200104713 Validation loss: 0.009302164427936077\n",
            "MCC Train: 0.029542880368220947 MCC val: 0.0\n",
            "\n",
            "Epoch: 19\n",
            "Training loss: 0.010146970860660076 Validation loss: 0.009291930124163628\n",
            "MCC Train: -0.006206071781013082 MCC val: 0.0\n",
            "\n",
            "Epoch: 20\n",
            "Training loss: 0.009964893572032452 Validation loss: 0.009344659745693207\n",
            "MCC Train: 0.0130405668311407 MCC val: 0.0\n",
            "\n",
            "Epoch: 21\n",
            "Training loss: 0.00960798654705286 Validation loss: 0.009308536536991596\n",
            "MCC Train: 0.02850001765251861 MCC val: 0.0\n",
            "\n",
            "Epoch: 22\n",
            "Training loss: 0.009734131395816803 Validation loss: 0.009337450377643108\n",
            "MCC Train: 0.04410519743274561 MCC val: 0.0\n",
            "\n",
            "Epoch: 23\n",
            "Training loss: 0.009878733195364475 Validation loss: 0.00934411957859993\n",
            "MCC Train: 0.0038196912007461975 MCC val: 0.0\n",
            "\n",
            "Epoch: 24\n",
            "Training loss: 0.009789837524294853 Validation loss: 0.009330694563686848\n",
            "MCC Train: -0.004463452044841483 MCC val: 0.0\n",
            "\n",
            "Epoch: 25\n",
            "Training loss: 0.009622413665056229 Validation loss: 0.009292085655033588\n",
            "MCC Train: 0.026603149378016725 MCC val: 0.0\n",
            "\n",
            "Epoch: 26\n",
            "Training loss: 0.009662683121860027 Validation loss: 0.00930702779442072\n",
            "MCC Train: 0.008507145603459151 MCC val: 0.0\n",
            "Early stopping\n",
            "\n",
            "0.0001\t0.5\t0.0005\t2\tFalse\ttrain_losses\tearly_stopping_model_0.0001_0.5_0.0005_2_False.pt\t0.01209678,0.011582476,0.010991945,0.010857328,0.010712874,0.010581127,0.010683896,0.010330895,0.010247742,0.010272573,0.010124363,0.010196817,0.010127445,0.010016406,0.009910537,0.0100619085,0.009993715,0.009898925,0.010146971,0.009964894,0.009607987,0.009734131,0.009878733,0.0097898375,0.009622414,0.009662683\n",
            "\n",
            "0.0001\t0.5\t0.0005\t2\tFalse\tval_losses\tearly_stopping_model_0.0001_0.5_0.0005_2_False.pt\t0.0100759985,0.009883501,0.009804505,0.00956525,0.0095446855,0.009377325,0.009286073,0.009365458,0.009398281,0.009268845,0.009390497,0.009298365,0.009333135,0.009267863,0.009353899,0.009257519,0.009367411,0.009302164,0.00929193,0.00934466,0.009308537,0.00933745,0.00934412,0.009330695,0.009292086,0.009307028\n",
            "\n",
            "0.0001\t0.5\t0.0005\t2\tFalse\ttrain_acc\tearly_stopping_model_0.0001_0.5_0.0005_2_False.pt\t0.569717297556301,0.5946334451365597,0.6231432678485865,0.6475802587446094,0.6648298993770964,0.6655486344034499,0.6629132726401533,0.6880689985625299,0.6868711068519406,0.6962146621945376,0.6947771921418304,0.7019645424053665,0.6923814087206517,0.704839482510781,0.7041207474844274,0.7093914710110206,0.7045999041686631,0.7134643028270244,0.6990896022999521,0.7101102060373742,0.7204120747484427,0.7232870148538572,0.7113080977479636,0.7113080977479636,0.7220891231432679,0.7184954480114998\n",
            "\n",
            "0.0001\t0.5\t0.0005\t2\tFalse\tval_acc\tearly_stopping_model_0.0001_0.5_0.0005_2_False.pt\t0.7225848563968669,0.7480417754569191,0.7480417754569191,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75\n",
            "\n",
            "0.0001 0.5 0.0005 2 True\n",
            "loss weight 0.2496406324868232\n",
            "\n",
            "Epoch: 1\n",
            "Training loss: 0.0049650282599031925 Validation loss: 0.004048330243676901\n",
            "MCC Train: -0.0061183463155006146 MCC val: 0.07023891324262452\n",
            "\n",
            "Epoch: 2\n",
            "Training loss: 0.004939395934343338 Validation loss: 0.004037594422698021\n",
            "MCC Train: 0.013554256567145942 MCC val: 0.08660834826353939\n",
            "\n",
            "Epoch: 3\n",
            "Training loss: 0.004739758092910051 Validation loss: 0.004031158052384853\n",
            "MCC Train: 0.052862857536438435 MCC val: 0.10610281899707558\n",
            "\n",
            "Epoch: 4\n",
            "Training loss: 0.004904508590698242 Validation loss: 0.004021448083221912\n",
            "MCC Train: -0.018882104746072503 MCC val: 0.10179059162797809\n",
            "\n",
            "Epoch: 5\n",
            "Training loss: 0.00471686152741313 Validation loss: 0.004012951627373695\n",
            "MCC Train: 0.028772516377012048 MCC val: 0.12073666924653652\n",
            "\n",
            "Epoch: 6\n",
            "Training loss: 0.004804533440619707 Validation loss: 0.004010658245533705\n",
            "MCC Train: -0.009994026490890751 MCC val: 0.12665359099074355\n",
            "\n",
            "Epoch: 7\n",
            "Training loss: 0.004676761105656624 Validation loss: 0.004008376970887184\n",
            "MCC Train: 0.01852723560188607 MCC val: 0.11910253033265458\n",
            "\n",
            "Epoch: 8\n",
            "Training loss: 0.0046481778845191 Validation loss: 0.004003769252449274\n",
            "MCC Train: 0.027393137502756973 MCC val: 0.1426878491703898\n",
            "\n",
            "Epoch: 9\n",
            "Training loss: 0.004636157304048538 Validation loss: 0.003996904473751783\n",
            "MCC Train: 0.010222848197788792 MCC val: 0.13519294273875204\n",
            "\n",
            "Epoch: 10\n",
            "Training loss: 0.004636494442820549 Validation loss: 0.003996594343334436\n",
            "MCC Train: 0.010489993304844004 MCC val: 0.15009808133069266\n",
            "\n",
            "Epoch: 11\n",
            "Training loss: 0.004654375836253166 Validation loss: 0.0039905100129544735\n",
            "MCC Train: 0.017156205528377686 MCC val: 0.15855365431889842\n",
            "\n",
            "Epoch: 12\n",
            "Training loss: 0.004499569069594145 Validation loss: 0.003983241971582174\n",
            "MCC Train: 0.024619208072098588 MCC val: 0.13268237121866497\n",
            "\n",
            "Epoch: 13\n",
            "Training loss: 0.0045736851170659065 Validation loss: 0.003987143747508526\n",
            "MCC Train: 0.019635890887013497 MCC val: 0.16053863596210735\n",
            "\n",
            "Epoch: 14\n",
            "Training loss: 0.004466497339308262 Validation loss: 0.003985629882663488\n",
            "MCC Train: 0.04400205187590879 MCC val: 0.1458176066819595\n",
            "\n",
            "Epoch: 15\n",
            "Training loss: 0.004466785117983818 Validation loss: 0.003987468779087067\n",
            "MCC Train: 0.016863387786276184 MCC val: 0.1501852574770441\n",
            "\n",
            "Epoch: 16\n",
            "Training loss: 0.004480166360735893 Validation loss: 0.003981424029916525\n",
            "MCC Train: 0.03957054151159931 MCC val: 0.14707730164199032\n",
            "\n",
            "Epoch: 17\n",
            "Training loss: 0.004509755410254002 Validation loss: 0.003980460576713085\n",
            "MCC Train: 0.011324809188230194 MCC val: 0.15983298241999785\n",
            "\n",
            "Epoch: 18\n",
            "Training loss: 0.0044625005684792995 Validation loss: 0.003974149003624916\n",
            "MCC Train: 0.017145851186562956 MCC val: 0.14262430680793198\n",
            "\n",
            "Epoch: 19\n",
            "Training loss: 0.004459371790289879 Validation loss: 0.003974027466028929\n",
            "MCC Train: 0.03459635435263368 MCC val: 0.14066651554015103\n",
            "\n",
            "Epoch: 20\n",
            "Training loss: 0.004468068480491638 Validation loss: 0.003972832579165697\n",
            "MCC Train: 0.016611488004293903 MCC val: 0.14391778474922162\n",
            "\n",
            "Epoch: 21\n",
            "Training loss: 0.004459424875676632 Validation loss: 0.003973792772740126\n",
            "MCC Train: 0.008032620882623156 MCC val: 0.15838725613360224\n",
            "\n",
            "Epoch: 22\n",
            "Training loss: 0.004308489151299 Validation loss: 0.003964643459767103\n",
            "MCC Train: 0.04511162847164378 MCC val: 0.18703057231488915\n",
            "\n",
            "Epoch: 23\n",
            "Training loss: 0.0044199759140610695 Validation loss: 0.003971093334257603\n",
            "MCC Train: 0.01908080114411941 MCC val: 0.16383959662336425\n",
            "\n",
            "Epoch: 24\n",
            "Training loss: 0.004351516719907522 Validation loss: 0.003965047653764486\n",
            "MCC Train: 0.03821340849482014 MCC val: 0.16896313148273365\n",
            "\n",
            "Epoch: 25\n",
            "Training loss: 0.004390080459415913 Validation loss: 0.003957821521908045\n",
            "MCC Train: 0.027389331061180622 MCC val: 0.18429235096257893\n",
            "\n",
            "Epoch: 26\n",
            "Training loss: 0.004345532972365618 Validation loss: 0.003961313981562853\n",
            "MCC Train: 0.02683497915710435 MCC val: 0.18106216485311008\n",
            "\n",
            "Epoch: 27\n",
            "Training loss: 0.0044135767966508865 Validation loss: 0.0039583612233400345\n",
            "MCC Train: -0.010257945031186438 MCC val: 0.19446266371596144\n",
            "\n",
            "Epoch: 28\n",
            "Training loss: 0.004365620668977499 Validation loss: 0.003959165420383215\n",
            "MCC Train: 0.019635890887013497 MCC val: 0.20102771032774153\n",
            "\n",
            "Epoch: 29\n",
            "Training loss: 0.004304036498069763 Validation loss: 0.003957551438361406\n",
            "MCC Train: 0.04345575524020061 MCC val: 0.18967352488958414\n",
            "\n",
            "Epoch: 30\n",
            "Training loss: 0.0043577090837061405 Validation loss: 0.003948877099901438\n",
            "MCC Train: 0.027665221558243008 MCC val: 0.19452632933980415\n",
            "\n",
            "Epoch: 31\n",
            "Training loss: 0.0043329703621566296 Validation loss: 0.0039490023627877235\n",
            "MCC Train: 0.023788886145846115 MCC val: 0.18762053512732874\n",
            "\n",
            "Epoch: 32\n",
            "Training loss: 0.004355473443865776 Validation loss: 0.003939494956284761\n",
            "MCC Train: 0.025172756358645285 MCC val: 0.21134664887538318\n",
            "\n",
            "Epoch: 33\n",
            "Training loss: 0.0043166582472622395 Validation loss: 0.003943894524127245\n",
            "MCC Train: 0.01770087239314198 MCC val: 0.19401222061393059\n",
            "\n",
            "Epoch: 34\n",
            "Training loss: 0.004253951832652092 Validation loss: 0.00393878435716033\n",
            "MCC Train: 0.04482997527082743 MCC val: 0.2161791588189704\n",
            "\n",
            "Epoch: 35\n",
            "Training loss: 0.004305528476834297 Validation loss: 0.0039357072673738\n",
            "MCC Train: 0.023792729884256875 MCC val: 0.20037017117544098\n",
            "\n",
            "Epoch: 36\n",
            "Training loss: 0.004220311529934406 Validation loss: 0.003927490208297968\n",
            "MCC Train: 0.03375690398389266 MCC val: 0.20662098956766567\n",
            "\n",
            "Epoch: 37\n",
            "Training loss: 0.004252759274095297 Validation loss: 0.003923306707292795\n",
            "MCC Train: 0.04234609962883209 MCC val: 0.2298526426624619\n",
            "\n",
            "Epoch: 38\n",
            "Training loss: 0.004207727964967489 Validation loss: 0.003919949289411306\n",
            "MCC Train: 0.05591195457408748 MCC val: 0.21214031262541694\n",
            "\n",
            "Epoch: 39\n",
            "Training loss: 0.004224773496389389 Validation loss: 0.0039040239062160254\n",
            "MCC Train: 0.06920185109173266 MCC val: 0.24147017371328275\n",
            "\n",
            "Epoch: 40\n",
            "Training loss: 0.004236513748764992 Validation loss: 0.0038942997343838215\n",
            "MCC Train: 0.05867361212238238 MCC val: 0.2514839634800714\n",
            "\n",
            "Epoch: 41\n",
            "Training loss: 0.004201147239655256 Validation loss: 0.003886941820383072\n",
            "MCC Train: 0.03459058457276118 MCC val: 0.24204537991412686\n",
            "\n",
            "Epoch: 42\n",
            "Training loss: 0.004193355794996023 Validation loss: 0.0038719719741493464\n",
            "MCC Train: 0.044303120353806374 MCC val: 0.26464212210532256\n",
            "\n",
            "Epoch: 43\n",
            "Training loss: 0.004191037267446518 Validation loss: 0.0038647137116640806\n",
            "MCC Train: 0.05400320143177485 MCC val: 0.2440341492159123\n",
            "\n",
            "Epoch: 44\n",
            "Training loss: 0.004217988811433315 Validation loss: 0.0038497704081237316\n",
            "MCC Train: 0.04125225958031374 MCC val: 0.2499227018477236\n",
            "\n",
            "Epoch: 45\n",
            "Training loss: 0.004237435758113861 Validation loss: 0.0038308494258672\n",
            "MCC Train: 0.06421240544032034 MCC val: 0.2611151333601508\n",
            "\n",
            "Epoch: 46\n",
            "Training loss: 0.004121719393879175 Validation loss: 0.0038266165647655725\n",
            "MCC Train: 0.09854474151823846 MCC val: 0.27901468788039396\n",
            "\n",
            "Epoch: 47\n",
            "Training loss: 0.0041303182952106 Validation loss: 0.003807945642620325\n",
            "MCC Train: 0.10723865910783427 MCC val: 0.29024787679906977\n",
            "\n",
            "Epoch: 48\n",
            "Training loss: 0.0041200933046638966 Validation loss: 0.0038043882232159376\n",
            "MCC Train: 0.10786805440460565 MCC val: 0.29353975919904085\n",
            "\n",
            "Epoch: 49\n",
            "Training loss: 0.00410179840400815 Validation loss: 0.0037839701399207115\n",
            "MCC Train: 0.0900102271831455 MCC val: 0.29400324572482534\n",
            "\n",
            "Epoch: 50\n",
            "Training loss: 0.004110423382371664 Validation loss: 0.0037763153668493032\n",
            "MCC Train: 0.0989461888302497 MCC val: 0.29645021994500925\n",
            "0.0001\t0.5\t0.0005\t2\tTrue\ttrain_losses\tearly_stopping_model_0.0001_0.5_0.0005_2_True.pt\t0.0049650283,0.004939396,0.004739758,0.0049045086,0.0047168615,0.0048045334,0.004676761,0.004648178,0.0046361573,0.0046364944,0.004654376,0.004499569,0.004573685,0.0044664973,0.004466785,0.0044801664,0.0045097554,0.0044625006,0.004459372,0.0044680685,0.004459425,0.004308489,0.004419976,0.0043515167,0.0043900805,0.004345533,0.004413577,0.0043656207,0.0043040365,0.004357709,0.0043329704,0.0043554734,0.0043166582,0.004253952,0.0043055285,0.0042203115,0.0042527593,0.004207728,0.0042247735,0.0042365137,0.0042011472,0.004193356,0.0041910373,0.004217989,0.0042374358,0.0041217194,0.0041303183,0.0041200933,0.0041017984,0.0041104234\n",
            "\n",
            "0.0001\t0.5\t0.0005\t2\tTrue\tval_losses\tearly_stopping_model_0.0001_0.5_0.0005_2_True.pt\t0.0040483302,0.0040375944,0.004031158,0.004021448,0.0040129516,0.0040106582,0.004008377,0.0040037693,0.0039969045,0.0039965943,0.00399051,0.003983242,0.0039871437,0.00398563,0.003987469,0.003981424,0.0039804606,0.003974149,0.0039740275,0.0039728326,0.003973793,0.0039646435,0.0039710933,0.0039650477,0.0039578215,0.003961314,0.003958361,0.0039591654,0.0039575514,0.003948877,0.0039490024,0.003939495,0.0039438945,0.0039387844,0.0039357073,0.00392749,0.0039233067,0.0039199493,0.003904024,0.0038942997,0.0038869418,0.003871972,0.0038647137,0.0038497704,0.0038308494,0.0038266166,0.0038079456,0.0038043882,0.0037839701,0.0037763154\n",
            "\n",
            "0.0001\t0.5\t0.0005\t2\tTrue\ttrain_acc\tearly_stopping_model_0.0001_0.5_0.0005_2_True.pt\t0.5052707235265932,0.5083852419741255,0.5304264494489698,0.503833253473886,0.5196454240536655,0.5033540967896503,0.5155725922376617,0.5146142788691902,0.5107810253953042,0.5162913272640154,0.5086248203162435,0.5203641590800192,0.515093435553426,0.5265931959750838,0.5174892189746046,0.5237182558696694,0.5141351221849545,0.5129372304743651,0.515093435553426,0.5057498802108289,0.5016770483948251,0.5203641590800192,0.5160517489218974,0.5124580737901294,0.5170100622903689,0.5174892189746046,0.5002395783421179,0.515093435553426,0.5289889793962625,0.5206037374221371,0.5210828941063728,0.5194058457115477,0.5124580737901294,0.5249161475802587,0.5239578342117872,0.5191662673694298,0.5280306660277911,0.5325826545280307,0.5378533780546239,0.5316243411595591,0.5246765692381409,0.5325826545280307,0.5366554863440345,0.5309056061332056,0.5344992812649736,0.5493531384762818,0.5606133205558218,0.563967417345472,0.5505510301868711,0.5582175371346431\n",
            "\n",
            "0.0001\t0.5\t0.0005\t2\tTrue\tval_acc\tearly_stopping_model_0.0001_0.5_0.0005_2_True.pt\t0.5698433420365535,0.5822454308093995,0.6253263707571801,0.5509138381201044,0.6077023498694517,0.5822454308093995,0.5554830287206266,0.5907310704960835,0.5744125326370757,0.5744125326370757,0.5966057441253264,0.5300261096605744,0.610313315926893,0.5456919060052219,0.5522193211488251,0.5261096605744126,0.5633159268929504,0.5078328981723238,0.5274151436031331,0.5261096605744126,0.5593994778067886,0.5724543080939948,0.5424281984334204,0.5633159268929504,0.6070496083550914,0.6116187989556136,0.585509138381201,0.5685378590078329,0.5639686684073107,0.5907310704960835,0.6024804177545692,0.6292428198433421,0.597911227154047,0.6455613577023499,0.6155352480417755,0.5972584856396866,0.6383812010443864,0.6240208877284595,0.652088772845953,0.6814621409921671,0.6514360313315927,0.6801566579634465,0.6507832898172323,0.652088772845953,0.6651436031331592,0.6847258485639687,0.7003916449086162,0.6971279373368147,0.7030026109660574,0.7010443864229765\n",
            "\n",
            "0.0001 0.5 0.0005 3 False\n",
            "\n",
            "Epoch: 1\n",
            "Training loss: 0.015314891934394836 Validation loss: 0.010884140618145466\n",
            "MCC Train: -0.021331631052166698 MCC val: 0.013872989971044221\n",
            "\n",
            "Epoch: 2\n",
            "Training loss: 0.012327277101576328 Validation loss: 0.01036070380359888\n",
            "MCC Train: -0.01494795058271936 MCC val: 0.01889836343177292\n",
            "\n",
            "Epoch: 3\n",
            "Training loss: 0.011195134371519089 Validation loss: 0.010115918703377247\n",
            "MCC Train: -0.00038398364930009206 MCC val: 0.0\n",
            "\n",
            "Epoch: 4\n",
            "Training loss: 0.010518672876060009 Validation loss: 0.009898717515170574\n",
            "MCC Train: 0.011973331714168242 MCC val: 0.0\n",
            "\n",
            "Epoch: 5\n",
            "Training loss: 0.01031377725303173 Validation loss: 0.009779085405170918\n",
            "MCC Train: 0.0041175230994891935 MCC val: 0.0\n",
            "\n",
            "Epoch: 6\n",
            "Training loss: 0.010185563936829567 Validation loss: 0.009816628880798817\n",
            "MCC Train: 0.004461138166235972 MCC val: 0.0\n",
            "\n",
            "Epoch: 7\n",
            "Training loss: 0.010337352752685547 Validation loss: 0.009741431102156639\n",
            "MCC Train: 0.023483161856331147 MCC val: 0.0\n",
            "\n",
            "Epoch: 8\n",
            "Training loss: 0.010254338383674622 Validation loss: 0.009718726389110088\n",
            "MCC Train: 0.003269830742638747 MCC val: 0.0\n",
            "\n",
            "Epoch: 9\n",
            "Training loss: 0.010113714262843132 Validation loss: 0.009757681749761105\n",
            "MCC Train: -0.016509870444666806 MCC val: 0.0\n",
            "\n",
            "Epoch: 10\n",
            "Training loss: 0.009960676543414593 Validation loss: 0.009758872911334038\n",
            "MCC Train: -0.0016003639206169803 MCC val: 0.0\n",
            "\n",
            "Epoch: 11\n",
            "Training loss: 0.009849969297647476 Validation loss: 0.009727763012051582\n",
            "MCC Train: 0.009478114358717373 MCC val: 0.0\n",
            "\n",
            "Epoch: 12\n",
            "Training loss: 0.009899578057229519 Validation loss: 0.009747333824634552\n",
            "MCC Train: 0.018089946334445897 MCC val: 0.0\n",
            "\n",
            "Epoch: 13\n",
            "Training loss: 0.01002606749534607 Validation loss: 0.009766055271029472\n",
            "MCC Train: 0.0007482853584490844 MCC val: 0.0\n",
            "\n",
            "Epoch: 14\n",
            "Training loss: 0.009788752533495426 Validation loss: 0.00979485735297203\n",
            "MCC Train: -0.01146976985496322 MCC val: 0.0\n",
            "\n",
            "Epoch: 15\n",
            "Training loss: 0.009822907857596874 Validation loss: 0.009769969619810581\n",
            "MCC Train: -0.009040813913041793 MCC val: 0.0\n",
            "\n",
            "Epoch: 16\n",
            "Training loss: 0.00990273430943489 Validation loss: 0.009783499874174595\n",
            "MCC Train: -0.02913990264036075 MCC val: 0.0\n",
            "\n",
            "Epoch: 17\n",
            "Training loss: 0.009676508605480194 Validation loss: 0.009847746230661869\n",
            "MCC Train: 0.030020494660185356 MCC val: 0.0\n",
            "\n",
            "Epoch: 18\n",
            "Training loss: 0.00958279613405466 Validation loss: 0.009833213873207569\n",
            "MCC Train: 0.013647797390988611 MCC val: 0.0\n",
            "Early stopping\n",
            "\n",
            "0.0001\t0.5\t0.0005\t3\tFalse\ttrain_losses\tearly_stopping_model_0.0001_0.5_0.0005_3_False.pt\t0.015314892,0.012327277,0.011195134,0.010518673,0.010313777,0.010185564,0.010337353,0.010254338,0.010113714,0.009960677,0.009849969,0.009899578,0.0100260675,0.0097887525,0.009822908,0.009902734,0.009676509,0.009582796\n",
            "\n",
            "0.0001\t0.5\t0.0005\t3\tFalse\tval_losses\tearly_stopping_model_0.0001_0.5_0.0005_3_False.pt\t0.010884141,0.010360704,0.010115919,0.0098987175,0.009779085,0.009816629,0.009741431,0.009718726,0.009757682,0.009758873,0.009727763,0.009747334,0.009766055,0.009794857,0.00976997,0.0097835,0.009847746,0.009833214\n",
            "\n",
            "0.0001\t0.5\t0.0005\t3\tFalse\ttrain_acc\tearly_stopping_model_0.0001_0.5_0.0005_3_False.pt\t0.41135601341638717,0.5299472927647341,0.6049353138476282,0.6492573071394346,0.6703402012458074,0.6875898418782942,0.6928605654048874,0.6902252036415908,0.6940584571154768,0.7014853857211308,0.7024436990896022,0.7120268327743172,0.7074748442740776,0.7074748442740776,0.7137038811691423,0.7120268327743172,0.7218495448011499,0.7232870148538572\n",
            "\n",
            "0.0001\t0.5\t0.0005\t3\tFalse\tval_acc\tearly_stopping_model_0.0001_0.5_0.0005_3_False.pt\t0.4536553524804178,0.7180156657963447,0.7486945169712794,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75\n",
            "\n",
            "0.0001 0.5 0.0005 3 True\n",
            "loss weight 0.2496406324868232\n",
            "\n",
            "Epoch: 1\n",
            "Training loss: 0.0051895128563046455 Validation loss: 0.004052071366459131\n",
            "MCC Train: 0.004480668561252858 MCC val: 0.11398456563503463\n",
            "\n",
            "Epoch: 2\n",
            "Training loss: 0.004913504235446453 Validation loss: 0.004041182342916727\n",
            "MCC Train: 0.013888554356450455 MCC val: 0.11126441985805054\n",
            "\n",
            "Epoch: 3\n",
            "Training loss: 0.004817442037165165 Validation loss: 0.004042354412376881\n",
            "MCC Train: -0.0051938670598579645 MCC val: 0.09985111370085685\n",
            "\n",
            "Epoch: 4\n",
            "Training loss: 0.004733729176223278 Validation loss: 0.004036370664834976\n",
            "MCC Train: -0.001622001142850831 MCC val: 0.14936470730422452\n",
            "\n",
            "Epoch: 5\n",
            "Training loss: 0.004608204122632742 Validation loss: 0.004035277757793665\n",
            "MCC Train: 0.030241796589107556 MCC val: 0.11176207438683784\n",
            "\n",
            "Epoch: 6\n",
            "Training loss: 0.004507170524448156 Validation loss: 0.004034779500216246\n",
            "MCC Train: 0.03550764024350738 MCC val: 0.15757309502296601\n",
            "\n",
            "Epoch: 7\n",
            "Training loss: 0.004536788910627365 Validation loss: 0.004038509912788868\n",
            "MCC Train: 0.031029007966359563 MCC val: 0.11606639317491273\n",
            "\n",
            "Epoch: 8\n",
            "Training loss: 0.004597915336489677 Validation loss: 0.0040406291373074055\n",
            "MCC Train: 0.011639579171253267 MCC val: 0.13693183656440613\n",
            "\n",
            "Epoch: 9\n",
            "Training loss: 0.004488829988986254 Validation loss: 0.004039708990603685\n",
            "MCC Train: 0.0005719882273663077 MCC val: 0.09801005046048747\n",
            "\n",
            "Epoch: 10\n",
            "Training loss: 0.00451531121507287 Validation loss: 0.004029979929327965\n",
            "MCC Train: 0.004414717867498544 MCC val: 0.22732895198364264\n",
            "\n",
            "Epoch: 11\n",
            "Training loss: 0.004504499025642872 Validation loss: 0.0040339017286896706\n",
            "MCC Train: 0.003619433250180302 MCC val: 0.17229468166848816\n",
            "\n",
            "Epoch: 12\n",
            "Training loss: 0.004496601410210133 Validation loss: 0.004035492427647114\n",
            "MCC Train: -0.0008435566116841184 MCC val: 0.14792443578124712\n",
            "\n",
            "Epoch: 13\n",
            "Training loss: 0.004392992705106735 Validation loss: 0.00403026957064867\n",
            "MCC Train: 0.0321396345202886 MCC val: 0.21013762409004993\n",
            "\n",
            "Epoch: 14\n",
            "Training loss: 0.0043725185096263885 Validation loss: 0.004037727136164904\n",
            "MCC Train: 0.01912095355018757 MCC val: 0.17523009021723518\n",
            "\n",
            "Epoch: 15\n",
            "Training loss: 0.004505450371652842 Validation loss: 0.004035584162920713\n",
            "MCC Train: -0.02270154759186529 MCC val: 0.16382663988209717\n",
            "\n",
            "Epoch: 16\n",
            "Training loss: 0.004359062761068344 Validation loss: 0.004037938080728054\n",
            "MCC Train: 0.003878858873365005 MCC val: 0.18400272987201208\n",
            "\n",
            "Epoch: 17\n",
            "Training loss: 0.004311889875680208 Validation loss: 0.004036377649754286\n",
            "MCC Train: 0.03293244485229893 MCC val: 0.16408713077887668\n",
            "\n",
            "Epoch: 18\n",
            "Training loss: 0.004381226375699043 Validation loss: 0.0040276492945849895\n",
            "MCC Train: -0.00028754011649700164 MCC val: 0.22929442597986768\n",
            "\n",
            "Epoch: 19\n",
            "Training loss: 0.004356931429356337 Validation loss: 0.004029267933219671\n",
            "MCC Train: 0.010787073255960657 MCC val: 0.2342301214537113\n",
            "\n",
            "Epoch: 20\n",
            "Training loss: 0.004360118880867958 Validation loss: 0.004037909209728241\n",
            "MCC Train: 0.005257517600698974 MCC val: 0.19443589427242686\n",
            "\n",
            "Epoch: 21\n",
            "Training loss: 0.004348586779087782 Validation loss: 0.004030832555145025\n",
            "MCC Train: -0.02324333222244332 MCC val: 0.22216738586418283\n",
            "\n",
            "Epoch: 22\n",
            "Training loss: 0.004339404869824648 Validation loss: 0.0040289307944476604\n",
            "MCC Train: -0.011919893839854152 MCC val: 0.2571586440192939\n",
            "\n",
            "Epoch: 23\n",
            "Training loss: 0.004288900643587112 Validation loss: 0.004030547104775906\n",
            "MCC Train: 0.021867196912899553 MCC val: 0.2211640703209376\n",
            "\n",
            "Epoch: 24\n",
            "Training loss: 0.004294231534004211 Validation loss: 0.004034611862152815\n",
            "MCC Train: 0.01632848847413128 MCC val: 0.22298946584337698\n",
            "\n",
            "Epoch: 25\n",
            "Training loss: 0.00426893075928092 Validation loss: 0.004040318075567484\n",
            "MCC Train: 0.015515974526498607 MCC val: 0.15575223949534953\n",
            "\n",
            "Epoch: 26\n",
            "Training loss: 0.004239357076585293 Validation loss: 0.004034968558698893\n",
            "MCC Train: 0.03902369399787987 MCC val: 0.19589335177064646\n",
            "\n",
            "Epoch: 27\n",
            "Training loss: 0.004225229378789663 Validation loss: 0.004034352023154497\n",
            "MCC Train: 0.02601056074397966 MCC val: 0.25614123909839465\n",
            "\n",
            "Epoch: 28\n",
            "Training loss: 0.0042136553674936295 Validation loss: 0.004034146200865507\n",
            "MCC Train: 0.013548227953381812 MCC val: 0.26408023059117447\n",
            "Early stopping\n",
            "\n",
            "0.0001\t0.5\t0.0005\t3\tTrue\ttrain_losses\tearly_stopping_model_0.0001_0.5_0.0005_3_True.pt\t0.005189513,0.0049135042,0.004817442,0.004733729,0.004608204,0.0045071705,0.004536789,0.0045979153,0.00448883,0.004515311,0.004504499,0.0044966014,0.0043929927,0.0043725185,0.0045054504,0.0043590628,0.00431189,0.0043812264,0.0043569314,0.004360119,0.004348587,0.004339405,0.0042889006,0.0042942315,0.0042689308,0.004239357,0.0042252294,0.0042136554\n",
            "\n",
            "0.0001\t0.5\t0.0005\t3\tTrue\tval_losses\tearly_stopping_model_0.0001_0.5_0.0005_3_True.pt\t0.0040520714,0.0040411823,0.0040423544,0.0040363707,0.0040352778,0.0040347795,0.00403851,0.004040629,0.004039709,0.00402998,0.0040339017,0.0040354924,0.0040302696,0.004037727,0.004035584,0.004037938,0.0040363776,0.0040276493,0.004029268,0.004037909,0.0040308326,0.004028931,0.004030547,0.004034612,0.004040318,0.0040349686,0.004034352,0.004034146\n",
            "\n",
            "0.0001\t0.5\t0.0005\t3\tTrue\ttrain_acc\tearly_stopping_model_0.0001_0.5_0.0005_3_True.pt\t0.3866794441782463,0.4458552946813608,0.4633445136559655,0.4870627695256349,0.5011978917105894,0.5033540967896503,0.5071873502635362,0.5009583133684715,0.4947292764734068,0.5062290368950647,0.4954480114997604,0.5035936751317681,0.5071873502635362,0.5026353617632966,0.4918543363679923,0.5004791566842357,0.5256348826066124,0.5031145184475323,0.5069477719214183,0.5026353617632966,0.4880210828941064,0.49976042165788215,0.5088643986583613,0.5074269286056541,0.5023957834211787,0.5270723526593196,0.5134163871586008,0.5107810253953042\n",
            "\n",
            "0.0001\t0.5\t0.0005\t3\tTrue\tval_acc\tearly_stopping_model_0.0001_0.5_0.0005_3_True.pt\t0.4706266318537859,0.6338120104438643,0.6984334203655352,0.693864229765013,0.7121409921671018,0.7362924281984334,0.7369451697127938,0.7310704960835509,0.7369451697127938,0.7571801566579635,0.7467362924281984,0.7389033942558747,0.7532637075718016,0.7539164490861618,0.7565274151436031,0.758485639686684,0.7552219321148825,0.7610966057441253,0.7637075718015666,0.762402088772846,0.762402088772846,0.7734986945169713,0.7656657963446475,0.7656657963446475,0.7578328981723238,0.7630548302872062,0.7734986945169713,0.7741514360313316\n",
            "\n",
            "0.0001 0.5 0.005 2 False\n",
            "\n",
            "Epoch: 1\n",
            "Training loss: 0.012996818870306015 Validation loss: 0.0109536899253726\n",
            "MCC Train: 0.011317494864193567 MCC val: 0.08000465092458282\n",
            "\n",
            "Epoch: 2\n",
            "Training loss: 0.01255331002175808 Validation loss: 0.010560969822108746\n",
            "MCC Train: -0.049826528990000944 MCC val: 0.13542674387205642\n",
            "\n",
            "Epoch: 3\n",
            "Training loss: 0.011533902958035469 Validation loss: 0.010282626375555992\n",
            "MCC Train: -0.028829036074815344 MCC val: 0.16992684475149464\n",
            "\n",
            "Epoch: 4\n",
            "Training loss: 0.010988207533955574 Validation loss: 0.01016811653971672\n",
            "MCC Train: 0.008275540283870756 MCC val: 0.1669318360135837\n",
            "\n",
            "Epoch: 5\n",
            "Training loss: 0.010667976923286915 Validation loss: 0.009989103302359581\n",
            "MCC Train: -0.0037826073764214195 MCC val: 0.19422180273661266\n",
            "\n",
            "Epoch: 6\n",
            "Training loss: 0.010576528497040272 Validation loss: 0.009901870973408222\n",
            "MCC Train: 0.016280824441629326 MCC val: 0.18654024714494563\n",
            "\n",
            "Epoch: 7\n",
            "Training loss: 0.0106602618470788 Validation loss: 0.009679263457655907\n",
            "MCC Train: -0.0006415394042453275 MCC val: 0.1398011036989461\n",
            "\n",
            "Epoch: 8\n",
            "Training loss: 0.010592460632324219 Validation loss: 0.009629989042878151\n",
            "MCC Train: -0.012060330568573356 MCC val: 0.11152450116306847\n",
            "\n",
            "Epoch: 9\n",
            "Training loss: 0.010273758322000504 Validation loss: 0.009657840244472027\n",
            "MCC Train: -0.001954754905572835 MCC val: 0.12888481555661677\n",
            "\n",
            "Epoch: 10\n",
            "Training loss: 0.010283030569553375 Validation loss: 0.009690526872873306\n",
            "MCC Train: -0.021632704999282437 MCC val: 0.07414122823257416\n",
            "\n",
            "Epoch: 11\n",
            "Training loss: 0.010056642815470695 Validation loss: 0.009674792177975178\n",
            "MCC Train: 0.047507810624061286 MCC val: 0.10259783520851541\n",
            "\n",
            "Epoch: 12\n",
            "Training loss: 0.010006271302700043 Validation loss: 0.009616606868803501\n",
            "MCC Train: -0.008571755107437965 MCC val: 0.06551791708748941\n",
            "\n",
            "Epoch: 13\n",
            "Training loss: 0.009918139316141605 Validation loss: 0.009648187085986137\n",
            "MCC Train: 0.03164461825480629 MCC val: 0.11099385888363648\n",
            "\n",
            "Epoch: 14\n",
            "Training loss: 0.009928904473781586 Validation loss: 0.009530225768685341\n",
            "MCC Train: 0.009908766039685999 MCC val: 0.10259783520851541\n",
            "\n",
            "Epoch: 15\n",
            "Training loss: 0.009929024614393711 Validation loss: 0.00960485078394413\n",
            "MCC Train: 0.022267435117116038 MCC val: 0.08037486332952987\n",
            "\n",
            "Epoch: 16\n",
            "Training loss: 0.009886675514280796 Validation loss: 0.009532610885798931\n",
            "MCC Train: 0.021848841162904274 MCC val: 0.10297049891304745\n",
            "\n",
            "Epoch: 17\n",
            "Training loss: 0.009758043102920055 Validation loss: 0.009617682546377182\n",
            "MCC Train: 0.0036411537905256036 MCC val: 0.06839855680567694\n",
            "\n",
            "Epoch: 18\n",
            "Training loss: 0.00961229670792818 Validation loss: 0.009614186361432076\n",
            "MCC Train: 0.02549127341898973 MCC val: 0.06551791708748941\n",
            "\n",
            "Epoch: 19\n",
            "Training loss: 0.009747860953211784 Validation loss: 0.009564138017594814\n",
            "MCC Train: 0.052273543674957394 MCC val: 0.0944967006892155\n",
            "\n",
            "Epoch: 20\n",
            "Training loss: 0.009540969505906105 Validation loss: 0.009571664966642857\n",
            "MCC Train: 0.026839287419444604 MCC val: 0.019822394114938215\n",
            "\n",
            "Epoch: 21\n",
            "Training loss: 0.00984035711735487 Validation loss: 0.009623387828469276\n",
            "MCC Train: 0.01348747954425865 MCC val: 0.06839855680567694\n",
            "\n",
            "Epoch: 22\n",
            "Training loss: 0.009524356573820114 Validation loss: 0.00969924870878458\n",
            "MCC Train: 0.01149991047306901 MCC val: 0.1049207622848424\n",
            "\n",
            "Epoch: 23\n",
            "Training loss: 0.009701104834675789 Validation loss: 0.009692159481346607\n",
            "MCC Train: 0.028847863698099583 MCC val: 0.09093132731353008\n",
            "\n",
            "Epoch: 24\n",
            "Training loss: 0.009525119327008724 Validation loss: 0.009621837176382542\n",
            "MCC Train: 0.0613790897228618 MCC val: 0.1049207622848424\n",
            "Early stopping\n",
            "\n",
            "0.0001\t0.5\t0.005\t2\tFalse\ttrain_losses\tearly_stopping_model_0.0001_0.5_0.005_2_False.pt\t0.012996819,0.01255331,0.011533903,0.0109882075,0.010667977,0.0105765285,0.010660262,0.010592461,0.010273758,0.010283031,0.010056643,0.010006271,0.009918139,0.0099289045,0.009929025,0.0098866755,0.009758043,0.009612297,0.009747861,0.0095409695,0.009840357,0.009524357,0.009701105,0.009525119\n",
            "\n",
            "0.0001\t0.5\t0.005\t2\tFalse\tval_losses\tearly_stopping_model_0.0001_0.5_0.005_2_False.pt\t0.01095369,0.01056097,0.010282626,0.010168117,0.009989103,0.009901871,0.009679263,0.009629989,0.00965784,0.009690527,0.009674792,0.009616607,0.009648187,0.009530226,0.009604851,0.009532611,0.009617683,0.009614186,0.009564138,0.009571665,0.009623388,0.009699249,0.0096921595,0.009621837\n",
            "\n",
            "0.0001\t0.5\t0.005\t2\tFalse\ttrain_acc\tearly_stopping_model_0.0001_0.5_0.005_2_False.pt\t0.5218016291327264,0.53378054623862,0.579060852898898,0.6169142309535218,0.6312889314805942,0.6550071873502635,0.6528509822712026,0.659798754192621,0.6732151413512218,0.6770483948251078,0.693579300431241,0.6868711068519406,0.7053186391950168,0.7022041207474844,0.7053186391950168,0.7077144226161955,0.7060373742213704,0.7081935793004313,0.7170579779587926,0.7168183996166747,0.7165788212745567,0.7170579779587926,0.7213703881169142,0.729276473406804\n",
            "\n",
            "0.0001\t0.5\t0.005\t2\tFalse\tval_acc\tearly_stopping_model_0.0001_0.5_0.005_2_False.pt\t0.4640992167101828,0.6364229765013055,0.720626631853786,0.7356396866840731,0.7558746736292428,0.758485639686684,0.7571801566579635,0.7545691906005222,0.7558746736292428,0.7513054830287206,0.7539164490861618,0.7513054830287206,0.7545691906005222,0.7539164490861618,0.7519582245430809,0.7539164490861618,0.7513054830287206,0.7513054830287206,0.7532637075718016,0.7493472584856397,0.7513054830287206,0.7539164490861618,0.7526109660574413,0.7539164490861618\n",
            "\n",
            "0.0001 0.5 0.005 2 True\n",
            "loss weight 0.2496406324868232\n",
            "\n",
            "Epoch: 1\n",
            "Training loss: 0.005185125861316919 Validation loss: 0.004085289314389229\n",
            "MCC Train: -0.0004913800051750913 MCC val: -0.009951357233775536\n",
            "\n",
            "Epoch: 2\n",
            "Training loss: 0.005187582690268755 Validation loss: 0.004047730006277561\n",
            "MCC Train: -0.0030032546780794406 MCC val: 0.050424085068004304\n",
            "\n",
            "Epoch: 3\n",
            "Training loss: 0.004988459870219231 Validation loss: 0.004032773431390524\n",
            "MCC Train: 0.006316124078445372 MCC val: 0.09469147805536393\n",
            "\n",
            "Epoch: 4\n",
            "Training loss: 0.0050184763967990875 Validation loss: 0.004019440617412329\n",
            "MCC Train: -0.010486092488366603 MCC val: 0.13702693599231328\n",
            "\n",
            "Epoch: 5\n",
            "Training loss: 0.004956528544425964 Validation loss: 0.004021323285996914\n",
            "MCC Train: 0.001566387024702621 MCC val: 0.1412050375712278\n",
            "\n",
            "Epoch: 6\n",
            "Training loss: 0.00492370780557394 Validation loss: 0.004003357142210007\n",
            "MCC Train: -0.005043446830618361 MCC val: 0.15071553677617988\n",
            "\n",
            "Epoch: 7\n",
            "Training loss: 0.004747926257550716 Validation loss: 0.004007801879197359\n",
            "MCC Train: 0.016069135783233796 MCC val: 0.14650309572284606\n",
            "\n",
            "Epoch: 8\n",
            "Training loss: 0.00474913977086544 Validation loss: 0.00400321651250124\n",
            "MCC Train: -0.009509552073138288 MCC val: 0.1366968182092803\n",
            "\n",
            "Epoch: 9\n",
            "Training loss: 0.004745196551084518 Validation loss: 0.004003128968179226\n",
            "MCC Train: 0.008262760646385932 MCC val: 0.16785233553338114\n",
            "\n",
            "Epoch: 10\n",
            "Training loss: 0.004628531634807587 Validation loss: 0.003998046740889549\n",
            "MCC Train: 0.038197956686620745 MCC val: 0.1387229658739604\n",
            "\n",
            "Epoch: 11\n",
            "Training loss: 0.004678844008594751 Validation loss: 0.003992618527263403\n",
            "MCC Train: 0.011318687821364644 MCC val: 0.1388935992248077\n",
            "\n",
            "Epoch: 12\n",
            "Training loss: 0.004556714557111263 Validation loss: 0.003996765241026878\n",
            "MCC Train: 0.01935637891317144 MCC val: 0.15767407133430889\n",
            "\n",
            "Epoch: 13\n",
            "Training loss: 0.004550912883132696 Validation loss: 0.003992422018200159\n",
            "MCC Train: 0.016593449617216212 MCC val: 0.14553376779804983\n",
            "\n",
            "Epoch: 14\n",
            "Training loss: 0.004518010653555393 Validation loss: 0.00399977108463645\n",
            "MCC Train: 0.0293364864175207 MCC val: 0.1275082907480079\n",
            "\n",
            "Epoch: 15\n",
            "Training loss: 0.00458215456455946 Validation loss: 0.003996999468654394\n",
            "MCC Train: -0.007508644697080533 MCC val: 0.14148809217507066\n",
            "\n",
            "Epoch: 16\n",
            "Training loss: 0.004486837889999151 Validation loss: 0.003986116033047438\n",
            "MCC Train: 0.013813768148113378 MCC val: 0.16359774630542176\n",
            "\n",
            "Epoch: 17\n",
            "Training loss: 0.004529851954430342 Validation loss: 0.003983765374869108\n",
            "MCC Train: 0.01244710457279629 MCC val: 0.15678732452622984\n",
            "\n",
            "Epoch: 18\n",
            "Training loss: 0.0044499896466732025 Validation loss: 0.0039894175715744495\n",
            "MCC Train: 0.01741747067181152 MCC val: 0.1721590893695281\n",
            "\n",
            "Epoch: 19\n",
            "Training loss: 0.004387666936963797 Validation loss: 0.003983818925917149\n",
            "MCC Train: 0.030452554132182418 MCC val: 0.158085014900874\n",
            "\n",
            "Epoch: 20\n",
            "Training loss: 0.004392760340124369 Validation loss: 0.003982766065746546\n",
            "MCC Train: 0.012428794773220805 MCC val: 0.16179338891238532\n",
            "\n",
            "Epoch: 21\n",
            "Training loss: 0.004390755668282509 Validation loss: 0.003979204222559929\n",
            "MCC Train: 0.015756715881422828 MCC val: 0.1557450379250064\n",
            "\n",
            "Epoch: 22\n",
            "Training loss: 0.004293609410524368 Validation loss: 0.003975375089794397\n",
            "MCC Train: 0.06919346436229591 MCC val: 0.16007091416884003\n",
            "\n",
            "Epoch: 23\n",
            "Training loss: 0.004343044478446245 Validation loss: 0.003972336649894714\n",
            "MCC Train: 0.020746841780622884 MCC val: 0.17894091724227432\n",
            "\n",
            "Epoch: 24\n",
            "Training loss: 0.0043641491793096066 Validation loss: 0.0039742933586239815\n",
            "MCC Train: 0.015760638835968822 MCC val: 0.1488651337414384\n",
            "\n",
            "Epoch: 25\n",
            "Training loss: 0.004404901526868343 Validation loss: 0.00397119065746665\n",
            "MCC Train: 0.022403311473707093 MCC val: 0.1933371694900547\n",
            "\n",
            "Epoch: 26\n",
            "Training loss: 0.004313471727073193 Validation loss: 0.003964459989219904\n",
            "MCC Train: 0.03431810650505938 MCC val: 0.18985028769884515\n",
            "\n",
            "Epoch: 27\n",
            "Training loss: 0.004296593833714724 Validation loss: 0.003960451111197472\n",
            "MCC Train: 0.032927534249238645 MCC val: 0.19336494655432562\n",
            "\n",
            "Epoch: 28\n",
            "Training loss: 0.004324598237872124 Validation loss: 0.003961347509175539\n",
            "MCC Train: 0.022682570131098527 MCC val: 0.17150165563891562\n",
            "\n",
            "Epoch: 29\n",
            "Training loss: 0.0042528980411589146 Validation loss: 0.0039598834700882435\n",
            "MCC Train: 0.04068462439568235 MCC val: 0.20075290955099448\n",
            "\n",
            "Epoch: 30\n",
            "Training loss: 0.004253560211509466 Validation loss: 0.003942492883652449\n",
            "MCC Train: 0.037918702545180656 MCC val: 0.17197811495865173\n",
            "\n",
            "Epoch: 31\n",
            "Training loss: 0.004236592911183834 Validation loss: 0.003938367590308189\n",
            "MCC Train: 0.03654688769176143 MCC val: 0.17723431380090365\n",
            "\n",
            "Epoch: 32\n",
            "Training loss: 0.004199934657663107 Validation loss: 0.0039317491464316845\n",
            "MCC Train: 0.06176385745212543 MCC val: 0.19336805978608618\n",
            "\n",
            "Epoch: 33\n",
            "Training loss: 0.004208177328109741 Validation loss: 0.003928092774003744\n",
            "MCC Train: 0.061194591726191704 MCC val: 0.19218363049550188\n",
            "\n",
            "Epoch: 34\n",
            "Training loss: 0.004255590029060841 Validation loss: 0.003910100553184748\n",
            "MCC Train: 0.042900886493528106 MCC val: 0.18354008153286647\n",
            "\n",
            "Epoch: 35\n",
            "Training loss: 0.004178245086222887 Validation loss: 0.003897974034771323\n",
            "MCC Train: 0.06256081897278958 MCC val: 0.21916182207351018\n",
            "\n",
            "Epoch: 36\n",
            "Training loss: 0.004139390308409929 Validation loss: 0.003894287394359708\n",
            "MCC Train: 0.08139329221507365 MCC val: 0.2013458072889651\n",
            "\n",
            "Epoch: 37\n",
            "Training loss: 0.004105773754417896 Validation loss: 0.0038814886938780546\n",
            "MCC Train: 0.10778804691843857 MCC val: 0.21334742252563246\n",
            "\n",
            "Epoch: 38\n",
            "Training loss: 0.004145916551351547 Validation loss: 0.0038729712832719088\n",
            "MCC Train: 0.0866853461688816 MCC val: 0.21122332598326946\n",
            "\n",
            "Epoch: 39\n",
            "Training loss: 0.004081805236637592 Validation loss: 0.0038603267166763544\n",
            "MCC Train: 0.09137334828009373 MCC val: 0.21284625471813695\n",
            "\n",
            "Epoch: 40\n",
            "Training loss: 0.004105907399207354 Validation loss: 0.003841561730951071\n",
            "MCC Train: 0.08971955433637802 MCC val: 0.23665719512263725\n",
            "\n",
            "Epoch: 41\n",
            "Training loss: 0.004056156612932682 Validation loss: 0.0038316315039992332\n",
            "MCC Train: 0.11137418762075951 MCC val: 0.23606412148994307\n",
            "\n",
            "Epoch: 42\n",
            "Training loss: 0.004065647255629301 Validation loss: 0.003822671016678214\n",
            "MCC Train: 0.11545636028120891 MCC val: 0.24710455234619128\n",
            "\n",
            "Epoch: 43\n",
            "Training loss: 0.00402970751747489 Validation loss: 0.0038189548067748547\n",
            "MCC Train: 0.1250062085074105 MCC val: 0.24374756789551086\n",
            "\n",
            "Epoch: 44\n",
            "Training loss: 0.004049001261591911 Validation loss: 0.003803458297625184\n",
            "MCC Train: 0.0847414411043401 MCC val: 0.2344879124778939\n",
            "\n",
            "Epoch: 45\n",
            "Training loss: 0.003984207287430763 Validation loss: 0.0037900733295828104\n",
            "MCC Train: 0.14470530723119743 MCC val: 0.23232032519337617\n",
            "\n",
            "Epoch: 46\n",
            "Training loss: 0.0039565288461744785 Validation loss: 0.0037671991158276796\n",
            "MCC Train: 0.16814472874125533 MCC val: 0.2609618601058399\n",
            "\n",
            "Epoch: 47\n",
            "Training loss: 0.003973032347857952 Validation loss: 0.0037687201984226704\n",
            "MCC Train: 0.18338018515130478 MCC val: 0.25297316928293645\n",
            "\n",
            "Epoch: 48\n",
            "Training loss: 0.003965433686971664 Validation loss: 0.003756902879104018\n",
            "MCC Train: 0.14850538236044608 MCC val: 0.2504414893580128\n",
            "\n",
            "Epoch: 49\n",
            "Training loss: 0.003936789929866791 Validation loss: 0.0037479852326214314\n",
            "MCC Train: 0.17219354760540234 MCC val: 0.2579978002386601\n",
            "\n",
            "Epoch: 50\n",
            "Training loss: 0.003921933472156525 Validation loss: 0.0037528870161622763\n",
            "MCC Train: 0.16726498295211792 MCC val: 0.23529415601856868\n",
            "0.0001\t0.5\t0.005\t2\tTrue\ttrain_losses\tearly_stopping_model_0.0001_0.5_0.005_2_True.pt\t0.005185126,0.0051875827,0.00498846,0.0050184764,0.0049565285,0.004923708,0.0047479263,0.00474914,0.0047451966,0.0046285316,0.004678844,0.0045567146,0.004550913,0.0045180107,0.0045821546,0.004486838,0.004529852,0.0044499896,0.004387667,0.0043927603,0.0043907557,0.0042936094,0.0043430445,0.004364149,0.0044049015,0.0043134717,0.004296594,0.0043245982,0.004252898,0.00425356,0.004236593,0.0041999347,0.0042081773,0.00425559,0.004178245,0.0041393903,0.0041057738,0.0041459166,0.0040818052,0.0041059074,0.0040561566,0.0040656473,0.0040297075,0.0040490013,0.0039842073,0.003956529,0.0039730323,0.0039654337,0.00393679,0.0039219335\n",
            "\n",
            "0.0001\t0.5\t0.005\t2\tTrue\tval_losses\tearly_stopping_model_0.0001_0.5_0.005_2_True.pt\t0.0040852893,0.00404773,0.0040327734,0.0040194406,0.0040213233,0.004003357,0.004007802,0.0040032165,0.004003129,0.0039980467,0.0039926185,0.0039967652,0.003992422,0.003999771,0.0039969995,0.003986116,0.0039837654,0.0039894176,0.003983819,0.003982766,0.003979204,0.003975375,0.0039723366,0.0039742934,0.0039711907,0.00396446,0.003960451,0.0039613475,0.0039598835,0.003942493,0.0039383676,0.003931749,0.003928093,0.0039101006,0.003897974,0.0038942874,0.0038814887,0.0038729713,0.0038603267,0.0038415617,0.0038316315,0.003822671,0.0038189548,0.0038034583,0.0037900733,0.003767199,0.0037687202,0.0037569029,0.0037479852,0.003752887\n",
            "\n",
            "0.0001\t0.5\t0.005\t2\tTrue\ttrain_acc\tearly_stopping_model_0.0001_0.5_0.005_2_True.pt\t0.560134163871586,0.5503114518447533,0.5448011499760421,0.5333013895543843,0.5330618112122664,0.5134163871586008,0.5368950646861523,0.5162913272640154,0.524436990896023,0.528270244369909,0.5270723526593196,0.5191662673694298,0.5273119310014375,0.526353617632966,0.5059894585529469,0.5210828941063728,0.5079060852898898,0.5213224724484906,0.5287494010541447,0.5179683756588405,0.5155725922376617,0.5359367513176809,0.5246765692381409,0.5270723526593196,0.518926689027312,0.526353617632966,0.5232390991854337,0.52252036415908,0.5179683756588405,0.5275515093435553,0.5301868711068519,0.5400095831336847,0.5380929563967417,0.5285098227120268,0.5359367513176809,0.5440824149496886,0.5606133205558218,0.5491135601341639,0.5493531384762818,0.5493531384762818,0.5613320555821754,0.5586966938188788,0.5692381408720651,0.5479156684235745,0.5781025395304265,0.5915189266890273,0.5975083852419741,0.584571154767609,0.5908001916626737,0.5953521801629132\n",
            "\n",
            "0.0001\t0.5\t0.005\t2\tTrue\tval_acc\tearly_stopping_model_0.0001_0.5_0.005_2_True.pt\t0.7369451697127938,0.7134464751958225,0.6984334203655352,0.7010443864229765,0.7043080939947781,0.6325065274151436,0.6370757180156658,0.6122715404699739,0.6488250652741514,0.5659268929503917,0.5463446475195822,0.5574412532637075,0.5704960835509139,0.5254569190600522,0.5391644908616188,0.5652741514360313,0.564621409921671,0.5593994778067886,0.5202349869451697,0.5502610966057441,0.5476501305483029,0.5404699738903395,0.5626631853785901,0.49869451697127937,0.556135770234987,0.5372062663185379,0.5672323759791122,0.5176240208877284,0.5613577023498695,0.5013054830287206,0.4934725848563969,0.5254569190600522,0.5228459530026109,0.5071801566579635,0.5535248041775457,0.5156657963446475,0.5345953002610966,0.5326370757180157,0.54177545691906,0.5737597911227154,0.5600522193211488,0.5887728459530026,0.5744125326370757,0.5718015665796344,0.5698433420365535,0.6037859007832899,0.5939947780678851,0.5861618798955613,0.6011749347258486,0.5652741514360313\n",
            "\n",
            "0.0001 0.5 0.005 3 False\n",
            "\n",
            "Epoch: 1\n",
            "Training loss: 0.01637851819396019 Validation loss: 0.011032415553927422\n",
            "MCC Train: -0.028894616868465374 MCC val: 0.05954294706474296\n",
            "\n",
            "Epoch: 2\n",
            "Training loss: 0.012832678854465485 Validation loss: 0.01029546745121479\n",
            "MCC Train: 0.011597786167790962 MCC val: 0.03231094268435045\n",
            "\n",
            "Epoch: 3\n",
            "Training loss: 0.011115431785583496 Validation loss: 0.009950685314834118\n",
            "MCC Train: 0.0035500337368364844 MCC val: 0.0\n",
            "\n",
            "Epoch: 4\n",
            "Training loss: 0.01101130060851574 Validation loss: 0.009806257672607899\n",
            "MCC Train: -0.032769755157282685 MCC val: 0.0\n",
            "\n",
            "Epoch: 5\n",
            "Training loss: 0.010611090809106827 Validation loss: 0.00974670983850956\n",
            "MCC Train: -0.016507318759930795 MCC val: 0.0\n",
            "\n",
            "Epoch: 6\n",
            "Training loss: 0.010295716114342213 Validation loss: 0.009645305573940277\n",
            "MCC Train: -0.005989961393726513 MCC val: 0.0\n",
            "\n",
            "Epoch: 7\n",
            "Training loss: 0.010169881395995617 Validation loss: 0.0096325958147645\n",
            "MCC Train: 0.007335095302427401 MCC val: 0.0\n",
            "\n",
            "Epoch: 8\n",
            "Training loss: 0.010188194923102856 Validation loss: 0.009617345407605171\n",
            "MCC Train: -0.010575579418700517 MCC val: 0.0\n",
            "\n",
            "Epoch: 9\n",
            "Training loss: 0.010233823210000992 Validation loss: 0.009584619663655758\n",
            "MCC Train: 0.01730979593117046 MCC val: 0.0\n",
            "\n",
            "Epoch: 10\n",
            "Training loss: 0.0100546320900321 Validation loss: 0.009634454734623432\n",
            "MCC Train: 0.008902357516830732 MCC val: 0.0\n",
            "\n",
            "Epoch: 11\n",
            "Training loss: 0.00982909556478262 Validation loss: 0.009718289598822594\n",
            "MCC Train: 0.006228007148814301 MCC val: 0.0\n",
            "\n",
            "Epoch: 12\n",
            "Training loss: 0.009674866683781147 Validation loss: 0.009686535224318504\n",
            "MCC Train: -0.007438590845634987 MCC val: 0.0\n",
            "\n",
            "Epoch: 13\n",
            "Training loss: 0.009776001796126366 Validation loss: 0.009672221727669239\n",
            "MCC Train: 0.012126751341143244 MCC val: 0.0\n",
            "\n",
            "Epoch: 14\n",
            "Training loss: 0.009717870503664017 Validation loss: 0.009707394987344742\n",
            "MCC Train: 0.012391638721026811 MCC val: 0.0\n",
            "\n",
            "Epoch: 15\n",
            "Training loss: 0.009635094553232193 Validation loss: 0.00971703976392746\n",
            "MCC Train: 0.0007848603101284118 MCC val: 0.0\n",
            "\n",
            "Epoch: 16\n",
            "Training loss: 0.00961262546479702 Validation loss: 0.009701279923319817\n",
            "MCC Train: -0.0033179108212587605 MCC val: 0.0\n",
            "\n",
            "Epoch: 17\n",
            "Training loss: 0.009680262766778469 Validation loss: 0.009724986739456654\n",
            "MCC Train: 0.018888404529419832 MCC val: 0.0\n",
            "\n",
            "Epoch: 18\n",
            "Training loss: 0.009613696485757828 Validation loss: 0.009764008224010468\n",
            "MCC Train: 0.011205875321164318 MCC val: 0.0\n",
            "\n",
            "Epoch: 19\n",
            "Training loss: 0.009518980979919434 Validation loss: 0.009752173908054829\n",
            "MCC Train: -0.0038887148199051023 MCC val: 0.0\n",
            "Early stopping\n",
            "\n",
            "0.0001\t0.5\t0.005\t3\tFalse\ttrain_losses\tearly_stopping_model_0.0001_0.5_0.005_3_False.pt\t0.016378518,0.012832679,0.011115432,0.011011301,0.010611091,0.010295716,0.010169881,0.010188195,0.010233823,0.010054632,0.009829096,0.009674867,0.009776002,0.0097178705,0.009635095,0.009612625,0.009680263,0.0096136965,0.009518981\n",
            "\n",
            "0.0001\t0.5\t0.005\t3\tFalse\tval_losses\tearly_stopping_model_0.0001_0.5_0.005_3_False.pt\t0.011032416,0.010295467,0.009950685,0.009806258,0.00974671,0.009645306,0.009632596,0.009617345,0.00958462,0.009634455,0.00971829,0.009686535,0.009672222,0.009707395,0.00971704,0.00970128,0.009724987,0.009764008,0.009752174\n",
            "\n",
            "0.0001\t0.5\t0.005\t3\tFalse\ttrain_acc\tearly_stopping_model_0.0001_0.5_0.005_3_False.pt\t0.38907522759942503,0.5172496406324868,0.5970292285577384,0.6200287494010541,0.6542884523239099,0.6770483948251078,0.687829420220412,0.6952563488260661,0.7014853857211308,0.706756109247724,0.7096310493531385,0.7089123143267848,0.7177767129851461,0.716099664590321,0.7189746046957355,0.7201724964063249,0.7261619549592717,0.725443219932918,0.7278390033540968\n",
            "\n",
            "0.0001\t0.5\t0.005\t3\tFalse\tval_acc\tearly_stopping_model_0.0001_0.5_0.005_3_False.pt\t0.4007832898172324,0.7408616187989556,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75\n",
            "\n",
            "0.0001 0.5 0.005 3 True\n",
            "loss weight 0.2496406324868232\n",
            "\n",
            "Epoch: 1\n",
            "Training loss: 0.00516040064394474 Validation loss: 0.004049181006848812\n",
            "MCC Train: -0.012274459410622168 MCC val: 0.029230678866776678\n",
            "\n",
            "Epoch: 2\n",
            "Training loss: 0.005160490516573191 Validation loss: 0.004063109401613474\n",
            "MCC Train: 0.00466929636117026 MCC val: 0.03992411660227938\n",
            "\n",
            "Epoch: 3\n",
            "Training loss: 0.004999840632081032 Validation loss: 0.004050894174724817\n",
            "MCC Train: 0.012707100827940337 MCC val: 0.04132504849158291\n",
            "\n",
            "Epoch: 4\n",
            "Training loss: 0.004908889532089233 Validation loss: 0.004050763323903084\n",
            "MCC Train: 0.007759733216269123 MCC val: 0.04416910861698556\n",
            "\n",
            "Epoch: 5\n",
            "Training loss: 0.0047478023916482925 Validation loss: 0.004041935782879591\n",
            "MCC Train: 0.022133833954274994 MCC val: 0.05102704997541358\n",
            "\n",
            "Epoch: 6\n",
            "Training loss: 0.004926417954266071 Validation loss: 0.004045584704726934\n",
            "MCC Train: -0.018827550014988835 MCC val: 0.04927910996265743\n",
            "\n",
            "Epoch: 7\n",
            "Training loss: 0.0046400767751038074 Validation loss: 0.004046168178319931\n",
            "MCC Train: 0.015493432862916342 MCC val: 0.03461246119942309\n",
            "\n",
            "Epoch: 8\n",
            "Training loss: 0.004659584257751703 Validation loss: 0.004041074309498072\n",
            "MCC Train: 0.019664389325049655 MCC val: 0.05817710130303743\n",
            "\n",
            "Epoch: 9\n",
            "Training loss: 0.00463460898026824 Validation loss: 0.004044349305331707\n",
            "MCC Train: -0.0016743931749156893 MCC val: 0.05236374221430269\n",
            "\n",
            "Epoch: 10\n",
            "Training loss: 0.004601352382451296 Validation loss: 0.004043210297822952\n",
            "MCC Train: -0.03791615560978139 MCC val: 0.05610368565632842\n",
            "\n",
            "Epoch: 11\n",
            "Training loss: 0.004502449184656143 Validation loss: 0.004039095249027014\n",
            "MCC Train: 0.017703988601458966 MCC val: 0.06833943479858152\n",
            "\n",
            "Epoch: 12\n",
            "Training loss: 0.0044722487218678 Validation loss: 0.0040426054038107395\n",
            "MCC Train: 0.008630289096199211 MCC val: 0.05075913250845873\n",
            "\n",
            "Epoch: 13\n",
            "Training loss: 0.0044927136041224 Validation loss: 0.004036543890833855\n",
            "MCC Train: 0.0003019764267394206 MCC val: 0.07441405122512211\n",
            "\n",
            "Epoch: 14\n",
            "Training loss: 0.0043572066351771355 Validation loss: 0.00404079956933856\n",
            "MCC Train: 0.018538368073183778 MCC val: 0.07183229690961629\n",
            "\n",
            "Epoch: 15\n",
            "Training loss: 0.0044386126101017 Validation loss: 0.004036652389913797\n",
            "MCC Train: -0.0013914868274999903 MCC val: 0.066055146976738\n",
            "\n",
            "Epoch: 16\n",
            "Training loss: 0.004390375688672066 Validation loss: 0.0040439399890601635\n",
            "MCC Train: -0.015522546302159332 MCC val: 0.05420770854544945\n",
            "\n",
            "Epoch: 17\n",
            "Training loss: 0.004365167114883661 Validation loss: 0.004039745777845383\n",
            "MCC Train: 0.004703181986069755 MCC val: 0.05456729532860966\n",
            "\n",
            "Epoch: 18\n",
            "Training loss: 0.004289194475859404 Validation loss: 0.004041857086122036\n",
            "MCC Train: 0.03436159763967509 MCC val: 0.05414245210726616\n",
            "\n",
            "Epoch: 19\n",
            "Training loss: 0.004345484543591738 Validation loss: 0.004044021479785442\n",
            "MCC Train: 0.0047305218749391816 MCC val: 0.04495002088719743\n",
            "\n",
            "Epoch: 20\n",
            "Training loss: 0.004352083429694176 Validation loss: 0.004043460823595524\n",
            "MCC Train: -0.0077392282436272025 MCC val: 0.04353961330028776\n",
            "\n",
            "Epoch: 21\n",
            "Training loss: 0.004334417637437582 Validation loss: 0.004045457579195499\n",
            "MCC Train: 0.005571402830619622 MCC val: 0.0781751739432523\n",
            "\n",
            "Epoch: 22\n",
            "Training loss: 0.004284068942070007 Validation loss: 0.004047651309520006\n",
            "MCC Train: 0.020517795819824623 MCC val: 0.04692345849296401\n",
            "\n",
            "Epoch: 23\n",
            "Training loss: 0.00424511544406414 Validation loss: 0.004042728804051876\n",
            "MCC Train: 0.010578560621978851 MCC val: 0.06722075488713869\n",
            "Early stopping\n",
            "\n",
            "0.0001\t0.5\t0.005\t3\tTrue\ttrain_losses\tearly_stopping_model_0.0001_0.5_0.005_3_True.pt\t0.0051604006,0.0051604905,0.0049998406,0.0049088895,0.0047478024,0.004926418,0.004640077,0.0046595843,0.004634609,0.0046013524,0.004502449,0.0044722487,0.0044927136,0.0043572066,0.0044386126,0.0043903757,0.004365167,0.0042891945,0.0043454845,0.0043520834,0.0043344176,0.004284069,0.0042451154\n",
            "\n",
            "0.0001\t0.5\t0.005\t3\tTrue\tval_losses\tearly_stopping_model_0.0001_0.5_0.005_3_True.pt\t0.004049181,0.0040631094,0.004050894,0.0040507633,0.004041936,0.0040455847,0.004046168,0.0040410743,0.0040443493,0.0040432103,0.0040390952,0.0040426054,0.004036544,0.0040407996,0.0040366524,0.00404394,0.004039746,0.004041857,0.0040440215,0.004043461,0.0040454576,0.0040476513,0.004042729\n",
            "\n",
            "0.0001\t0.5\t0.005\t3\tTrue\ttrain_acc\tearly_stopping_model_0.0001_0.5_0.005_3_True.pt\t0.5134163871586008,0.5146142788691902,0.5167704839482511,0.5004791566842357,0.5124580737901294,0.4937709631049353,0.5086248203162435,0.5050311451844753,0.5033540967896503,0.48298993770963106,0.5110206037374221,0.49161475802587445,0.492573071394346,0.5098227120268328,0.5016770483948251,0.49904168663152854,0.5026353617632966,0.5071873502635362,0.49496885481552466,0.4932918064206996,0.4928126497364638,0.5009583133684715,0.49089602299952084\n",
            "\n",
            "0.0001\t0.5\t0.005\t3\tTrue\tval_acc\tearly_stopping_model_0.0001_0.5_0.005_3_True.pt\t0.33616187989556134,0.3002610966057441,0.3074412532637076,0.304177545691906,0.3113577023498694,0.3002610966057441,0.29112271540469975,0.30156657963446476,0.29308093994778067,0.30221932114882505,0.29765013054830286,0.2904699738903394,0.2989556135770235,0.30156657963446476,0.30221932114882505,0.28655352480417756,0.29960835509138384,0.28263707571801566,0.2859007832898172,0.2904699738903394,0.2989556135770235,0.28133159268929503,0.3028720626631854\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XI_aik5CzDdM"
      },
      "source": [
        "## Performance evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "id": "bHxihZI4mILA",
        "outputId": "3be90a21-d36c-4653-f98f-e9a2167c7457"
      },
      "source": [
        "with open(drive_path+'models_parameter_tuning/record_metrics_parameter_tuning.txt', \"r\") as o:\n",
        "    header = o.readline()\n",
        "    tuning_results = o.read().splitlines()\n",
        "\n",
        "val_losses_list = []\n",
        "min_loss_model = [1]\n",
        "min_loss_model_weighted = [1]\n",
        "for i in range(len(tuning_results)):\n",
        "    learning_rate, dropout, weight_decay, num_fc, loss_weight, metric_name, filename, results = tuning_results[i].split(\"\\t\")\n",
        "    results = [float(i) for i in results.split(\",\")]\n",
        "    tuning_results[i] = [learning_rate, dropout, weight_decay, num_fc, loss_weight, metric_name, filename, results]\n",
        "    if metric_name == \"val_losses\":\n",
        "        val_losses_list.append(min(results))\n",
        "        if loss_weight == \"True\" and min(results) < min_loss_model_weighted[0]:\n",
        "            min_loss_model_weighted = [min(results), i]\n",
        "        elif (loss_weight == \"False\") and (min(results) < min_loss_model[0]):\n",
        "            min_loss_model = [min(results), i]\n",
        "\n",
        "plt.plot(list(range(len(tuning_results) // 4)), val_losses_list)\n",
        "print(min_loss_model)\n",
        "print(min_loss_model_weighted)\n",
        "print(tuning_results[min_loss_model[1]])\n",
        "print(tuning_results[min_loss_model_weighted[1]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.004996595, 41]\n",
            "[0.0024655857, 37]\n",
            "['0.001', '0.5', '0.0005', '3', 'False', 'val_losses', 'early_stopping_model_0.001_0.5_0.0005_3_False.pt', [0.009612054, 0.009643829, 0.009765155, 0.00986958, 0.009817706, 0.009795891, 0.00974362, 0.009704567, 0.009583751, 0.009417938, 0.009119192, 0.008934, 0.008670426, 0.00846089, 0.008376354, 0.008188663, 0.007927445, 0.007934066, 0.007905411, 0.00793033, 0.0078065507, 0.0077546514, 0.007754408, 0.0076957433, 0.007668937, 0.007606556, 0.0075348313, 0.0074576596, 0.007196842, 0.006860502, 0.0063740155, 0.006316848, 0.005954829, 0.0058624344, 0.0055927513, 0.0056353747, 0.005513258, 0.005163068, 0.005209354, 0.0051173856, 0.005179845, 0.005011499, 0.004996595, 0.00507959, 0.0054268776, 0.0053902525, 0.0049970145, 0.0051151114, 0.00533523, 0.0057038898]]\n",
            "['0.001', '0.5', '0.0005', '2', 'True', 'val_losses', 'early_stopping_model_0.001_0.5_0.0005_2_True.pt', [0.003936119, 0.003896522, 0.0038479264, 0.0037229673, 0.00367898, 0.0036685993, 0.0036317997, 0.0036201328, 0.0035876934, 0.003610527, 0.0035813234, 0.0035169353, 0.0034227914, 0.0035402079, 0.0039301817, 0.0033337015, 0.0034830365, 0.0031127622, 0.0032954852, 0.0030845846, 0.002858085, 0.002791255, 0.0026582852, 0.0025374522, 0.0025549047, 0.0024999748, 0.0025264162, 0.0025769982, 0.0025811114, 0.0024655857, 0.0026374361, 0.0025730846, 0.0025862132, 0.0025723944, 0.0027487462, 0.0025651674, 0.0025896502, 0.0025947886, 0.003553662, 0.0029348095]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "kiAGOgrG06MP",
        "outputId": "89a2651f-8f05-4308-b25a-2e918fde429a"
      },
      "source": [
        "plt.plot(tuning_results[min_loss_model[1]-1][-1])\n",
        "plt.plot(tuning_results[min_loss_model[1]][-1])\n",
        "plt.legend([\"Train Loss\", \"Validation Loss\"])\n",
        "plt.title(\"Loss\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(tuning_results[min_loss_model[1]+1][-1])\n",
        "plt.plot(tuning_results[min_loss_model[1]+2][-1])\n",
        "plt.legend([\"Train Acc\", \"Validation Acc\"])\n",
        "plt.title(\"Acc\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUX_WLq7zDdN",
        "outputId": "152e7dfb-9908-4877-d26c-9322371ce87c"
      },
      "source": [
        "# Plots of training epochs\n",
        "epoch = np.arange(1, len(train_acc) + 1)\n",
        "plt.figure()\n",
        "plt.plot(epoch, losses, \"r\", epoch, val_losses, \"b\")\n",
        "plt.legend([\"Train Loss\", \"Validation Loss\"])\n",
        "plt.vlines(best_epoch, ymin=0, ymax=0.005, linestyles='dashed')\n",
        "plt.xlabel(\"Epoch\"), plt.ylabel(\"Loss\")\n",
        "\n",
        "epoch = np.arange(1, len(train_acc) + 1)\n",
        "plt.figure()\n",
        "plt.plot(epoch, train_acc, \"r\", epoch, valid_acc, \"b\")\n",
        "plt.legend([\"Train Accuracy\", \"Validation Accuracy\"])\n",
        "plt.vlines(best_epoch, ymin=0, ymax=0.9, linestyles='dashed')\n",
        "plt.xlabel(\"Epoch\"), plt.ylabel(\"Acc\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(Text(0.5, 0, 'Epoch'), Text(0, 0.5, 'Acc'))"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNNLvPlwzDdN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d17ed7f-31af-42b3-c639-3889cdcef231"
      },
      "source": [
        "# Performance evaluation metrics of final model\n",
        "\n",
        "final_model = torch.load(drive_path+'models_parameter_tuning/early_stopping_model_0.001_0.5_0.0005_3_False.pt')\n",
        "# final_model = torch.load(drive_path+'models_parameter_tuning/early_stopping_model_0.001_0.5_0.0005_2_True.pt')\n",
        "\n",
        "final_model.train()\n",
        "train_preds, train_preds_auc, train_targs = [], [], []\n",
        "for batch_idx, (data, target) in enumerate(train_ldr):\n",
        "    X_batch = data.float().detach().requires_grad_(True)\n",
        "    target_batch = torch.tensor(np.array(target), dtype=torch.float).unsqueeze(1)\n",
        "    \n",
        "    output = final_model(X_batch.to(device))\n",
        "    preds = np.round(output.detach().cpu())\n",
        "    preds_auc = output.detach().cpu()\n",
        "    train_targs += list(np.array(target_batch.cpu()))\n",
        "    train_preds += list(preds.data.numpy().flatten())\n",
        "    train_preds_auc += list(preds_auc.data.numpy().flatten())\n",
        "\n",
        "final_model.eval()\n",
        "val_preds, val_preds_auc, val_targs = [], [], []\n",
        "with torch.no_grad():\n",
        "    for batch_idx, (data, target) in enumerate(val_ldr):  ###\n",
        "        x_batch_val = data.float().detach()\n",
        "        y_batch_val = target.float().detach().unsqueeze(1)\n",
        "\n",
        "        output = final_model(x_batch_val.to(device))\n",
        "\n",
        "        preds = np.round(output.detach().cpu())\n",
        "        val_preds += list(preds.data.numpy().flatten())\n",
        "        preds_auc = output.detach().cpu()\n",
        "        val_preds_auc += list(preds_auc.data.numpy().flatten())\n",
        "        val_targs += list(np.array(y_batch_val))\n",
        "\n",
        "print(\"MCC Train:\", matthews_corrcoef(train_targs, train_preds))\n",
        "print(\"MCC Test:\", matthews_corrcoef(val_targs, val_preds))\n",
        "\n",
        "prec_val = metrics.precision_score(val_targs, val_preds)\n",
        "rec_val = metrics.recall_score(val_targs, val_preds)\n",
        "f1_val = 2 * ((prec_val * rec_val) / (prec_val + rec_val))\n",
        "\n",
        "print(\"Precision Test:\", prec_val)\n",
        "print(\"Recall Test:\", rec_val)\n",
        "print(\"F1 Test:\", f1_val)\n",
        "\n",
        "print(\"Confusion matrix train:\", confusion_matrix(train_targs, train_preds), sep=\"\\n\")\n",
        "print(\"Confusion matrix test:\", confusion_matrix(val_targs, val_preds), sep=\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MCC Train: 0.6739842817377084\n",
            "MCC Test: 0.6343536171904575\n",
            "Precision Test: 0.8661417322834646\n",
            "Recall Test: 0.5744125326370757\n",
            "F1 Test: 0.6907378335949764\n",
            "Confusion matrix train:\n",
            "[[3081   51]\n",
            " [ 433  609]]\n",
            "Confusion matrix test:\n",
            "[[1115   34]\n",
            " [ 163  220]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYYlvLICzDdP"
      },
      "source": [
        "def plot_roc(targets, predictions):\n",
        "    # ROC\n",
        "    fpr, tpr, threshold = metrics.roc_curve(targets, predictions)\n",
        "    roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "    # plot ROC\n",
        "    plt.figure()\n",
        "    plt.title(\"Receiver Operating Characteristic\")\n",
        "    plt.plot(fpr, tpr, \"b\", label=\"AUC = %0.2f\" % roc_auc)\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.plot([0, 1], [0, 1], \"r--\")\n",
        "    plt.xlim([0, 1])\n",
        "    plt.ylim([0, 1])\n",
        "    plt.ylabel(\"True Positive Rate\")\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "    # plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGWPHpr-zDdP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "5f9dbc9e-dbab-4e84-9dee-cb0320d85d08"
      },
      "source": [
        "plot_roc(train_targs, train_preds_auc)\n",
        "plt.title(\"Training AUC\")\n",
        "plot_roc(val_targs, val_preds_auc)\n",
        "plt.title(\"Validation AUC\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "av9kZibSzDdP"
      },
      "source": [
        "# Helpful scripts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1ye24zFzDdQ"
      },
      "source": [
        "# Show dataset as copied dataframes with named features\n",
        "The dataset is a 3D numpy array, of dimensions n_complexes x features x positions. This makes viewing the features for individual complexes or samples challenging. Below is a function which copies the entire dataset, and converts it into a list of DataFrames with named indices and columns, in order to make understanding the data easier.\n",
        "\n",
        "NB: This list of dataframes are only copies, and will not be passable into the neural network architecture."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yinrdpjqzDdR",
        "outputId": "d47cada6-fd64-47fd-e6f9-b6c707f73be6"
      },
      "source": [
        "pd.read_csv(\"../hackathon_data_scripts/data/example.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>A</th>\n",
              "      <th>C</th>\n",
              "      <th>D</th>\n",
              "      <th>E</th>\n",
              "      <th>F</th>\n",
              "      <th>G</th>\n",
              "      <th>H</th>\n",
              "      <th>I</th>\n",
              "      <th>K</th>\n",
              "      <th>L</th>\n",
              "      <th>...</th>\n",
              "      <th>global_tcr_fa_rep</th>\n",
              "      <th>global_tcr_fa_sol</th>\n",
              "      <th>global_tcr_p_aa_pp</th>\n",
              "      <th>global_pmhc_total_score</th>\n",
              "      <th>global_pmhc_fa_atr</th>\n",
              "      <th>global_pmhc_fa_dun</th>\n",
              "      <th>global_pmhc_fa_elec</th>\n",
              "      <th>global_pmhc_fa_rep</th>\n",
              "      <th>global_pmhc_fa_sol</th>\n",
              "      <th>global_pmhc_p_aa_pp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>681.926</td>\n",
              "      <td>-40.471</td>\n",
              "      <td>2.401</td>\n",
              "      <td>-555.661</td>\n",
              "      <td>246.945</td>\n",
              "      <td>-359.301</td>\n",
              "      <td>2.25</td>\n",
              "      <td>733.179</td>\n",
              "      <td>-39.727</td>\n",
              "      <td>0.481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>681.926</td>\n",
              "      <td>-40.471</td>\n",
              "      <td>2.401</td>\n",
              "      <td>-555.661</td>\n",
              "      <td>246.945</td>\n",
              "      <td>-359.301</td>\n",
              "      <td>2.25</td>\n",
              "      <td>733.179</td>\n",
              "      <td>-39.727</td>\n",
              "      <td>0.481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>681.926</td>\n",
              "      <td>-40.471</td>\n",
              "      <td>2.401</td>\n",
              "      <td>-555.661</td>\n",
              "      <td>246.945</td>\n",
              "      <td>-359.301</td>\n",
              "      <td>2.25</td>\n",
              "      <td>733.179</td>\n",
              "      <td>-39.727</td>\n",
              "      <td>0.481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>681.926</td>\n",
              "      <td>-40.471</td>\n",
              "      <td>2.401</td>\n",
              "      <td>-555.661</td>\n",
              "      <td>246.945</td>\n",
              "      <td>-359.301</td>\n",
              "      <td>2.25</td>\n",
              "      <td>733.179</td>\n",
              "      <td>-39.727</td>\n",
              "      <td>0.481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>681.926</td>\n",
              "      <td>-40.471</td>\n",
              "      <td>2.401</td>\n",
              "      <td>-555.661</td>\n",
              "      <td>246.945</td>\n",
              "      <td>-359.301</td>\n",
              "      <td>2.25</td>\n",
              "      <td>733.179</td>\n",
              "      <td>-39.727</td>\n",
              "      <td>0.481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>415</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>416</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>417</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>418</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>419</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>420 rows × 54 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       A    C    D    E    F    G    H    I    K    L  ...  global_tcr_fa_rep  \\\n",
              "0    0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...            681.926   \n",
              "1    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...            681.926   \n",
              "2    0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  ...            681.926   \n",
              "3    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...            681.926   \n",
              "4    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...            681.926   \n",
              "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...                ...   \n",
              "415  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...              0.000   \n",
              "416  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...              0.000   \n",
              "417  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...              0.000   \n",
              "418  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...              0.000   \n",
              "419  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...              0.000   \n",
              "\n",
              "      global_tcr_fa_sol   global_tcr_p_aa_pp  global_pmhc_total_score  \\\n",
              "0               -40.471                2.401                 -555.661   \n",
              "1               -40.471                2.401                 -555.661   \n",
              "2               -40.471                2.401                 -555.661   \n",
              "3               -40.471                2.401                 -555.661   \n",
              "4               -40.471                2.401                 -555.661   \n",
              "..                  ...                  ...                      ...   \n",
              "415               0.000                0.000                    0.000   \n",
              "416               0.000                0.000                    0.000   \n",
              "417               0.000                0.000                    0.000   \n",
              "418               0.000                0.000                    0.000   \n",
              "419               0.000                0.000                    0.000   \n",
              "\n",
              "      global_pmhc_fa_atr   global_pmhc_fa_dun   global_pmhc_fa_elec  \\\n",
              "0                246.945             -359.301                  2.25   \n",
              "1                246.945             -359.301                  2.25   \n",
              "2                246.945             -359.301                  2.25   \n",
              "3                246.945             -359.301                  2.25   \n",
              "4                246.945             -359.301                  2.25   \n",
              "..                   ...                  ...                   ...   \n",
              "415                0.000                0.000                  0.00   \n",
              "416                0.000                0.000                  0.00   \n",
              "417                0.000                0.000                  0.00   \n",
              "418                0.000                0.000                  0.00   \n",
              "419                0.000                0.000                  0.00   \n",
              "\n",
              "     global_pmhc_fa_rep   global_pmhc_fa_sol   global_pmhc_p_aa_pp  \n",
              "0               733.179              -39.727                 0.481  \n",
              "1               733.179              -39.727                 0.481  \n",
              "2               733.179              -39.727                 0.481  \n",
              "3               733.179              -39.727                 0.481  \n",
              "4               733.179              -39.727                 0.481  \n",
              "..                  ...                  ...                   ...  \n",
              "415               0.000                0.000                 0.000  \n",
              "416               0.000                0.000                 0.000  \n",
              "417               0.000                0.000                 0.000  \n",
              "418               0.000                0.000                 0.000  \n",
              "419               0.000                0.000                 0.000  \n",
              "\n",
              "[420 rows x 54 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zmtfb8S-zDdR",
        "outputId": "085b41b1-1a2e-46d6-d806-4ab723dbeab0"
      },
      "source": [
        "def copy_as_dataframes(dataset_X):\n",
        "    \"\"\"\n",
        "    Returns list of DataFrames with named features from dataset_X,\n",
        "    using example CSV file\n",
        "    \"\"\"\n",
        "    df_raw = pd.read_csv(\"../hackathon_data_scripts/data/example.csv\")\n",
        "    return [pd.DataFrame(arr, columns=df_raw.columns) for arr in dataset_X]\n",
        "\n",
        "\n",
        "named_dataframes = copy_as_dataframes(X_train)\n",
        "print(\n",
        "    \"Showing first complex as dataframe. Columns are positions and indices are calculated features\"\n",
        ")\n",
        "named_dataframes[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Showing first complex as dataframe. Columns are positions and indices are calculated features\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>A</th>\n",
              "      <th>C</th>\n",
              "      <th>D</th>\n",
              "      <th>E</th>\n",
              "      <th>F</th>\n",
              "      <th>G</th>\n",
              "      <th>H</th>\n",
              "      <th>I</th>\n",
              "      <th>K</th>\n",
              "      <th>L</th>\n",
              "      <th>...</th>\n",
              "      <th>global_tcr_fa_rep</th>\n",
              "      <th>global_tcr_fa_sol</th>\n",
              "      <th>global_tcr_p_aa_pp</th>\n",
              "      <th>global_pmhc_total_score</th>\n",
              "      <th>global_pmhc_fa_atr</th>\n",
              "      <th>global_pmhc_fa_dun</th>\n",
              "      <th>global_pmhc_fa_elec</th>\n",
              "      <th>global_pmhc_fa_rep</th>\n",
              "      <th>global_pmhc_fa_sol</th>\n",
              "      <th>global_pmhc_p_aa_pp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>656.289</td>\n",
              "      <td>-47.814</td>\n",
              "      <td>1.699</td>\n",
              "      <td>-571.57</td>\n",
              "      <td>229.289</td>\n",
              "      <td>-359.096</td>\n",
              "      <td>2.145</td>\n",
              "      <td>727.371</td>\n",
              "      <td>-40.566</td>\n",
              "      <td>0.554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>656.289</td>\n",
              "      <td>-47.814</td>\n",
              "      <td>1.699</td>\n",
              "      <td>-571.57</td>\n",
              "      <td>229.289</td>\n",
              "      <td>-359.096</td>\n",
              "      <td>2.145</td>\n",
              "      <td>727.371</td>\n",
              "      <td>-40.566</td>\n",
              "      <td>0.554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>656.289</td>\n",
              "      <td>-47.814</td>\n",
              "      <td>1.699</td>\n",
              "      <td>-571.57</td>\n",
              "      <td>229.289</td>\n",
              "      <td>-359.096</td>\n",
              "      <td>2.145</td>\n",
              "      <td>727.371</td>\n",
              "      <td>-40.566</td>\n",
              "      <td>0.554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>656.289</td>\n",
              "      <td>-47.814</td>\n",
              "      <td>1.699</td>\n",
              "      <td>-571.57</td>\n",
              "      <td>229.289</td>\n",
              "      <td>-359.096</td>\n",
              "      <td>2.145</td>\n",
              "      <td>727.371</td>\n",
              "      <td>-40.566</td>\n",
              "      <td>0.554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>656.289</td>\n",
              "      <td>-47.814</td>\n",
              "      <td>1.699</td>\n",
              "      <td>-571.57</td>\n",
              "      <td>229.289</td>\n",
              "      <td>-359.096</td>\n",
              "      <td>2.145</td>\n",
              "      <td>727.371</td>\n",
              "      <td>-40.566</td>\n",
              "      <td>0.554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>415</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>416</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>417</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>418</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>419</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>420 rows × 54 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       A    C    D    E    F    G    H    I    K    L  ...  global_tcr_fa_rep  \\\n",
              "0    0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...            656.289   \n",
              "1    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...            656.289   \n",
              "2    0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  ...            656.289   \n",
              "3    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...            656.289   \n",
              "4    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...            656.289   \n",
              "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...                ...   \n",
              "415  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...              0.000   \n",
              "416  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...              0.000   \n",
              "417  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...              0.000   \n",
              "418  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...              0.000   \n",
              "419  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...              0.000   \n",
              "\n",
              "      global_tcr_fa_sol   global_tcr_p_aa_pp  global_pmhc_total_score  \\\n",
              "0               -47.814                1.699                  -571.57   \n",
              "1               -47.814                1.699                  -571.57   \n",
              "2               -47.814                1.699                  -571.57   \n",
              "3               -47.814                1.699                  -571.57   \n",
              "4               -47.814                1.699                  -571.57   \n",
              "..                  ...                  ...                      ...   \n",
              "415               0.000                0.000                     0.00   \n",
              "416               0.000                0.000                     0.00   \n",
              "417               0.000                0.000                     0.00   \n",
              "418               0.000                0.000                     0.00   \n",
              "419               0.000                0.000                     0.00   \n",
              "\n",
              "      global_pmhc_fa_atr   global_pmhc_fa_dun   global_pmhc_fa_elec  \\\n",
              "0                229.289             -359.096                 2.145   \n",
              "1                229.289             -359.096                 2.145   \n",
              "2                229.289             -359.096                 2.145   \n",
              "3                229.289             -359.096                 2.145   \n",
              "4                229.289             -359.096                 2.145   \n",
              "..                   ...                  ...                   ...   \n",
              "415                0.000                0.000                 0.000   \n",
              "416                0.000                0.000                 0.000   \n",
              "417                0.000                0.000                 0.000   \n",
              "418                0.000                0.000                 0.000   \n",
              "419                0.000                0.000                 0.000   \n",
              "\n",
              "     global_pmhc_fa_rep   global_pmhc_fa_sol   global_pmhc_p_aa_pp  \n",
              "0               727.371              -40.566                 0.554  \n",
              "1               727.371              -40.566                 0.554  \n",
              "2               727.371              -40.566                 0.554  \n",
              "3               727.371              -40.566                 0.554  \n",
              "4               727.371              -40.566                 0.554  \n",
              "..                  ...                  ...                   ...  \n",
              "415               0.000                0.000                 0.000  \n",
              "416               0.000                0.000                 0.000  \n",
              "417               0.000                0.000                 0.000  \n",
              "418               0.000                0.000                 0.000  \n",
              "419               0.000                0.000                 0.000  \n",
              "\n",
              "[420 rows x 54 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5K9b_1dzDdS"
      },
      "source": [
        "# View complex MHC, peptide and TCR alpha/beta sequences\n",
        "You may want to view the one-hot encoded sequences as sequences in single-letter amino-acid format. The below function will return the TCR, peptide and MHC sequences for the dataset as 3 lists."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnWyE921zDdS"
      },
      "source": [
        "def oneHot(residue):\n",
        "    \"\"\"\n",
        "    Converts string sequence to one-hot encoding\n",
        "    Example usage:\n",
        "    seq = \"GSHSMRY\"\n",
        "    oneHot(seq)\n",
        "    \"\"\"\n",
        "\n",
        "    mapping = dict(zip(\"ACDEFGHIKLMNPQRSTVWY\", range(20)))\n",
        "    if residue in \"ACDEFGHIKLMNPQRSTVWY\":\n",
        "        return np.eye(20)[mapping[residue]]\n",
        "    else:\n",
        "        return np.zeros(20)\n",
        "\n",
        "\n",
        "def reverseOneHot(encoding):\n",
        "    \"\"\"\n",
        "    Converts one-hot encoded array back to string sequence\n",
        "    \"\"\"\n",
        "    mapping = dict(zip(range(20), \"ACDEFGHIKLMNPQRSTVWY\"))\n",
        "    seq = \"\"\n",
        "    for i in range(len(encoding)):\n",
        "        if np.max(encoding[i]) > 0:\n",
        "            seq += mapping[np.argmax(encoding[i])]\n",
        "    return seq\n",
        "\n",
        "\n",
        "def extract_sequences(dataset_X):\n",
        "    \"\"\"\n",
        "    Return DataFrame with MHC, peptide and TCR a/b sequences from\n",
        "    one-hot encoded complex sequences in dataset X\n",
        "    \"\"\"\n",
        "    mhc_sequences = [reverseOneHot(arr[0:179, 0:20]) for arr in dataset_X]\n",
        "    pep_sequences = [reverseOneHot(arr[179:190, 0:20]) for arr in dataset_X]\n",
        "    tcr_sequences = [reverseOneHot(arr[192:, 0:20]) for arr in dataset_X]\n",
        "    df_sequences = pd.DataFrame(\n",
        "        {\"MHC\": mhc_sequences, \"peptide\": pep_sequences, \"tcr\": tcr_sequences}\n",
        "    )\n",
        "    return df_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "YNKjxSa9zDdS",
        "outputId": "fe08e715-b9ad-40f3-f779-213aa3723d06"
      },
      "source": [
        "complex_sequences = extract_sequences(X_val)\n",
        "print(\"Showing MHC, peptide and TCR alpha/beta sequences for each complex\")\n",
        "complex_sequences"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Showing MHC, peptide and TCR alpha/beta sequences for each complex\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MHC</th>\n",
              "      <th>peptide</th>\n",
              "      <th>tcr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>GSHSMRYFFTSVSRPGRGEPRFIAVGYVDDTQFVRFDSDAASQRME...</td>\n",
              "      <td>GILGFVFTL</td>\n",
              "      <td>EQSPQFLSIQEGENLTVYCNSSSVFSSLQWYRQEPGEGPVLLVTVV...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>GSHSMRYFFTSVSRPGRGEPRFIAVGYVDDTQFVRFDSDAASQRME...</td>\n",
              "      <td>GILGFVFTL</td>\n",
              "      <td>EQSPQFLSIQEGENLTVYCNSSSVFSSLQWYRQEPGEGPVLLVTVV...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>GSHSMRYFFTSVSRPGRGEPRFIAVGYVDDTQFVRFDSDAASQRME...</td>\n",
              "      <td>GILGFVFTL</td>\n",
              "      <td>QQVKQNSPSLSVQEGRISILNCDYTNSMFDYFLWYKKYPAEGPTFL...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>GSHSMRYFFTSVSRPGRGEPRFIAVGYVDDTQFVRFDSDAASQRME...</td>\n",
              "      <td>GILGFVFTL</td>\n",
              "      <td>EQSPQFLSIQEGENLTVYCNSSSVFSSLQWYRQEPGEGPVLLVTVV...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>GSHSMRYFFTSVSRPGRGEPRFIAVGYVDDTQFVRFDSDAASQRME...</td>\n",
              "      <td>GILGFVFTL</td>\n",
              "      <td>EQSPQFLSIQEGENLTVYCNSSSVFSSLQWYRQEPGEGPVLLVTVV...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1521</th>\n",
              "      <td>GSHSMRYFFTSVSRPGRGEPRFIAVGYVDDTQFVRFDSDAASQRME...</td>\n",
              "      <td>FLYALALLL</td>\n",
              "      <td>QSPQSMFIQEGEDVSMNCTSSSIFNTWLWYKQEPGEGPVLLIALYK...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1522</th>\n",
              "      <td>GSHSMRYFFTSVSRPGRGEPRFIAVGYVDDTQFVRFDSDAASQRME...</td>\n",
              "      <td>LLFGYPVYV</td>\n",
              "      <td>PQALSIQEGENATMNCSYKTSINNLQWYRQNSGRGLVHLILIRSNE...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1523</th>\n",
              "      <td>GSHSMRYFFTSVSRPGRGEPRFIAVGYVDDTQFVRFDSDAASQRME...</td>\n",
              "      <td>GLCTLVAML</td>\n",
              "      <td>EQSPQFLSIQEGENLTVYCNSSSVFSSLQWYRQEPGEGPVLLVTVV...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1524</th>\n",
              "      <td>GSHSMRYFFTSVSRPGRGEPRFIAVGYVDDTQFVRFDSDAASQRME...</td>\n",
              "      <td>FLYALALLL</td>\n",
              "      <td>QQVKQNSPSLSVQEGRISILNCDYTNSMFDYFLWYKKYPAEGPTFL...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1525</th>\n",
              "      <td>GSHSMRYFFTSVSRPGRGEPRFIAVGYVDDTQFVRFDSDAASQRME...</td>\n",
              "      <td>GLCTLVAML</td>\n",
              "      <td>EQSPQSLIVQEGKNLTINCTSSKTLYGLYWYKQKYGEGLIFLMMLQ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1526 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    MHC    peptide  \\\n",
              "0     GSHSMRYFFTSVSRPGRGEPRFIAVGYVDDTQFVRFDSDAASQRME...  GILGFVFTL   \n",
              "1     GSHSMRYFFTSVSRPGRGEPRFIAVGYVDDTQFVRFDSDAASQRME...  GILGFVFTL   \n",
              "2     GSHSMRYFFTSVSRPGRGEPRFIAVGYVDDTQFVRFDSDAASQRME...  GILGFVFTL   \n",
              "3     GSHSMRYFFTSVSRPGRGEPRFIAVGYVDDTQFVRFDSDAASQRME...  GILGFVFTL   \n",
              "4     GSHSMRYFFTSVSRPGRGEPRFIAVGYVDDTQFVRFDSDAASQRME...  GILGFVFTL   \n",
              "...                                                 ...        ...   \n",
              "1521  GSHSMRYFFTSVSRPGRGEPRFIAVGYVDDTQFVRFDSDAASQRME...  FLYALALLL   \n",
              "1522  GSHSMRYFFTSVSRPGRGEPRFIAVGYVDDTQFVRFDSDAASQRME...  LLFGYPVYV   \n",
              "1523  GSHSMRYFFTSVSRPGRGEPRFIAVGYVDDTQFVRFDSDAASQRME...  GLCTLVAML   \n",
              "1524  GSHSMRYFFTSVSRPGRGEPRFIAVGYVDDTQFVRFDSDAASQRME...  FLYALALLL   \n",
              "1525  GSHSMRYFFTSVSRPGRGEPRFIAVGYVDDTQFVRFDSDAASQRME...  GLCTLVAML   \n",
              "\n",
              "                                                    tcr  \n",
              "0     EQSPQFLSIQEGENLTVYCNSSSVFSSLQWYRQEPGEGPVLLVTVV...  \n",
              "1     EQSPQFLSIQEGENLTVYCNSSSVFSSLQWYRQEPGEGPVLLVTVV...  \n",
              "2     QQVKQNSPSLSVQEGRISILNCDYTNSMFDYFLWYKKYPAEGPTFL...  \n",
              "3     EQSPQFLSIQEGENLTVYCNSSSVFSSLQWYRQEPGEGPVLLVTVV...  \n",
              "4     EQSPQFLSIQEGENLTVYCNSSSVFSSLQWYRQEPGEGPVLLVTVV...  \n",
              "...                                                 ...  \n",
              "1521  QSPQSMFIQEGEDVSMNCTSSSIFNTWLWYKQEPGEGPVLLIALYK...  \n",
              "1522  PQALSIQEGENATMNCSYKTSINNLQWYRQNSGRGLVHLILIRSNE...  \n",
              "1523  EQSPQFLSIQEGENLTVYCNSSSVFSSLQWYRQEPGEGPVLLVTVV...  \n",
              "1524  QQVKQNSPSLSVQEGRISILNCDYTNSMFDYFLWYKKYPAEGPTFL...  \n",
              "1525  EQSPQSLIVQEGKNLTINCTSSKTLYGLYWYKQKYGEGLIFLMMLQ...  \n",
              "\n",
              "[1526 rows x 3 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_537tpCzDdT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRZgVDxOzDdT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}