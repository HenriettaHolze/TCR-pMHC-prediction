import numpy as np
import pandas as pd
import torch

def reverseOneHot(encoding):
    """
    Converts one-hot encoded array back to string sequence
    """
    mapping = dict(zip(range(20), "ACDEFGHIKLMNPQRSTVWY"))
    seq = ""
    for i in range(len(encoding)):
        if np.max(encoding[i]) > 0:
            seq += mapping[np.argmax(encoding[i])]
    return seq


def extract_sequences(dataset_X):
    """
    Return DataFrame with MHC, peptide and TCR a/b sequences from
    one-hot encoded complex sequences in dataset X
    """
    mhc_sequences = [reverseOneHot(arr[0:179, 0:20]) for arr in dataset_X]
    pep_sequences = [reverseOneHot(arr[179:190, 0:20]) for arr in dataset_X]
    tcr_sequences = [reverseOneHot(arr[190:, 0:20]) for arr in dataset_X]
    df_sequences = pd.DataFrame(
        {"MHC": mhc_sequences, "peptide": pep_sequences, "tcr": tcr_sequences}
    )
    return df_sequences


def load_mean_embeddings(folder_path : str, seq_counts : int, type : str):
    """
    Loads embeddings generated by esm into a list of numpy arrays
    """
    data = []
    for i in range(seq_counts):
        file = folder_path + '/' + type + '-' + str(i) + '.pt'
        data.append(torch.load(file)['mean_representations'][33].numpy())
    return data


def load_embeddings(folder_path : str, seq_counts : int, type : str):
    """
    Loads embeddings generated by esm into a list of numpy arrays
    """
    data = []
    for i in range(seq_counts):
        file = folder_path + '/' + type + '-' + str(i) + '.pt'
        data.append(torch.load(file)['representations'][33].numpy())
    return data


def make_mapdict(seqs : list[str], unique_seqs : list[str]):
    """
    Generate a dict in order to map sequences to the embeddings made on unique sequences
    """

    mapping = {}
    for i in range(len(seqs)):
        for j in range(len(unique_seqs)):
            if seqs[i] == unique_seqs[j]:
                mapping[i] = j
                break
    return mapping

def impute_mean_embeddings(data, mhc_emb, pep_emb, tcr_emb):

    complex_sequences = extract_sequences(data)

    MHC_list = np.array(complex_sequences["MHC"], dtype=str)
    peptide_list = np.array(complex_sequences["peptide"], dtype=str)
    tcr_list = np.array(complex_sequences["tcr"], dtype=str)

    unique_mhc = np.unique(MHC_list)
    unique_peptide = np.unique(peptide_list)
    unique_tcr = np.unique(tcr_list)

    map_mhc = make_mapdict(MHC_list, unique_mhc)
    map_peptide = make_mapdict(peptide_list, unique_peptide)
    map_tcr = make_mapdict(tcr_list, unique_tcr)

    embedded = np.zeros((data.shape[0], data.shape[1], data.shape[2] + 1280))
    for i in range(data.shape[0]):
        rows, _ = data[i].shape
        embed_arr = np.zeros((rows, 1280))
        embed_arr[0,:] = mhc_emb[map_mhc[i]]
        embed_arr[1,:] = pep_emb[map_peptide[i]]
        embed_arr[2,:] = tcr_emb[map_tcr[i]]
        embedded[i] = np.concatenate((data[i], embed_arr), axis=1)

    return embedded

def get_unique_counts(data):
    """
    Return number of unique sequences of mhc, peptides and tcrs
    """
    complex_sequences = extract_sequences(data)

    MHC_list = np.array(complex_sequences["MHC"], dtype=str)
    peptide_list = np.array(complex_sequences["peptide"], dtype=str)
    tcr_list = np.array(complex_sequences["tcr"], dtype=str)

    unique_mhc = np.unique(MHC_list)
    unique_peptide = np.unique(peptide_list)
    unique_tcr = np.unique(tcr_list)

    return [len(unique_mhc), len(unique_peptide), len(unique_tcr)]

def impute_embeddings(data, mhc_emb, pep_emb, tcr_emb):

    complex_sequences = extract_sequences(data)

    MHC_list = np.array(complex_sequences["MHC"], dtype=str)
    peptide_list = np.array(complex_sequences["peptide"], dtype=str)
    tcr_list = np.array(complex_sequences["tcr"], dtype=str)

    unique_mhc = np.unique(MHC_list)
    unique_peptide = np.unique(peptide_list)
    unique_tcr = np.unique(tcr_list)

    map_mhc = make_mapdict(MHC_list, unique_mhc)
    map_peptide = make_mapdict(peptide_list, unique_peptide)
    map_tcr = make_mapdict(tcr_list, unique_tcr)

    embedded = np.zeros((data.shape[0], data.shape[1], data.shape[2] + 1280))

    embedded[:data.shape[0], :data.shape[1], :data.shape[2]] = data
    for i in range(data.shape[0]):
        rows, _ = data[i].shape

        embedded[i ,:179, data.shape[2]:] = mhc_emb[map_mhc[i]]
        embedded[i,179:188, data.shape[2]:] = pep_emb[map_peptide[i]]
        for j in range(188, 420):
            if not np.all(embedded[i, j, :20] == 0):
                embedded[i,j:j+len(tcr_list[i]), data.shape[2]:] = tcr_emb[map_tcr[i]]
                break


    return embedded


def mean_embeddings_main():
    path = "hackathon_data_scripts/data/train/"
    files = ['P3_input.npz', 'P4_input.npz', 'P2_input.npz', 'P1_input.npz']
    data_list = []
    target_list = []


    for fp in files:
        data = np.load(path+fp)["arr_0"]
        targets = np.load(path+fp.replace("input", "labels"))["arr_0"]

        target_list.append(targets)
        data_list.append(data)

    X_train = np.concatenate(data_list[:-1])
    y_train = np.concatenate(target_list[:-1])

    X_val = np.concatenate(data_list[-1:])
    y_val = np.concatenate(target_list[-1:])

    # Save y data straightaway
    np.savez_compressed('data/y_train', y_train)
    np.savez_compressed('data/y_val', y_val)

    X_train_counts = get_unique_counts(X_train)
    X_val_counts = get_unique_counts(X_val)

    MHC_train = load_mean_embeddings("data/mean_embeddings/MHC-X_train", X_train_counts[0], 'MHC')
    MHC_val = load_mean_embeddings("data/mean_embeddings/MHC-X_val", X_val_counts[0], 'MHC')
    pep_train = load_mean_embeddings("data/mean_embeddings/peptide-X_train", X_train_counts[1], 'peptide')
    pep_val = load_mean_embeddings("data/mean_embeddings/peptide-X_val",  X_val_counts[1], 'peptide')
    tcr_train = load_mean_embeddings("data/mean_embeddings/tcr-X_train", X_train_counts[2], 'tcr')
    tcr_val = load_mean_embeddings("data/mean_embeddings/tcr-X_val",  X_val_counts[2], 'tcr')

    X_val = impute_mean_embeddings(X_val, MHC_val, pep_val, tcr_val)
    X_train = impute_mean_embeddings(X_train, MHC_train, pep_train, tcr_train)

    # Check that data looks correct
    print(X_val.shape)
    print(X_val[0,:,:20])
    print(X_val[100,7,:20])
    print(X_val[0,:,54:])
    print(X_val[-1,:,-1])
    print(X_train.shape)

    np.savez_compressed('data/X_train_mean_emb', X_train)
    np.savez_compressed('data/X_val_mean_emb', X_val)


def embeddings_main():
    path = "hackathon_data_scripts/data/train/"
    files = ['P3_input.npz', 'P4_input.npz', 'P2_input.npz', 'P1_input.npz']
    data_list = []


    for fp in files:
        data = np.load(path+fp)["arr_0"]
        data_list.append(data)

    X_train = np.concatenate(data_list[:-1])
    X_val = np.concatenate(data_list[-1:])
    X_train_counts = get_unique_counts(X_train)
    X_val_counts = get_unique_counts(X_val)

    MHC_train = load_embeddings("data/embeddings/MHC-X_train", X_train_counts[0], 'MHC')
    MHC_val = load_embeddings("data/embeddings/MHC-X_val", X_val_counts[0], 'MHC')
    pep_train = load_embeddings("data/embeddings/peptide-X_train", X_train_counts[1], 'peptide')
    pep_val = load_embeddings("data/embeddings/peptide-X_val", X_val_counts[1], 'peptide')
    tcr_train = load_embeddings("data/embeddings/tcr-X_train", X_train_counts[2], 'tcr')
    tcr_val = load_embeddings("data/embeddings/tcr-X_val", X_val_counts[2],'tcr')

    X_val = impute_embeddings(X_val, MHC_val, pep_val, tcr_val)
    X_train = impute_embeddings(X_train, MHC_train, pep_train, tcr_train)

    # Check that data looks correct
    print(X_val.shape)
    print(X_val[0,:,:20])
    print(X_val[100,7,:20])
    print(X_val[0,:,54:])
    print(X_val[-1,:,-1])

    print(X_train.shape)

    np.savez_compressed('data/X_train_emb', X_train)
    np.savez_compressed('data/X_val_emb', X_val)




if __name__ == '__main__':
    mean_embeddings_main()
    embeddings_main()
